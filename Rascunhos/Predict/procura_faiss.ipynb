{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 09:48:55.493988: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import time\n",
    "import glob\n",
    "import h5py\n",
    "import faiss\n",
    "import click\n",
    "import curses\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "from model_RA.fp_RA.melspec.melspectrogram_RA import get_melspec_layer\n",
    "from model_RA.fp_RA.nnfp import get_fingerprinter\n",
    "from model_RA.utils.dataloader_keras import genUnbalSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5_data(source_dir):\n",
    "    h5Files = sorted(glob.glob(source_dir + '**/*.h5', recursive=True))\n",
    "\n",
    "    embs_count = 0\n",
    "    embs_info = []\n",
    "    embs = []\n",
    "\n",
    "    for i in range(len(h5Files[30005:])):\n",
    "        with h5py.File(h5Files[i], \"r\") as f:\n",
    "            #print(i)\n",
    "            base_name = os.path.splitext(os.path.basename(h5Files[i]))[0]\n",
    "            #primeiro objeto é o que contém os embeddings\n",
    "            a_group_key = list(f.keys())[0]\n",
    "\n",
    "            #Extração dos embs como um array\n",
    "            ds_arr = f[a_group_key][()]  # returns as a numpy array\n",
    "            #print(ds_arr.shape)\n",
    "            embeddings = np.squeeze(ds_arr, axis=1)\n",
    "            #print(embeddings.shape)\n",
    "            embs.append(embeddings) #Guarda na lista os embs\n",
    "            #arrayEmb = ds_arr\n",
    "\n",
    "            embs_count += len(ds_arr) #conta quantos embs tem o vetor\n",
    "            embs_info.append([i, base_name, embs_count, ds_arr]) #guarda numa lista o número de vetores até o momento.\n",
    "            # embs_info = [indice, file_name, n_segs, array]\n",
    "            \n",
    "            f.close()\n",
    "    return embs, embs_info\n",
    "\n",
    "def create_index(db_embeddings, nogpu=True, n_centroids=256, code_sz=64, nbits=8):\n",
    "    #faiss.IndexIVFPQ(quantizer, d, n_centroids, code_sz, nbits), com d=, nlist=n_centroids=50, m=code_sz=8, bits=nbits=8\n",
    "    #faiss.IndexIVFPQ(quantizer, d, nlist, m, bits)\n",
    "    #n_centroids -> clusters\n",
    "    \n",
    "    d = db_embeddings.shape[1]  # Dim emb #len(db_embeddings[0][0][0])\n",
    "\n",
    "    quantizer = faiss.IndexFlatL2(d)\n",
    "\n",
    "    code_sz = 64 # power of 2\n",
    "    n_centroids = 256 #Veronoi Cells\n",
    "    nbits = 8  # nbits must be 8, 12 or 16, The dimension d should be a multiple of M.\n",
    "    index = faiss.IndexIVFPQ(quantizer, d, n_centroids, code_sz, nbits) #Adicona clustering\n",
    "\n",
    "    # Se não usar GPU\n",
    "    if not nogpu:\n",
    "        res = faiss.StandardGpuResources()\n",
    "        index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "\n",
    "    if not index.is_trained:\n",
    "        index.train(db_embeddings)\n",
    "\n",
    "    # Adicionando os embeddings ao índice\n",
    "    index.add(db_embeddings)\n",
    "    print(f\"Foram adicionados:{index.ntotal}\")\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/mnt/dev/rodrigoalmeida/neural-audio-fp/logs/emb/CHECK_BFTRI_100/101/'\n",
    "h5Dir = '/mnt/dataset/public/Fingerprinting/Embeddings_BFTRI/dummy_db/'\n",
    "h5Embs, embs_info = load_h5_data(h5Dir)\n",
    "embsArrayDummy=np.vstack(h5Embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m faiss_engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43membsArrayDummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnogpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_centroids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_sz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#dummy_db\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m, in \u001b[0;36mcreate_index\u001b[0;34m(db_embeddings, nogpu, n_centroids, code_sz, nbits)\u001b[0m\n\u001b[1;32m     47\u001b[0m     index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mindex_cpu_to_gpu(res, \u001b[38;5;241m0\u001b[39m, index)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m index\u001b[38;5;241m.\u001b[39mis_trained:\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Adicionando os embeddings ao índice\u001b[39;00m\n\u001b[1;32m     53\u001b[0m index\u001b[38;5;241m.\u001b[39madd(db_embeddings)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfpy/lib/python3.9/site-packages/faiss/__init__.py:128\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_train\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    126\u001b[0m n, d \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswig_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfpy/lib/python3.9/site-packages/faiss/swigfaiss.py:2776\u001b[0m, in \u001b[0;36mIndexIVF.train\u001b[0;34m(self, n, x)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, n, x):\n\u001b[0;32m-> 2776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_swigfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexIVF_train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "faiss_engine = create_index(embsArrayDummy, nogpu=True, n_centroids=256, code_sz=64, nbits=8) #dummy_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_fp\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def predict(X, m_pre, m_fp):\n",
    "    \"\"\" \n",
    "    Test step used for mini-search-validation \n",
    "    X -> (B,1,8000)\n",
    "    \"\"\"\n",
    "    #tf.print(X)\n",
    "    feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = False\n",
    "    emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)\n",
    "    #emb_f_postL2 = tf.math.l2_normalize(emb_f, axis=1)\n",
    "    emb_gf = m_fp.div_enc(emb_f)\n",
    "    emb_gf = tf.math.l2_normalize(emb_gf, axis=1)\n",
    "    return emb_gf # f(.), L2(f(.)), L2(g(f(.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default_RA.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.InitializationOnlyStatus at 0x7c1585ea5a60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = \"default_RA\"\n",
    "cfg = load_config(config)\n",
    "\n",
    "m_pre, m_fp = build_fp(cfg)\n",
    "\n",
    "checkpoint_root_dir:str = \"./logs/CHECK_BFTRI_100/101/\"\n",
    "checkpoint = tf.train.Checkpoint(m_fp)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_root_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 09:49:49.880413: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 262144000 exceeds 10% of free system memory.\n",
      "2024-06-22 09:49:50.018361: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 262144000 exceeds 10% of free system memory.\n",
      "2024-06-22 09:49:50.018426: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 262144000 exceeds 10% of free system memory.\n",
      "2024-06-22 09:49:50.018441: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 262144000 exceeds 10% of free system memory.\n",
      "2024-06-22 09:49:51.168904: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 262144000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "#source_root_dir = '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/'\n",
    "audio_dir = '/mnt/dataset/public/Fingerprinting/query_procura/000003.wav' #audio query\n",
    "ts_dummy_db_source_fps = sorted(\n",
    "    glob.glob(audio_dir, recursive=True))\n",
    "\n",
    "dur = cfg['MODEL']['DUR']\n",
    "hop = cfg['MODEL']['HOP']\n",
    "fs = cfg['MODEL']['FS']\n",
    "bsz = ts_batch_sz = cfg['BSZ']['TS_BATCH_SZ']\n",
    "\n",
    "_ts_n_anchor = ts_batch_sz\n",
    "ds = genUnbalSequence(\n",
    "    ts_dummy_db_source_fps,\n",
    "    ts_batch_sz,\n",
    "    _ts_n_anchor,\n",
    "    dur,\n",
    "    hop,\n",
    "    fs,\n",
    "    shuffle=False,\n",
    "    random_offset_anchor=False,\n",
    "    drop_the_last_non_full_batch=False)\n",
    "\n",
    "enq = tf.keras.utils.OrderedEnqueuer(ds,use_multiprocessing=True,shuffle=False)\n",
    "enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'], max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "\n",
    "i = 0\n",
    "emb_query_list = []\n",
    "\n",
    "while i < len(enq.sequence):\n",
    "    X, _ = next(enq.get())\n",
    "    emb = predict(X, m_pre, m_fp)\n",
    "    emb_query_list.append(emb.numpy())\n",
    "    i += 1\n",
    "enq.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_query_array = np.vstack(emb_query_list) #emb_array[472] = emb_query_list[3][97] pois emb_query_list tem 4 batches, sendo os 3 primeiros preenchidos até 125 vetores, e o último com 98 vetores.\n",
    "#Com esta conversão passo a ter um array com todos os vetores, ou seja, os 473\n",
    "#genérico: O tem a seguinte forma emb_query_list[N_BSZ][BSZ], e quando o último não está preenchido tem o valor que entre 0 e 125. Pois, BSZ de teste = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faiss_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfaiss_engine\u001b[49m\u001b[38;5;241m.\u001b[39mntotal)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(faiss_engine\u001b[38;5;241m.\u001b[39mnprobe)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# c) Buscar o índice\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'faiss_engine' is not defined"
     ]
    }
   ],
   "source": [
    "print(faiss_engine.ntotal)\n",
    "print(faiss_engine.nprobe)\n",
    "topN = 1 #Numero de índices por vetor que retornar na comparação\n",
    "\n",
    "# c) Buscar o índice\n",
    "D, I = faiss_engine.search(emb_query_array, 1) # D: Distâncias, I: Índices dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "II=I\n",
    "for offset in range(len(I)):\n",
    "    II[offset, :] -= offset\n",
    "\n",
    "candidates = np.unique(I[np.where(I >= 0)])   # ignore id < 0\n",
    "\n",
    "\n",
    "x = 0\n",
    "idx = 0\n",
    "for i in range(len(embs_info)):\n",
    "    if embs_info[i][2] < candidates[0]:\n",
    "        x=embs_info[i+1][2]\n",
    "        idx = i+1\n",
    "\n",
    "print(idx, x, candidates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = \"/mnt/dataset/public/Fingerprinting/selected_tracks.csv\"\n",
    "metadata_df = pd.read_csv(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) Recuperar os metadados\n",
    "\n",
    "data = metadata_df.loc[metadata_df[\"track_id\"] == int(embs_info[idx][1])]\n",
    "\n",
    "# e) Retornar ao Cliente\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
