{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import click\n",
    "import yaml\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import curses\n",
    "import numpy as np\n",
    "#sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))\n",
    "from eval.utils.get_index_faiss import get_index\n",
    "from eval.utils.print_table import PrintTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.eval_faiss import eval_faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memmap_data(source_dir,\n",
    "                     fname,\n",
    "                     append_extra_length=None,\n",
    "                     shape_only=False,\n",
    "                     display=True):\n",
    "    \"\"\"\n",
    "    Load data and datashape from the file path.\n",
    "\n",
    "    • Get shape from [source_dir/.npy}.\n",
    "    • Load memmap data from [source_dir/fname.mm].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source_dir : (str)\n",
    "    fname : (str)\n",
    "        File name except extension.\n",
    "    append_empty_length : None or (int)\n",
    "        Length to appened empty vector when loading memmap. If activate, the\n",
    "        file will be opened as 'r+' mode.\n",
    "    shape_only : (bool), optional\n",
    "        Return only shape. The default is False.\n",
    "    display : (bool), optional\n",
    "        The default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (data, data_shape)\n",
    "\n",
    "    \"\"\"\n",
    "    path_shape = source_dir + fname + '_shape.npy'\n",
    "    path_data = source_dir + fname + '.mm'\n",
    "    data_shape = np.load(path_shape)\n",
    "    if shape_only:\n",
    "        return data_shape\n",
    "\n",
    "    if append_extra_length:\n",
    "        data_shape[0] += append_extra_length\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r+',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    else:\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    if display:\n",
    "        print(f'Load {data_shape[0]:,} items from \\033[32m{path_data}\\033[0m.')\n",
    "    return data, data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name:str = \"Checks_test_generate\"   # string\n",
    "checkpoint_index:int = 100  # int\n",
    "config:str = \"default\"       # string 'default'\n",
    "index_type:str = 'IVFPQ'  # {'L2', 'IVF', 'IVFPQ', \" + \"'IVFPQ-RR', 'IVFPQ-ONDISK', HNSW'}\"\n",
    "test_seq_len:str =  '11'   # string '1 3 5 9 11 19' segundos \n",
    "test_ids:str = \"icassp\"\n",
    "nogpu:bool = False\n",
    "emb_dummy_dir:str = None\n",
    "max_train:int = 1e7\n",
    "k_probe:int = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(config)\n",
    "emb_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + checkpoint_name + '/' + \\\n",
    "    str(checkpoint_index) + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSegment/sequence-wise audio search experiment and evaluation: implementation based on FAISS.\\n\\nex) python eval.py EMB_DIR --index_type ivfpq\\n\\nEMB_DIR: Directory where {query, db, dummy_db}.mm files are located. The 'raw_score.npy' and 'test_ids.npy' will be also created in the same directory.\\n\""
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def eval_faiss(emb_dir,\n",
    "               emb_dummy_dir=None,\n",
    "               index_type='ivfpq',\n",
    "               nogpu=False,\n",
    "               max_train=1e7,\n",
    "               test_ids='icassp',\n",
    "               test_seq_len='1 3 5 9 11 19',\n",
    "               k_probe=20,\n",
    "               display_interval=5):\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Segment/sequence-wise audio search experiment and evaluation: implementation based on FAISS.\n",
    "\n",
    "ex) python eval.py EMB_DIR --index_type ivfpq\n",
    "\n",
    "EMB_DIR: Directory where {query, db, dummy_db}.mm files are located. The 'raw_score.npy' and 'test_ids.npy' will be also created in the same directory.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_len = np.asarray(\n",
    "    list(map(int, test_seq_len.split())))  # '1 3 5' --> [1, 3, 5]\n",
    "#'11' -> array([11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./logs/emb/Checks_test_generate/100/'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 29,500 items from \u001b[32m./logs/emb/Checks_test_generate/100/query.mm\u001b[0m.\n",
      "Load 29,500 items from \u001b[32m./logs/emb/Checks_test_generate/100/db.mm\u001b[0m.\n",
      "Load 53,754,198 items from \u001b[32m./logs/emb/Checks_test_generate/100/dummy_db.mm\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "# Load items from {query, db, dummy_db}\n",
    "query, query_shape = load_memmap_data(emb_dir, 'query')\n",
    "db, db_shape = load_memmap_data(emb_dir, 'db')\n",
    "if emb_dummy_dir is None:\n",
    "    emb_dummy_dir = emb_dir\n",
    "dummy_db, dummy_db_shape = load_memmap_data(emb_dummy_dir, 'dummy_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" ----------------------------------------------------------------------\\nFAISS index setup\\n\\n    dummy: 10 items.\\n    db: 5 items.\\n    query: 5 items, corresponding to 'db'.\\n\\n    index.add(dummy_db); index.add(db) # 'dummy_db' first\\n\\n            |------ dummy_db ------|\\n    index: [d0, d1, d2,..., d8, d9, d11, d12, d13, d14, d15]\\n                                    |--------- db ----------|\\n\\n                                    |--------query ---------|\\n                                    [q0,  q1,  q2,  q3,  q4]\\n\\n• The set of ground truth IDs for q[i] will be (i + len(dummy_db))\\n\\n---------------------------------------------------------------------- \""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ----------------------------------------------------------------------\n",
    "FAISS index setup\n",
    "\n",
    "    dummy: 10 items.\n",
    "    db: 5 items.\n",
    "    query: 5 items, corresponding to 'db'.\n",
    "\n",
    "    index.add(dummy_db); index.add(db) # 'dummy_db' first\n",
    "\n",
    "            |------ dummy_db ------|\n",
    "    index: [d0, d1, d2,..., d8, d9, d11, d12, d13, d14, d15]\n",
    "                                    |--------- db ----------|\n",
    "\n",
    "                                    |--------query ---------|\n",
    "                                    [q0,  q1,  q2,  q3,  q4]\n",
    "\n",
    "• The set of ground truth IDs for q[i] will be (i + len(dummy_db))\n",
    "\n",
    "---------------------------------------------------------------------- \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train FAISS index\n",
    "index = get_index(index_type, dummy_db, dummy_db.shape, (not nogpu), max_train)\n",
    "\n",
    "# Add items to index\n",
    "start_time = time.time()\n",
    "\n",
    "index.add(dummy_db); print(f'{len(dummy_db)} items from dummy DB')\n",
    "index.add(db); print(f'{len(db)} items from reference DB')\n",
    "\n",
    "t = time.time() - start_time\n",
    "print(f'Added total {index.ntotal} items to DB. {t:>4.2f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ----------------------------------------------------------------------\n",
    "We need to prepare a merged {dummy_db + db} memmap:\n",
    "\n",
    "• Calcuation of sequence-level matching score requires reconstruction of\n",
    "    vectors from FAISS index.\n",
    "• Unforunately, current faiss.index.reconstruct_n(id_start, id_stop)\n",
    "    supports only CPU index.\n",
    "• We prepare a fake_recon_index thourgh the on-disk method.\n",
    "\n",
    "---------------------------------------------------------------------- \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fake_recon_index, total 53783698 items. 0.06 sec.\n"
     ]
    }
   ],
   "source": [
    "# Prepare fake_recon_index\n",
    "del dummy_db\n",
    "start_time = time.time()\n",
    "\n",
    "fake_recon_index, index_shape = load_memmap_data(\n",
    "    emb_dummy_dir, 'dummy_db', append_extra_length=query_shape[0],\n",
    "    display=False)\n",
    "fake_recon_index[dummy_db_shape[0]:dummy_db_shape[0] + query_shape[0], :] = db[:, :]\n",
    "fake_recon_index.flush()\n",
    "\n",
    "t = time.time() - start_time\n",
    "print(f'Created fake_recon_index, total {index_shape[0]} items. {t:>4.2f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_id: \u001b[93micassp\u001b[0m,  n_test: \u001b[93m2000\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get test_ids\n",
    "print(f'test_id: \\033[93m{test_ids}\\033[0m,  ', end='')\n",
    "if test_ids.lower() == 'all':\n",
    "    test_ids = np.arange(0, len(query) - max(test_seq_len), 1) # will test all segments in query/db set\n",
    "elif test_ids.lower() == 'icassp':\n",
    "    test_ids = np.load(\n",
    "        glob.glob('./**/test_ids_icassp2021.npy', recursive=True)[0])\n",
    "elif test_ids.isnumeric():\n",
    "    test_ids = np.random.permutation(len(query) - max(test_seq_len))[:int(test_ids)]\n",
    "else:\n",
    "    test_ids = np.load(test_ids)\n",
    "\n",
    "n_test = len(test_ids)\n",
    "gt_ids  = test_ids + dummy_db_shape[0]\n",
    "print(f'n_test: \\033[93m{n_test:n}\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Segement/sequence-level search & evaluation \"\"\"\n",
    "# Define metric\n",
    "top1_exact = np.zeros((n_test, len(test_seq_len))).astype(int) # (n_test, test_seg_len)\n",
    "top1_near = np.zeros((n_test, len(test_seq_len))).astype(int)\n",
    "top3_exact = np.zeros((n_test, len(test_seq_len))).astype(int)\n",
    "top10_exact = np.zeros((n_test, len(test_seq_len))).astype(int)\n",
    "# top1_song = np.zeros((n_test, len(test_seq_len))).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[mti=0\n",
      "test_id=14655\n",
      "gt_id=53768853\n",
      "si=0\n",
      "sl=11\n",
      "q=[[ 0.10253137 -0.00045375  0.0620372  ... -0.11246537 -0.10671374\n",
      "  -0.05634388]\n",
      " [ 0.04767687 -0.07006861  0.08062644 ... -0.19844265 -0.02969167\n",
      "  -0.00992421]\n",
      " [ 0.03126371 -0.05754444  0.11367033 ... -0.15368056  0.01969014\n",
      "   0.07624688]\n",
      " ...\n",
      " [-0.05556197 -0.0404008   0.00360346 ... -0.13998988 -0.11149226\n",
      "   0.001388  ]\n",
      " [ 0.05866905 -0.00876279 -0.04984107 ... -0.08355431 -0.0883724\n",
      "  -0.08032892]\n",
      " [ 0.16766731  0.01832582 -0.09314838 ... -0.03284546 -0.08796763\n",
      "  -0.05063683]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# segment-level top k search for each segment\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m _, I \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241m.\u001b[39msearch(q, k_probe) \u001b[38;5;66;03m# _: distance, I: result IDs matrix\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# offset compensation to get the start IDs of candidate sequences\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m offset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(I)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "scr = curses.initscr()\n",
    "pt = PrintTable(scr=scr, test_seq_len=test_seq_len,\n",
    "                row_names=['Top1 exact', 'Top1 near', 'Top3 exact','Top10 exact'])\n",
    "start_time = time.time()\n",
    "for ti, test_id in enumerate(test_ids):\n",
    "    print(f\"ti={ti}\")\n",
    "    print(f\"test_id={test_id}\")\n",
    "    gt_id = gt_ids[ti]\n",
    "    print(f\"gt_id={gt_id}\")\n",
    "    for si, sl in enumerate(test_seq_len):\n",
    "        print(f\"si={si}\")\n",
    "        print(f\"sl={sl}\")\n",
    "        assert test_id <= len(query)\n",
    "        q = query[test_id:(test_id + sl), :] # shape(q) = (length, dim)\n",
    "        print(f\"q={q}\")\n",
    "\n",
    "        # segment-level top k search for each segment\n",
    "        _, I = index.search(q, k_probe) # _: distance, I: result IDs matrix\n",
    "\n",
    "        # offset compensation to get the start IDs of candidate sequences\n",
    "        for offset in range(len(I)):\n",
    "            I[offset, :] -= offset\n",
    "\n",
    "        # unique candidates\n",
    "        candidates = np.unique(I[np.where(I >= 0)])   # ignore id < 0\n",
    "\n",
    "        \"\"\" Sequence match score \"\"\"\n",
    "        _scores = np.zeros(len(candidates))\n",
    "        for ci, cid in enumerate(candidates):\n",
    "            _scores[ci] = np.mean(\n",
    "                np.diag(\n",
    "                    # np.dot(q, index.reconstruct_n(cid, (cid + l)).T)\n",
    "                    np.dot(q, fake_recon_index[cid:cid + sl, :].T)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        \"\"\" Evaluate \"\"\"\n",
    "        pred_ids = candidates[np.argsort(-_scores)[:10]]\n",
    "        # pred_id = candidates[np.argmax(_scores)] <-- only top1-hit\n",
    "\n",
    "        # top1 hit\n",
    "        top1_exact[ti, si] = int(gt_id == pred_ids[0])\n",
    "        top1_near[ti, si] = int(\n",
    "            pred_ids[0] in [gt_id - 1, gt_id, gt_id + 1])\n",
    "        # top1_song = need song info here...\n",
    "\n",
    "        # top3, top10 hit\n",
    "        top3_exact[ti, si] = int(gt_id in pred_ids[:3])\n",
    "        top10_exact[ti, si] = int(gt_id in pred_ids[:10])\n",
    "\n",
    "\n",
    "    if (ti != 0) & ((ti % display_interval) == 0):\n",
    "        avg_search_time = (time.time() - start_time) / display_interval \\\n",
    "            / len(test_seq_len)\n",
    "        top1_exact_rate = 100. * np.mean(top1_exact[:ti + 1, :], axis=0)\n",
    "        top1_near_rate = 100. * np.mean(top1_near[:ti + 1, :], axis=0)\n",
    "        top3_exact_rate = 100. * np.mean(top3_exact[:ti + 1, :], axis=0)\n",
    "        top10_exact_rate = 100. * np.mean(top10_exact[:ti + 1, :], axis=0)\n",
    "        # top1_song = 100 * np.mean(tp_song[:ti + 1, :], axis=0)\n",
    "\n",
    "        pt.update_counter(ti, n_test, avg_search_time * 1000.)\n",
    "        pt.update_table((top1_exact_rate, top1_near_rate, top3_exact_rate,\n",
    "                            top10_exact_rate))\n",
    "        start_time = time.time() # reset stopwatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "top1_exact_rate = 100. * np.mean(top1_exact, axis=0)\n",
    "top1_near_rate = 100. * np.mean(top1_near, axis=0)\n",
    "top3_exact_rate = 100. * np.mean(top3_exact, axis=0)\n",
    "top10_exact_rate = 100. * np.mean(top10_exact, axis=0)\n",
    "# top1_song = 100 * np.mean(top1_song[:ti + 1, :], axis=0)\n",
    "\n",
    "pt.update_counter(ti, n_test, avg_search_time * 1000.)\n",
    "pt.update_table((top1_exact_rate, top1_near_rate, top3_exact_rate, top10_exact_rate))\n",
    "pt.close_table() # close table and print summary\n",
    "del fake_recon_index, query, db\n",
    "np.save(f'{emb_dir}/raw_score.npy',\n",
    "        np.concatenate(\n",
    "            (top1_exact, top1_near, top3_exact, top10_exact), axis=1))\n",
    "np.save(f'{emb_dir}/test_ids.npy', test_ids)\n",
    "print(f'Saved test_ids and raw score to {emb_dir}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nogpu:\n",
    "    eval_faiss([emb_dir, \"--index_type\", index_type, \"--test_seq_len\",\n",
    "                test_seq_len, \"--test_ids\", test_ids, \"--nogpu\"])\n",
    "else:\n",
    "    eval_faiss([emb_dir, \"--index_type\", index_type, \"--test_seq_len\",\n",
    "                test_seq_len, \"--test_ids\", test_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(checkpoint_name, checkpoint_index, config, index_type,\n",
    "             test_seq_len, test_ids, nogpu):\n",
    "    \"\"\" Search and evalutation.\n",
    "\n",
    "    ex) python run.py evaluate CHECKPOINT_NAME CHECKPOINT_INDEX\n",
    "\n",
    "    With options: \\b\\n\n",
    "\n",
    "    ex) python run.py evaluate CHECKPOINT_NAME CHEKPOINT_INDEX -i ivfpq -t 3000 --nogpu\n",
    "\n",
    "\n",
    "    • Currently, the 'evaluate' command does not reference any information other\n",
    "    than the output log directory from the config file.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    if nogpu:\n",
    "        eval_faiss([emb_dir, \"--index_type\", index_type, \"--test_seq_len\",\n",
    "                    test_seq_len, \"--test_ids\", test_ids, \"--nogpu\"])\n",
    "    else:\n",
    "        eval_faiss([emb_dir, \"--index_type\", index_type, \"--test_seq_len\",\n",
    "                    test_seq_len, \"--test_ids\", test_ids])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
