{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaad829c-3406-4fca-b521-3d3323ae7981",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Trainer**\n",
    "\n",
    "**Notas -** ver como funciona:\n",
    "- L2-normalization.\n",
    "- Hilbert space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c762d21-1e9b-411e-bd36-d2114e052211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\"\"\" trainer.py \"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from model.dataset import Dataset\n",
    "from model.fp.melspec.melspectrogram import get_melspec_layer\n",
    "from model.fp.specaug_chain.specaug_chain import get_specaug_chain_layer\n",
    "from model.fp.nnfp import get_fingerprinter\n",
    "from model.fp.NTxent_loss_single_gpu import NTxentLoss\n",
    "from model.fp.online_triplet_loss import OnlineTripletLoss\n",
    "from model.fp.lamb_optimizer import LAMB\n",
    "from model.utils.experiment_helper import ExperimentHelper\n",
    "from model.utils.mini_search_subroutines import mini_search_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640158c4-d3f2-4bc0-b093-7f5b311754dd",
   "metadata": {},
   "source": [
    "## **Build Fingerprinter**\n",
    "- ***m_pre*** is log-power-Mel-spectogram layer (S).\n",
    "    - As a first step, input audio X is converted to time-frequency representation S.\n",
    "    - To calculate the log Mel spectogram:\n",
    "        <br>The function needs the follow variables: *fs*, *dur*, *n_fft*, *stft_hop*, *n_mels*, *f_min*, *f_max*. These things are in *cfg*.\n",
    "- ***m_specaug*** is spec-augmentation layer.\n",
    "    - Cutout and Spec-augment are applied after extracting log-power Mel-spectrogram features, such that {$s^{org}, s^{rep}$}. Unlike other augmentations, we uniformly apply a **batch-wise** random mask to all examples in a batch including $s^{org}$. The size and position of each rectangle/vertical/horizontal mask is random in the range [1/10, 1/2] the length of each time/frequency axis.\n",
    "- ***m_fp*** is fingerprinter *g(f(.))*\n",
    "    - It is then fed into convolutional encoder $f(.)$. Finally, L2-normalization is applied to its output through a linear projection layer $g(.)$. Thus, we employ $g ◦ f : S → \\mathcal{Z}^d$ as a segment-wise encoder that transforms S into d-dimensional fingerprint embedding space $\\mathcal{Z}^d$. The d-dimensional output space $\\mathcal{Z}^d$ always belongs to *Hilbert* space $L^2(\\mathbb{R}^d)$: the cosine similarity of a pair unit such as cos($z_a$, $z_b$) becomes inner-product $z_a^Tz_b$.\n",
    "    <br>The $g◦f(.)$ described here can be interpreted as a reorganization of the previous audio fingerprinting networks [7] into the common form employed in self-supervised learning (SSL) [14–17]. However, our approach differs from the typical SSL that throws $g(.)$ away before fine-tuning for the target task: we maintain the self-supervised $g(.)$ up to the final target task.\n",
    "    \n",
    "Note: References [7] and [14-17] are in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e12b01b-d051-43d5-8e58-5ca659119d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_specaug: spec-augmentation layer.\n",
    "    m_specaug = get_specaug_chain_layer(cfg, trainable=False)\n",
    "    assert(m_specaug.bypass==False) # Detachable by setting m_specaug.bypass.\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_specaug, m_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f4f61-03c7-45d3-bf24-f4683a3a39d4",
   "metadata": {},
   "source": [
    "## **Train step**\n",
    "A mini-batch with the size of N consists of N/2 pairs of $\\{s^{org}, s^{rep}\\}$. $s^{org}$ is the time-frequency representation of sampled audio and $s^{rep}$ is the augmented replica of $s^{org}$, where $s^{rep} = M_\\alpha(s^{org})$. $M_{\\alpha}$ is an ordered augmentation chain that consists of multiple augmentors with the random parameter set $\\alpha$ for each replica. In this configuration, the indices of original examples are always odd, and that of replicas are even. Therefore, the batchwise output of $f ◦ g(s)$ can be $\\{z^{org}_{2k−1}, z^{rep}_{2k}\\}^{2/N}_{k=1}$.\n",
    "Anchors are a reference points chosen to be compared with others points inside of the same mini-batch - calculate by Batch_size/2.\n",
    "<br><br>train_step tem como argumentos: X (dados para treino), m_pre (os espetrogramas mel pré-calculados), m_specaug (a cadeia de aumento espetral dos dados), m_fp (dados fp), loss_obj (objeto de loss que calcula a loss entre os embeddings dos exemplos originais e replicados) e helper (para ajudar na atualização da loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b05af6-7d92-48fb-b01f-8613742a3dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(X, m_pre, m_specaug, m_fp, loss_obj, helper):\n",
    "    \"\"\" Train step \"\"\"\n",
    "    # X: (Xa, Xp)\n",
    "    # Xa: anchors or originals, s.t. [xa_0, xa_1,...]\n",
    "    # Xp: augmented replicas, s.t. [xp_0, xp_1] with xp_n = rand_aug(xa_n).\n",
    "    n_anchors = len(X[0])\n",
    "    X = tf.concat(X, axis=0)\n",
    "    feat = m_specaug(m_pre(X))  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = True\n",
    "    with tf.GradientTape() as t:\n",
    "        emb = m_fp(feat)  # (BSZ, Dim)\n",
    "        loss, sim_mtx, _ = loss_obj.compute_loss(\n",
    "            emb[:n_anchors, :], emb[n_anchors:, :]) # {emb_org, emb_rep}\n",
    "    g = t.gradient(loss, m_fp.trainable_variables)\n",
    "    helper.optimizer.apply_gradients(zip(g, m_fp.trainable_variables))\n",
    "    avg_loss = helper.update_tr_loss(loss) # To tensorboard.\n",
    "    return avg_loss, sim_mtx # avg_loss: average within the current epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303b283-dc6e-48a5-af2f-0569a920fa34",
   "metadata": {},
   "source": [
    "Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce2324-751d-44a1-aeaf-11710fdcb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(X, m_pre, m_fp, loss_obj, helper):\n",
    "    \"\"\" Validation step \"\"\"\n",
    "    n_anchors = len(X[0])\n",
    "    X = tf.concat(X, axis=0)\n",
    "    feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = False\n",
    "    emb = m_fp(feat)  # (BSZ, Dim)\n",
    "    loss, sim_mtx, _ = loss_obj.compute_loss(\n",
    "        emb[:n_anchors, :], emb[n_anchors:, :]) # {emb_org, emb_rep}\n",
    "    avg_loss = helper.update_val_loss(loss) # To tensorboard.\n",
    "    return avg_loss, sim_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7983e93e-b96c-4be5-8791-1d18571a629f",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e779655-27b6-4f31-ac2b-0afde9108657",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(X, m_pre, m_fp):\n",
    "    \"\"\" Test step used for mini-search-validation \"\"\"\n",
    "    X = tf.concat(X, axis=0)\n",
    "    feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = False\n",
    "    emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)\n",
    "    emb_f_postL2 = tf.math.l2_normalize(emb_f, axis=1)\n",
    "    emb_gf = m_fp.div_enc(emb_f)\n",
    "    emb_gf = tf.math.l2_normalize(emb_gf, axis=1)\n",
    "    return emb_f, emb_f_postL2, emb_gf # f(.), L2(f(.)), L2(g(f(.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89279d-4cf4-4a3b-bf28-9478c42d334f",
   "metadata": {},
   "source": [
    "### Mini search validation\n",
    "Exemplo:\n",
    "<br> ======= mini-search-validation: argmin f =======\n",
    "<br> Scope:\t   1   \t  3   \t  5   \t  9   \t  11  \t  19  \t \n",
    "<br> T1acc:\t 0.07\t0.07\t0.07\t0.07\t0.07\t0.07\t\n",
    "<br> mRank:\t 749.50\t748.50\t747.50\t745.50\t744.50\t740.50\t\n",
    "<br> ======= mini-search-validation: argmin L2(f) =======\n",
    "<br> Scope:\t   1   \t  3   \t  5   \t  9   \t  11  \t  19  \t \n",
    "<br> T1acc:\t 0.07\t0.07\t0.07\t0.07\t0.07\t0.07\t\n",
    "<br> mRank:\t 749.50\t748.50\t747.50\t745.50\t744.50\t740.50\t\n",
    "<br> ======= mini-search-validation: argmin g(f) =======\n",
    "<br> Scope:\t   1   \t  3   \t  5   \t  9   \t  11  \t  19  \t \n",
    "<br> T1acc:\t 0.07\t0.07\t0.07\t0.07\t0.07\t0.07\t\n",
    "<br> mRank:\t 749.50\t748.50\t747.50\t745.50\t744.50\t740.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde2c5e-69fd-4507-a1ce-0b220159f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_search_validation(ds, m_pre, m_fp, mode='argmin',\n",
    "                           scopes=[1, 3, 5, 9, 11, 19], max_n_samples=3000):\n",
    "    \"\"\" Mini-search-validation \"\"\"\n",
    "    # Construct mini-DB\n",
    "    key_strs = ['f', 'L2(f)', 'g(f)']\n",
    "    m_fp.trainable = False\n",
    "    (db, query, emb, dim) = (dict(), dict(), dict(), dict())\n",
    "    dim['f'] = dim['L2(f)'] = m_fp.front_hidden_ch[-1]\n",
    "    dim['g(f)'] = m_fp.emb_sz\n",
    "    bsz = ds.bsz\n",
    "    n_anchor = bsz // 2\n",
    "    n_iter = min(len(ds), max_n_samples // bsz)\n",
    "    for k in key_strs:\n",
    "        (db[k], query[k]) = (tf.zeros((0, dim[k])), tf.zeros((0, dim[k])))\n",
    "    for i in range(n_iter):\n",
    "        X = ds.__getitem__(i)\n",
    "        emb['f'], emb['L2(f)'], emb['g(f)'] = test_step(X, m_pre, m_fp)\n",
    "        for k in key_strs:\n",
    "            db[k] = tf.concat((db[k], emb[k][:n_anchor, :]), axis=0)\n",
    "            query[k] = tf.concat((query[k], emb[k][n_anchor:, :]), axis=0)\n",
    "\n",
    "    # Search test\n",
    "    accs_by_scope = dict()\n",
    "    for k in key_strs:\n",
    "        tf.print(f'======= mini-search-validation: \\033[31m{mode} \\033[33m{k} \\033[0m=======' + '\\033[0m')\n",
    "        query[k] = tf.expand_dims(query[k], axis=1) # (nQ, d) --> (nQ, 1, d)\n",
    "        accs_by_scope[k], _ = mini_search_eval(\n",
    "            query[k], db[k], scopes, mode, display=True)\n",
    "    return accs_by_scope, scopes, key_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c81e27-5133-4961-b0e3-50b6a65bff19",
   "metadata": {},
   "source": [
    "## **Trainer**\n",
    "Firstly, it loads the dataset. Where *cfg* is a dictionary contains configurations.\n",
    "After that, build the model calling *build_fp* function on the way to return *m_pre*, *m_specaug*, *m_fp*.\n",
    "\n",
    "<br> Learning rate: explicação.\n",
    "<br> Função de otimização: Adam\n",
    "- ```tf.keras.optimizers.Adam```: Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
    "- They trained the model using LAMB optimizer, which performed 2 pp better than Adam with the 3 s query sequence for batch size N ≥ 320. In practice, Adam worked better only for N ≤ 240. The learning rate had an initial value of 1e-4·N/640 with cosine decay without warmup or restarts, then it reached a minimum value of 1-e7 in 100 epochs.\n",
    "\n",
    "<br> Função de Loss: NTXENT\n",
    "- $l(i,j) = -log \\frac{exp(a_{i,j}/\\tau)}{\\mathbb{1} \\sum_{k=1}^{N}(k\\neq i)exp(a_{i,j}/\\tau)}$\n",
    "    - Onde, $\\mathbb{1} \\epsilon \\{0,1\\}$ is an indicator function that returns 1 iff(.) is true, and $\\tau > 0$ denotes the temperature parameter for softmax. The Equation is employed to replace MIPS from the property: computing the top-k (k=1 in our setup) predictions in the softmax function is equivalent to the MIPS.\n",
    "- De acordo com https://towardsdatascience.com/nt-xent-normalized-temperature-scaled-cross-entropy-loss-explained-and-implemented-in-pytorch-cc081f69848.\n",
    "    - At a high level, the contrastive learning model is fed 2N images, originating from N underlying images. Each of the N underlying images is augmented using a random set of image augmentations to produce 2 augmented images.\n",
    "    - For SoftMax: A low temperature increases the variance in the output distribution and makes the maximum value stand out over the other values. (Our value $\\tau = 0.05$).\n",
    "    - Pares positivos vs pares negativos:\n",
    "        - Pares positivos derivam da mesma imagem no processo de Augmentation.\n",
    "        - Pares negativos não derivam da mesma imagem.\n",
    "    \n",
    "<br> \n",
    "<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8ee3d-76db-4d84-80f5-e26dcc5a7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(cfg, checkpoint_name):\n",
    "    # Dataloader\n",
    "    dataset = Dataset(cfg)\n",
    "\n",
    "    # Build models.\n",
    "    m_pre, m_specaug, m_fp = build_fp(cfg)\n",
    "\n",
    "    # Learning schedule\n",
    "    total_nsteps = cfg['TRAIN']['MAX_EPOCH'] * len(dataset.get_train_ds())\n",
    "    if cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS':\n",
    "        lr_schedule = tf.keras.experimental.CosineDecay(\n",
    "            initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "            decay_steps=total_nsteps,\n",
    "            alpha=1e-06)\n",
    "    elif cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS-RESTART':\n",
    "        lr_schedule = tf.keras.experimental.CosineDecayRestarts(\n",
    "            initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "            first_decay_steps=int(total_nsteps * 0.1),\n",
    "            num_periods=0.5,\n",
    "            alpha=2e-06)\n",
    "    else:\n",
    "        lr_schedule = float(cfg['TRAIN']['LR'])\n",
    "\n",
    "    # Optimizer\n",
    "    if cfg['TRAIN']['OPTIMIZER'].upper() == 'LAMB':\n",
    "        opt = LAMB(learning_rate=lr_schedule)\n",
    "    elif cfg['TRAIN']['OPTIMIZER'].upper() == 'ADAM':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['TRAIN']['OPTIMIZER'])\n",
    "\n",
    "    # Experiment helper: see utils.experiment_helper.py for details.\n",
    "    helper = ExperimentHelper(\n",
    "        checkpoint_name=checkpoint_name,\n",
    "        optimizer=opt,\n",
    "        model_to_checkpoint=m_fp,\n",
    "        cfg=cfg)\n",
    "\n",
    "    # Loss objects\n",
    "    if cfg['LOSS']['LOSS_MODE'].upper() == 'NTXENT': # Default\n",
    "        loss_obj_train = NTxentLoss(\n",
    "            n_org=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            n_rep=cfg['BSZ']['TR_BATCH_SZ'] - cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            tau=cfg['LOSS']['TAU'])\n",
    "        loss_obj_val = NTxentLoss(\n",
    "            n_org=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            n_rep=cfg['BSZ']['VAL_BATCH_SZ'] - cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            tau=cfg['LOSS']['TAU'])\n",
    "    elif cfg['LOSS']['LOSS_MODE'].upper() == 'ONLINE-TRIPLET': # Now-playing\n",
    "        loss_obj_train = OnlineTripletLoss(\n",
    "            bsz=cfg['BSZ']['TR_BATCH_SZ'],\n",
    "            n_anchor=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            mode = 'semi-hard',\n",
    "            margin=cfg['LOSS']['MARGIN'])\n",
    "        loss_obj_val = OnlineTripletLoss(\n",
    "            bsz=cfg['BSZ']['VAL_BATCH_SZ'],\n",
    "            n_anchor=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            mode = 'all', # use 'all' mode for validation\n",
    "            margin=0.)\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['LOSS']['LOSS_MODE'])\n",
    "\n",
    "    # Training loop\n",
    "    ep_start = helper.epoch\n",
    "    ep_max = cfg['TRAIN']['MAX_EPOCH']\n",
    "    for ep in range(ep_start, ep_max + 1):\n",
    "        tf.print(f'EPOCH: {ep}/{ep_max}')\n",
    "\n",
    "        # Train\n",
    "        \"\"\" Parallelism to speed up preprocessing.............. \"\"\"\n",
    "        train_ds = dataset.get_train_ds(cfg['DATA_SEL']['REDUCE_ITEMS_P'])\n",
    "        progbar = Progbar(len(train_ds))\n",
    "        enq = tf.keras.utils.OrderedEnqueuer(\n",
    "            train_ds, use_multiprocessing=True, shuffle=train_ds.shuffle)\n",
    "        enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "                  max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "        i = 0\n",
    "        while i < len(enq.sequence):\n",
    "            X = next(enq.get()) # X: Tuple(Xa, Xp)\n",
    "            avg_loss, sim_mtx = train_step(X, m_pre, m_specaug, m_fp,\n",
    "                                            loss_obj_train, helper)\n",
    "            progbar.add(1, values=[(\"tr loss\", avg_loss)])\n",
    "            i += 1\n",
    "        enq.stop()\n",
    "        \"\"\" End of Parallelism................................. \"\"\"\n",
    "\n",
    "        if cfg['TRAIN']['SAVE_IMG'] and (sim_mtx is not None):\n",
    "            helper.write_image_tensorboard('tr_sim_mtx', sim_mtx.numpy())\n",
    "\n",
    "        # Validate\n",
    "        \"\"\" Parallelism to speed up preprocessing.............. \"\"\"\n",
    "        val_ds = dataset.get_val_ds(max_song=250) # max 500\n",
    "        enq = tf.keras.utils.OrderedEnqueuer(\n",
    "            val_ds, use_multiprocessing=True, shuffle=False)\n",
    "        enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "                  max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "        i = 0\n",
    "        while i < len(enq.sequence):\n",
    "            X = next(enq.get()) # X: Tuple(Xa, Xp)\n",
    "            _, sim_mtx = val_step(X, m_pre, m_fp, loss_obj_val,\n",
    "                                  helper)\n",
    "            i += 1\n",
    "        enq.stop()\n",
    "        \"\"\" End of Parallelism................................. \"\"\"\n",
    "\n",
    "        if cfg['TRAIN']['SAVE_IMG'] and (sim_mtx is not None):\n",
    "            helper.write_image_tensorboard('val_sim_mtx', sim_mtx.numpy())\n",
    "\n",
    "        # On epoch end\n",
    "        tf.print('tr_loss:{:.4f}, val_loss:{:.4f}'.format(\n",
    "            helper._tr_loss.result(), helper._val_loss.result()))\n",
    "        helper.update_on_epoch_end(save_checkpoint_now=True)\n",
    "\n",
    "\n",
    "        # Mini-search-validation (optional)\n",
    "        if cfg['TRAIN']['MINI_TEST_IN_TRAIN']:\n",
    "            accs_by_scope, scopes, key_strs = mini_search_validation(\n",
    "                val_ds, m_pre, m_fp)\n",
    "            for k in key_strs:\n",
    "                helper.update_minitest_acc(accs_by_scope[k], scopes, k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
