{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 14:22:21.141783: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import click\n",
    "import curses\n",
    "import pathlib\n",
    "import yaml\n",
    "import faiss\n",
    "import wave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from eval_RA.utils.get_index_faiss import get_index\n",
    "from eval_RA.utils.print_table import PrintTable\n",
    "\n",
    "from model_RA.fp_RA.melspec.melspectrogram_RA import get_melspec_layer\n",
    "from model_RA.fp_RA.nnfp import get_fingerprinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default_RA.yaml\n"
     ]
    }
   ],
   "source": [
    "config = \"default_RA\"\n",
    "cfg = load_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memmap_data(source_dir,\n",
    "                     fname,\n",
    "                     append_extra_length=None,\n",
    "                     shape_only=False,\n",
    "                     display=True):\n",
    "\n",
    "    path_shape = source_dir + fname + '_shape.npy'\n",
    "    path_data = source_dir + fname + '.mm'\n",
    "    data_shape = np.load(path_shape)\n",
    "    if shape_only:\n",
    "        return data_shape\n",
    "\n",
    "    if append_extra_length:\n",
    "        data_shape[0] += append_extra_length\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r+',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    else:\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    if display:\n",
    "        print(f'Load {data_shape[0]:,} items from \\033[32m{path_data}\\033[0m.')\n",
    "    return data, data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsDir = '/mnt/dev/rodrigoalmeida/neural-audio-fp/logs/emb/CHECK_BFTRI_100/101'\n",
    "emb_dir = logsDir + '/'\n",
    "\n",
    "emb_dummy_dir = None\n",
    "index_type='ivfpq'\n",
    "nogpu=False\n",
    "k_probe=1\n",
    "display_interval=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 29,500 items from \u001b[32m/mnt/dev/rodrigoalmeida/neural-audio-fp/logs/emb/CHECK_BFTRI_100/101/db.mm\u001b[0m.\n",
      "Load 53,754,198 items from \u001b[32m/mnt/dev/rodrigoalmeida/neural-audio-fp/logs/emb/CHECK_BFTRI_100/101/dummy_db.mm\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "db, db_shape = load_memmap_data(emb_dir, 'db')\n",
    "\n",
    "if emb_dummy_dir is None:\n",
    "    emb_dummy_dir = emb_dir\n",
    "\n",
    "dummy_db, dummy_db_shape = load_memmap_data(emb_dummy_dir, 'dummy_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53754198, 128) [53754198      128] (29500, 128) [29500   128]\n"
     ]
    }
   ],
   "source": [
    "print(dummy_db.shape, dummy_db_shape, db.shape, db_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(dummy_db, dummy_db_shape):\n",
    "    #d = dummy_db_shape[1]\n",
    "\n",
    "    # Build a flat (CPU) index\n",
    "    index = faiss.IndexFlatL2(128) #\n",
    "\n",
    "    index_type = 'ivfpq'\n",
    "    mode = index_type.lower()\n",
    "    print(f'Creating index: \\033[93m{mode}\\033[0m')\n",
    "\n",
    "    # Using IVF-PQ index\n",
    "    code_sz = 64 # power of 2\n",
    "    n_centroids = 256#\n",
    "    nbits = 8  # nbits must be 8, 12 or 16, The dimension d should be a multiple of M.\n",
    "    index = faiss.IndexIVFPQ(index, 128, n_centroids, code_sz, nbits)\n",
    "\n",
    "    train_data = dummy_db\n",
    "    max_train=1e7\n",
    "    max_nitem_train = int(max_train)\n",
    "\n",
    "    # Train index\n",
    "\n",
    "    if len(train_data) > max_nitem_train:\n",
    "        print('Training index using {:>3.2f} % of data...'.format(\n",
    "            100. * max_nitem_train / len(train_data)))\n",
    "        # shuffle and reduce training data\n",
    "        sel_tr_idx = np.random.permutation(len(train_data))\n",
    "        sel_tr_idx = sel_tr_idx[:max_nitem_train]\n",
    "        index.train(train_data[sel_tr_idx,:])\n",
    "\n",
    "    index.nprobe = 40\n",
    "    print(f\"index trained: {index.is_trained}\")\n",
    "\n",
    "    #index.add(dummy_db); print(f'{len(dummy_db)} items from dummy DB')\n",
    "    #index.add(db); print(f'{len(db)} items from reference DB') #corresponde aos que estão verdadeiros e iguais ao query_db\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index: \u001b[93mivfpq\u001b[0m\n",
      "Training index using 18.60 % of data...\n",
      "index trained: True\n"
     ]
    }
   ],
   "source": [
    "index = create_index(dummy_db, dummy_db_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53754198 items from dummy DB\n",
      "29500 items from reference DB\n"
     ]
    }
   ],
   "source": [
    "index.add(dummy_db); print(f'{len(dummy_db)} items from dummy DB')\n",
    "index.add(db); print(f'{len(db)} items from reference DB') #corresponde aos que estão verdadeiros e iguais ao query_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo + emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_fp\n",
    "\n",
    "@tf.function\n",
    "def predict(X, m_pre, m_fp):\n",
    "    \"\"\"\n",
    "    X -> (B,1,8000)\n",
    "    \"\"\"\n",
    "    feat = m_pre(X)  # (n, F, T, 1)\n",
    "    m_fp.trainable = False\n",
    "    emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)\n",
    "    emb_gf = m_fp.div_enc(emb_f)\n",
    "    emb_gf = tf.math.l2_normalize(emb_gf, axis=1)\n",
    "    return emb_gf # L2(g(f(.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def load_audio(queryDir):\n",
    "    with wave.open(queryDir, 'rb') as wav_file:\n",
    "        params = wav_file.getparams()\n",
    "        \n",
    "        #parâmetros\n",
    "        nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "        \n",
    "        frames = wav_file.readframes(nframes)\n",
    "        \n",
    "        audio_data = np.frombuffer(frames)\n",
    "        return audio_data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import soundfile as sf\n",
    "def load_audioo(file_path):\n",
    "    audio, _ = sf.read(file_path)\n",
    "    \n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)  # Convertendo para mono se necessário\n",
    "    # Normalizar o áudio\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    return audio\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_info(cfg, database, fs, hop, duration, segment_mode):\n",
    "\n",
    "    #file_seg_list = []\n",
    "    audio_seg_list = []\n",
    "    frames = []\n",
    "    for offset_idx, filename in enumerate(database):\n",
    "        print(filename)\n",
    "        #base_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "\n",
    "        if hop == None: hop = cfg['MODEL']['HOP']\n",
    "\n",
    "        n_frames_in_seg = fs * duration # 8000\n",
    "        n_frames_in_hop = fs * hop # 4000\n",
    "        file_ext = filename[-3:] #para ficar só com 'wav'\n",
    "\n",
    "\n",
    "        if file_ext == 'wav':\n",
    "            pt_wav = wave.open(filename, 'r')\n",
    "            \n",
    "            _fs = pt_wav.getframerate()\n",
    "\n",
    "            if fs != _fs:\n",
    "                raise ValueError('Sample rate should be {} but got {}'.format(\n",
    "                    str(fs), str(_fs)))\n",
    "\n",
    "            n_frames = pt_wav.getnframes()\n",
    "\n",
    "            if n_frames > n_frames_in_seg:\n",
    "                n_segs = (n_frames - n_frames_in_seg +\n",
    "                            n_frames_in_hop) // n_frames_in_hop\n",
    "            else:\n",
    "                n_segs = 1\n",
    "\n",
    "            n_segs = int(n_segs)\n",
    "\n",
    "            #file_seg_list.append([filename, n_segs]) #guardar numa lista o nome do audio e o numero de segmentos que tem. Para depois comparar no faiss\n",
    "            \n",
    "            assert (n_segs > 0)\n",
    "            residual_frames = np.max([\n",
    "                0,\n",
    "                n_frames - ((n_segs - 1) * n_frames_in_hop + n_frames_in_seg)\n",
    "            ])\n",
    "            \n",
    "            i=0\n",
    "            while i in range(n_frames):\n",
    "                frames.append(pt_wav.readframes(i))\n",
    "            pt_wav.close()\n",
    "        else:\n",
    "            raise NotImplementedError(file_ext)\n",
    "        \n",
    "\n",
    "        #guardar os segmentos por ficheiro de áudio\n",
    "        if segment_mode == 'all':\n",
    "            for seg_idx in range(n_segs):\n",
    "                offset_min, offset_max = int(-1 *\n",
    "                                             n_frames_in_hop), n_frames_in_hop\n",
    "                if seg_idx == 0:  # first seg\n",
    "                    offset_min = 0\n",
    "                if seg_idx == (n_segs - 1):  # last seg\n",
    "                    offset_max = residual_frames\n",
    "\n",
    "                audio_seg_list.append(\n",
    "                    [filename, seg_idx, offset_min, offset_max])\n",
    "\n",
    "    \"\"\" \n",
    "    #isto é para fazer quando carrego o ficheiro .h5  \n",
    "    total_segments = 0\n",
    "    for item in file_seg_list:\n",
    "        total_segments += item[1]\n",
    "        item.append(total_segments)\n",
    "    \"\"\" \n",
    "    return audio_seg_list, frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar o query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/test-dummy-db-100k-full/fma_full/000/000003.wav\n"
     ]
    }
   ],
   "source": [
    "queryDir = '/mnt/dataset/public/Fingerprinting/query_procura/000003.wav'\n",
    "m_pre, m_fp = build_fp(cfg)\n",
    "#audio = load_audio(queryDir)\n",
    "#audio = load_audioo(queryDir)\n",
    "\n",
    "source_root_dir = cfg['DIR']['SOURCE_ROOT_DIR']\n",
    "dummy_db = sorted(glob.glob(source_root_dir + 'test-dummy-db-100k-full/' +'**/*.wav', recursive=True))\n",
    "fs = 8000\n",
    "hop = None\n",
    "duration = 1\n",
    "segment_mode:str = 'all'\n",
    "\n",
    "x, framaes = get_audio_info(cfg, dummy_db[:1], fs, hop, duration, segment_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procurar o query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment-level top k search for each segment\n",
    "_, I = index.search(q, k_probe) # _: distance, I: result IDs matri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = query[test_id:(test_id + sl), :] # shape(q) = (length, dim)\n",
    "\n",
    "\n",
    "\n",
    "# offset compensation to get the start IDs of candidate sequences\n",
    "for offset in range(len(I)):\n",
    "    I[offset, :] -= offset\n",
    "\n",
    "# unique candidates\n",
    "candidates = np.unique(I[np.where(I >= 0)])   # ignore id < 0\n",
    "\n",
    "\"\"\" Sequence match score \"\"\"\n",
    "_scores = np.zeros(len(candidates))\n",
    "for ci, cid in enumerate(candidates):\n",
    "    _scores[ci] = np.mean(\n",
    "        np.diag(\n",
    "            # np.dot(q, index.reconstruct_n(cid, (cid + l)).T)\n",
    "            np.dot(q, fake_recon_index[cid:cid + sl, :].T)\n",
    "            )\n",
    "        )\n",
    "\n",
    "\"\"\" Evaluate \"\"\"\n",
    "pred_ids = candidates[np.argsort(-_scores)[:10]]\n",
    "# pred_id = candidates[np.argmax(_scores)] <-- only top1-hit\n",
    "\n",
    "# top1 hit\n",
    "top1_exact[ti, si] = int(gt_id == pred_ids[0])\n",
    "top1_near[ti, si] = int(\n",
    "    pred_ids[0] in [gt_id - 1, gt_id, gt_id + 1])\n",
    "# top1_song = need song info here...\n",
    "\n",
    "\n",
    "#if (ti != 0) & ((ti % display_interval) == 0):\n",
    "#    top1_exact_rate = 100. * np.mean(top1_exact[:ti + 1, :], axis=0)\n",
    "#    top1_near_rate = 100. * np.mean(top1_near[:ti + 1, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nao interessa\n",
    "def split_audio_into_segments(audio, segment_duration=1.0, hop_size=0.5, sample_rate=8000):\n",
    "    segment_samples = int(segment_duration * sample_rate)\n",
    "    hop_samples = int(hop_size * sample_rate)\n",
    "\n",
    "    segments = []\n",
    "    for start in range(0, len(audio) - segment_samples + 1, hop_samples):\n",
    "        segment = audio[start:start + segment_samples]\n",
    "        if len(segment) == segment_samples:\n",
    "            segments.append(segment)\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = []\n",
    "for start in range(0, len(audio) - segment_samples + 1, hop_samples):\n",
    "    segment = audio[start:start + segment_samples]\n",
    "    if len(segment) == segment_samples:\n",
    "        segments.append(segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar audio como no projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_event: [       0        1        2 ... 53754195 53754196 53754197]\n"
     ]
    }
   ],
   "source": [
    "duration=1\n",
    "hop=.5\n",
    "fs=8000\n",
    "seg_mode=\"all\"\n",
    "amp_mode='normal'\n",
    "offset_margin_hop_rate = 0.4\n",
    "reduce_items_p=0\n",
    "reduce_batch_first_half=False\n",
    "experimental_mode=False\n",
    "shuffle=False\n",
    "random_offset_anchor=False\n",
    "drop_the_last_non_full_batch=False # No augmentations...\n",
    "\n",
    "ts_batch_s = _ts_n_anchor = n_anchor = 125\n",
    "\n",
    "#Como bsz == n_anchor, então:\n",
    "n_pos_per_anchor = 0\n",
    "n_pos_bsz = 0\n",
    "\n",
    "offset_margin_frame = int(hop * offset_margin_hop_rate * fs) #1600\n",
    "\n",
    "\n",
    "fns_event_seg_list = x\n",
    "\n",
    "n_samples = len(fns_event_seg_list) # fp-generation #53754198\n",
    "\n",
    "\n",
    "index_event = np.arange(n_samples) #index_event: [ 0 1 2 ... 53754195 53754196 53754197]\n",
    "print(f\"index_event: {index_event}\")\n",
    "\n",
    "\n",
    "assert(reduce_items_p <= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(filename=str(),\n",
    "               seg_start_sec=float(),\n",
    "               offset_sec=0.0,\n",
    "               seg_length_sec=float(),\n",
    "               seg_pad_offset_sec=0.0,\n",
    "               fs=22050,\n",
    "               amp_mode='normal'):\n",
    "    \"\"\"\n",
    "        Open file to get file info --> Calulate index range\n",
    "        --> Load sample by index --> Padding --> Max-Normalize --> Out\n",
    "        \n",
    "    \"\"\"\n",
    "    start_frame_idx = np.floor((seg_start_sec + offset_sec) * fs).astype(int)\n",
    "    seg_length_frame = np.floor(seg_length_sec * fs).astype(int)\n",
    "    end_frame_idx = start_frame_idx + seg_length_frame\n",
    "\n",
    "    # Get file-info\n",
    "    file_ext = filename[-3:]\n",
    "    #print(start_frame_idx, end_frame_idx)\n",
    "\n",
    "    if file_ext == 'wav':\n",
    "        pt_wav = wave.open(filename, 'r')\n",
    "        pt_wav.setpos(start_frame_idx)\n",
    "        x = pt_wav.readframes(end_frame_idx - start_frame_idx)\n",
    "        x = np.frombuffer(x, dtype=np.int16)\n",
    "        x = x / 2**15  # dtype=float\n",
    "    else:\n",
    "        raise NotImplementedError(file_ext)\n",
    "\n",
    "    # padding process. it works only when win_size> audio_size and padding='random'\n",
    "    audio_arr = np.zeros(int(seg_length_sec * fs))\n",
    "    seg_pad_offset_idx = int(seg_pad_offset_sec * fs)\n",
    "    audio_arr[seg_pad_offset_idx:seg_pad_offset_idx + len(x)] = x\n",
    "    return audio_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_multi_start(filename=str(),\n",
    "                           seg_start_sec_list=[],\n",
    "                           seg_length_sec=float(),\n",
    "                           fs=22050,\n",
    "                           amp_mode='normal'):\n",
    "    \n",
    "    \"\"\" Load_audio wrapper for loading audio with multiple start indices. \"\"\"\n",
    "\n",
    "    out = None\n",
    "    for seg_start_sec in seg_start_sec_list:\n",
    "        x = load_audio(filename=filename,\n",
    "                       seg_start_sec=seg_start_sec,\n",
    "                       seg_length_sec=seg_length_sec,\n",
    "                       fs=8000)\n",
    "        x = x.reshape((1, -1))\n",
    "        if out is None:\n",
    "            out = x\n",
    "        else:\n",
    "            out = np.vstack((out, x))\n",
    "    return out  # (B,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __event_batch_load(anchor_idx_list):\n",
    "        \"\"\" Get Xa_batch and Xp_batch for anchor (original) and positive (replica) samples. \"\"\"\n",
    "        Xa_batch = None\n",
    "        Xp_batch = None\n",
    "\n",
    "\n",
    "        for idx in anchor_idx_list:  # idx: index for one sample\n",
    "            pos_start_sec_list = []\n",
    "\n",
    "\n",
    "            # fns_event_seg_list = [[filename, seg_idx, offset_min, offset_max], [ ... ] , ... [ ... ]]\n",
    "            offset_min, offset_max = fns_event_seg_list[idx][\n",
    "                2], fns_event_seg_list[idx][3]\n",
    "            anchor_offset_min = np.max([offset_min, -offset_margin_frame])\n",
    "            anchor_offset_max = np.min([offset_max, offset_margin_frame])\n",
    "            \n",
    "\n",
    "            if (random_offset_anchor == True) & (experimental_mode\n",
    "                                                      == False):\n",
    "                # Usually, we can apply random offset to anchor only in training.\n",
    "                np.random.seed(idx)\n",
    "\n",
    "                # Calculate anchor_start_sec\n",
    "                _anchor_offset_frame = np.random.randint(\n",
    "                    low=anchor_offset_min, high=anchor_offset_max)\n",
    "                _anchor_offset_sec = _anchor_offset_frame / fs\n",
    "                anchor_start_sec = fns_event_seg_list[idx][\n",
    "                    1] * hop + _anchor_offset_sec\n",
    "            else:\n",
    "                _anchor_offset_frame = 0\n",
    "                anchor_start_sec = fns_event_seg_list[idx][1] * hop\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            load audio returns: [anchor, pos1, pos2,..pos_n]\n",
    "            \"\"\"\n",
    "            #print(self.fns_event_seg_list[idx])\n",
    "            start_sec_list = np.concatenate(\n",
    "                ([anchor_start_sec], pos_start_sec_list))\n",
    "            \n",
    "            xs = load_audio_multi_start(fns_event_seg_list[idx][0],\n",
    "                                        start_sec_list,\n",
    "                                        duration,\n",
    "                                        fs,\n",
    "                                        amp_mode)  # xs: ((1+n_pos)),T)\n",
    "\n",
    "            if Xa_batch is None:\n",
    "                Xa_batch = xs[0, :].reshape((1, -1))\n",
    "                Xp_batch = xs[\n",
    "                    1:, :]  # If self.n_pos_per_anchor==0: this produces an empty array\n",
    "            else:\n",
    "                Xa_batch = np.vstack((Xa_batch, xs[0, :].reshape(\n",
    "                    (1, -1))))  # Xa_batch: (n_anchor, T)\n",
    "                Xp_batch = np.vstack(\n",
    "                    (Xp_batch, xs[1:, :]))  # Xp_batch: (n_pos, T)\n",
    "        return Xa_batch, Xp_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(idx):\n",
    "        \"\"\" Get anchor (original) and positive (replica) samples. \"\"\"\n",
    "\n",
    "        index_anchor_for_batch = index_event[idx * n_anchor:(idx + 1) * n_anchor]\n",
    "\n",
    "        Xa_batch, Xp_batch = __event_batch_load(index_anchor_for_batch)\n",
    "\n",
    "\n",
    "        Xa_batch = np.expand_dims(Xa_batch,\n",
    "                                  1).astype(np.float32)  # (n_anchor, 1, T)\n",
    "        Xp_batch = np.expand_dims(Xp_batch,\n",
    "                                  1).astype(np.float32)  # (n_pos, 1, T)\n",
    "        \n",
    "        return Xa_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
