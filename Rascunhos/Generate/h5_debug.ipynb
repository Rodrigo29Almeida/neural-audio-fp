{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import glob\n",
    "import h5py\n",
    "import click\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "#import deepdish as dd\n",
    "import tensorflow as tf\n",
    "\n",
    "from model_RA.fp_RA.melspec.melspectrogram_RA import get_melspec_layer\n",
    "from model_RA.fp_RA.nnfp import get_fingerprinter\n",
    "from model_RA.utils.dataloader_keras import genUnbalSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def load_audio(file_path):\n",
    "    audio, _ = librosa.load(file_path, sr=8000)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_fp\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def embeddingGenerator(X, m_pre, m_fp):\n",
    "    \"\"\" \n",
    "    X -> (B,1,8000)\n",
    "    \"\"\"\n",
    "    #tf.print(f\"X:{X}\")\n",
    "    #feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = False\n",
    "\n",
    "    return m_fp(m_pre(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default_RA.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.InitializationOnlyStatus at 0x7c6a8c5f28e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = \"default_RA\"\n",
    "cfg = load_config(config)\n",
    "\n",
    "dur=cfg['MODEL']['DUR'] \n",
    "hop=cfg['MODEL']['HOP'] \n",
    "fs=cfg['MODEL']['FS'] \n",
    "\n",
    "\n",
    "audio_files = sorted(glob.glob('/mnt/dataset/public/Fingerprinting/Embeddings_BFTRI/debug_audios' + '/*.wav', recursive=True))\n",
    "outputDir = '/mnt/dataset/public/Fingerprinting/Embeddings_BFTRI/debug_audios'\n",
    "\n",
    "m_pre, m_fp = build_fp(cfg)\n",
    "\n",
    "checkpoint_root_dir:str = \"./logs/CHECK_BFTRI_100/101/\"\n",
    "checkpoint = tf.train.Checkpoint(m_fp)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_root_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m bsz \u001b[38;5;241m=\u001b[39m ts_batch_sz \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m125\u001b[39m\n\u001b[1;32m     11\u001b[0m _ts_n_anchor \u001b[38;5;241m=\u001b[39m ts_batch_sz\n\u001b[0;32m---> 12\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mgenUnbalSequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mts_batch_sz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_ts_n_anchor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdur\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_offset_anchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_the_last_non_full_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m enq \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mOrderedEnqueuer(ds,use_multiprocessing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m enq\u001b[38;5;241m.\u001b[39mstart(workers\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEVICE\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPU_N_WORKERS\u001b[39m\u001b[38;5;124m'\u001b[39m], max_queue_size\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEVICE\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPU_MAX_QUEUE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/mnt/dev/rodrigoalmeida/neural-audio-fp/model_RA/utils/dataloader_keras.py:119\u001b[0m, in \u001b[0;36mgenUnbalSequence.__init__\u001b[0;34m(self, fns_event_list, bsz, n_anchor, duration, hop, fs, shuffle, seg_mode, amp_mode, random_offset_anchor, offset_margin_hop_rate, bg_mix_parameter, ir_mix_parameter, speech_mix_parameter, reduce_items_p, reduce_batch_first_half, experimental_mode, drop_the_last_non_full_batch)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeech_snr_range \u001b[38;5;241m=\u001b[39m speech_mix_parameter[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseg_mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_oneshot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m#print(f\"fns_event_list:{fns_event_list}\")\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfns_event_seg_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_fns_seg_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns_event_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseg_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mhop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m#print(f\"fns_event_seg_list:{self.fns_event_seg_list}\")\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m#self.fns_event_seg_list = [self.fns_event_seg_list[20]] # linha de cÃ³digo para o spectogram - tese\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m#print(f\"fns_event_seg_list:{self.fns_event_seg_list}\")\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseg_mode=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseg_mode))\n",
      "File \u001b[0;32m/mnt/dev/rodrigoalmeida/neural-audio-fp/model_RA/utils/audio_utils.py:193\u001b[0m, in \u001b[0;36mget_fns_seg_list\u001b[0;34m(fns_list, segment_mode, fs, duration, hop)\u001b[0m\n\u001b[1;32m    191\u001b[0m     pt_wav\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(file_ext)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# 'all', 'random_oneshot', 'first'\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m segment_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: /"
     ]
    }
   ],
   "source": [
    "for file_path in audio_files:\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    dir_name = f'{base_name[:3]}' #nome das pastas\n",
    "\n",
    "    #if not os.path.exists(dir_name):\n",
    "    #    os.makedirs(dir_name)\n",
    "\n",
    "    bsz = ts_batch_sz = 125\n",
    "\n",
    "    _ts_n_anchor = ts_batch_sz\n",
    "    ds = genUnbalSequence(\n",
    "        list(file_path),\n",
    "        ts_batch_sz,\n",
    "        _ts_n_anchor,\n",
    "        dur,\n",
    "        hop,\n",
    "        fs,\n",
    "        shuffle=False,\n",
    "        random_offset_anchor=False,\n",
    "        drop_the_last_non_full_batch=False)\n",
    "\n",
    "    enq = tf.keras.utils.OrderedEnqueuer(ds,use_multiprocessing=True,shuffle=False)\n",
    "    enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'], max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "\n",
    "    i = 0\n",
    "    emb_list = []\n",
    "\n",
    "    while i < len(enq.sequence):\n",
    "        X, _ = next(enq.get())\n",
    "        emb = embeddingGenerator(X, m_pre, m_fp)\n",
    "        emb_list.append(emb.numpy())\n",
    "        i += 1\n",
    "    enq.stop()\n",
    "\n",
    "    emb_array = np.concatenate(emb_list,axis=0)\n",
    "    #emb_array_list = np.array(emb_array)\n",
    "\n",
    "    output_file_path = os.path.join(outputDir, dir_name, base_name + '.h5')\n",
    "\n",
    "    #deepdish - encapsula\n",
    "    \n",
    "    # save -> dd.io.save(emb_array, output_file_path)\n",
    "    # load -> emb_array = dd.io.load(output_file_path)\n",
    "\n",
    "    with h5py.File(output_file_path, 'w') as hf:\n",
    "            hf.create_dataset('embeddings', data=emb_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
