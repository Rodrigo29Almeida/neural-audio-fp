{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_RA.utils.dataloader_keras import genUnbalSequence\n",
    "#import tensorflow as tf\n",
    "#from model_RA.dataset_RA import Dataset\n",
    "import glob\n",
    "#from model.utils.audio_utils import (bg_mix_batch, ir_aug_batch, load_audio,\n",
    "#                                     get_fns_seg_list, load_audio_multi_start)\n",
    "from model.utils.audio_utils import load_audio_multi_start\n",
    "import tensorflow as tf\n",
    "import wave\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memmap_data(source_dir, fname, append_extra_length=None, shape_only=False):\n",
    "    \"\"\"\n",
    "    Load data and datashape from the file path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source_dir : (str)\n",
    "        Directory where the files are located.\n",
    "    fname : (str)\n",
    "        File name except extension.\n",
    "    append_extra_length : None or (int)\n",
    "        Length to append empty vector when loading memmap.\n",
    "    shape_only : (bool), optional\n",
    "        Return only shape. The default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (data, data_shape)\n",
    "    \"\"\"\n",
    "    path_shape = os.path.join(source_dir, fname + '_shape.npy')\n",
    "    path_data = os.path.join(source_dir, fname + '.mm')\n",
    "    data_shape = np.load(path_shape)\n",
    "    if shape_only:\n",
    "        return data_shape\n",
    "\n",
    "    if append_extra_length:\n",
    "        data_shape[0] += append_extra_length\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r+',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    else:\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    return data, data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load audio\n",
    "#features\n",
    "#nnfp\n",
    "#generate\n",
    "#predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default_RA.yaml\n"
     ]
    }
   ],
   "source": [
    "config = \"default_RA\"\n",
    "cfg = load_config(config)\n",
    "#checkpoint_name = \"Checks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSZ\n",
    "tr_batch_sz = cfg['BSZ']['TR_BATCH_SZ']\n",
    "tr_n_anchor = cfg['BSZ']['TR_N_ANCHOR']\n",
    "val_batch_sz = cfg['BSZ']['VAL_BATCH_SZ']\n",
    "val_n_anchor = cfg['BSZ']['VAL_N_ANCHOR']\n",
    "ts_batch_sz = cfg['BSZ']['TS_BATCH_SZ']\n",
    "\n",
    "# Model parameters\n",
    "dur = cfg['MODEL']['DUR']\n",
    "hop = cfg['MODEL']['HOP']\n",
    "fs = cfg['MODEL']['FS']\n",
    "\n",
    "# Time-domain augmentation parameter\n",
    "tr_snr = cfg['TD_AUG']['TR_SNR']\n",
    "ts_snr = cfg['TD_AUG']['TS_SNR']\n",
    "val_snr = cfg['TD_AUG']['VAL_SNR']\n",
    "tr_use_bg_aug = cfg['TD_AUG']['TR_BG_AUG']\n",
    "ts_use_bg_aug = cfg['TD_AUG']['TS_BG_AUG']\n",
    "val_use_bg_aug = cfg['TD_AUG']['VAL_BG_AUG']\n",
    "tr_use_ir_aug = cfg['TD_AUG']['TR_IR_AUG']\n",
    "ts_use_ir_aug = cfg['TD_AUG']['TS_IR_AUG']\n",
    "val_use_ir_aug = cfg['TD_AUG']['VAL_IR_AUG']\n",
    "tr_use_speech_aug = cfg['TD_AUG']['TR_SPEECH_AUG']\n",
    "ts_use_speech_aug = cfg['TD_AUG']['TS_SPEECH_AUG']\n",
    "val_use_speech_aug = cfg['TD_AUG']['VAL_SPEECH_AUG']\n",
    "\n",
    "val_bg_fps = None\n",
    "val_ir_fps = None\n",
    "val_speech_fps = None\n",
    "\n",
    "seg_mode ='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seg_list(fns_list=[],\n",
    "                     segment_mode='all',\n",
    "                     fs=22050,\n",
    "                     duration=1,\n",
    "                     hop=None):\n",
    "    \"\"\"\n",
    "    return: fns_event_seg_list\n",
    "        \n",
    "        [[filename, seg_idx, offset_min, offset_max], [ ... ] , ... [ ... ]]\n",
    "        \n",
    "        offset_min is 0 or negative integer\n",
    "        offset_max is 0 or positive integer\n",
    "        \n",
    "    \"\"\"\n",
    "    if hop == None: hop = duration\n",
    "    fns_event_seg_list = []\n",
    "\n",
    "    #print(f\"fns_list={fns_list}\")\n",
    "\n",
    "    for offset_idx, filename in enumerate(fns_list):\n",
    "        # Get audio info\n",
    "        #print(f\"filename={filename}\")\n",
    "        n_frames_in_seg = fs * duration\n",
    "        n_frames_in_hop = fs * hop  # 2019 09.05\n",
    "        file_ext = filename[-3:]\n",
    "\n",
    "        if file_ext == 'wav':\n",
    "            pt_wav = wave.open(filename, 'r')\n",
    "            _fs = pt_wav.getframerate()\n",
    "\n",
    "            if fs != _fs:\n",
    "                raise ValueError('Sample rate should be {} but got {}'.format(\n",
    "                    str(fs), str(_fs)))\n",
    "\n",
    "            n_frames = pt_wav.getnframes()\n",
    "            #n_segs = n_frames // n_frames_in_seg\n",
    "            if n_frames > n_frames_in_seg:\n",
    "                n_segs = (n_frames - n_frames_in_seg +\n",
    "                          n_frames_in_hop) // n_frames_in_hop\n",
    "            else:\n",
    "                n_segs = 1\n",
    "\n",
    "            n_segs = int(n_segs)\n",
    "            assert (n_segs > 0)\n",
    "            residual_frames = np.max([\n",
    "                0,\n",
    "                n_frames - ((n_segs - 1) * n_frames_in_hop + n_frames_in_seg)\n",
    "            ])\n",
    "            pt_wav.close()\n",
    "        else:\n",
    "            raise NotImplementedError(file_ext)\n",
    "\n",
    "        # 'all', 'random_oneshot', 'first'\n",
    "        if segment_mode == 'all':\n",
    "            for seg_idx in range(n_segs):\n",
    "                offset_min, offset_max = int(-1 *\n",
    "                                             n_frames_in_hop), n_frames_in_hop\n",
    "                if seg_idx == 0:  # first seg\n",
    "                    offset_min = 0\n",
    "                if seg_idx == (n_segs - 1):  # last seg\n",
    "                    offset_max = residual_frames\n",
    "\n",
    "                fns_event_seg_list.append(\n",
    "                    [filename, seg_idx, offset_min, offset_max])\n",
    "        elif segment_mode == 'random_oneshot':\n",
    "            seg_idx = np.random.randint(0, n_segs)\n",
    "            offset_min, offset_max = n_frames_in_hop, n_frames_in_hop\n",
    "            if seg_idx == 0:  # first seg\n",
    "                offset_min = 0\n",
    "            if seg_idx == (n_segs - 1):  # last seg\n",
    "                offset_max = residual_frames\n",
    "            fns_event_seg_list.append(\n",
    "                [filename, seg_idx, offset_min, offset_max])\n",
    "        elif segment_mode == 'first':\n",
    "            seg_idx = 0\n",
    "            offset_min, offset_max = 0, 0\n",
    "            fns_event_seg_list.append(\n",
    "                [filename, seg_idx, offset_min, offset_max])\n",
    "        else:\n",
    "            raise NotImplementedError(segment_mode)\n",
    "\n",
    "    return fns_event_seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"audiopath = '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/test-query-db-500-30s/db/000/000134.wav'\\naudio_list =[audiopath]\\n\\nfns_event_seg_list = get_fns_seg_list(audio_list,\\n                                        seg_mode,\\n                                        fs,\\n                                        dur,\\n                                        hop=hop)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"audiopath = '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/test-query-db-500-30s/db/000/000134.wav'\n",
    "audio_list =[audiopath]\n",
    "\n",
    "fns_event_seg_list = get_fns_seg_list(audio_list,\n",
    "                                        seg_mode,\n",
    "                                        fs,\n",
    "                                        dur,\n",
    "                                        hop=hop)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_margin_hop_rate=0.4\n",
    "offset_margin_frame = int(hop * offset_margin_hop_rate * fs)\n",
    "random_offset_anchor=False\n",
    "n_pos_per_anchor = round((120 - 60) / 60)\n",
    "amp_mode='normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_load(anchor_idx_list, fns_event_seg_list):\n",
    "        Xa_batch = None\n",
    "        \n",
    "        for idx in anchor_idx_list:  # idx: index for one sample\n",
    "            pos_start_sec_list = []\n",
    "            # fns_event_seg_list = [[filename, seg_idx, offset_min, offset_max], [ ... ] , ... [ ... ]]\n",
    "            offset_min, offset_max = fns_event_seg_list[idx][\n",
    "                2], fns_event_seg_list[idx][3]\n",
    "            \n",
    "            anchor_offset_min = np.max([offset_min, -offset_margin_frame])\n",
    "            anchor_offset_max = np.min([offset_max, offset_margin_frame])\n",
    "            \n",
    "            \n",
    "            _anchor_offset_frame = 0\n",
    "            anchor_start_sec = fns_event_seg_list[idx][1] * hop\n",
    "\n",
    "\n",
    "            \"\"\" Calculate multiple(=self.n_pos_per_anchor) pos_start_sec. \"\"\"\n",
    "            if n_pos_per_anchor > 0:\n",
    "                pos_offset_min = np.max([\n",
    "                    (_anchor_offset_frame - offset_margin_frame),\n",
    "                    offset_min\n",
    "                ])\n",
    "                pos_offset_max = np.min([\n",
    "                    (_anchor_offset_frame + offset_margin_frame),\n",
    "                    offset_max\n",
    "                ])\n",
    "\n",
    "                if pos_offset_min==pos_offset_max==0:\n",
    "                    # Only the case of running extras/dataset2wav.py \n",
    "                    # as offset_margin_hot_rate=0\n",
    "                    pos_start_sec_list = fns_event_seg_list[idx][\n",
    "                        1] * hop\n",
    "                    pos_start_sec_list = [pos_start_sec_list]\n",
    "                    print('!!!!!!!!!!!!!!!!!!!!!!')\n",
    "                    print(f\"pos_start_sec_list:{pos_start_sec_list}\")\n",
    "                    print(f\"[anchor_start_sec]:{[anchor_start_sec]}\")\n",
    "\n",
    "                else:\n",
    "                    # Otherwise, we apply random offset to replicas \n",
    "                    _pos_offset_frame_list = np.random.randint(\n",
    "                        low=pos_offset_min,\n",
    "                        high=pos_offset_max,\n",
    "                        size=n_pos_per_anchor)\n",
    "                    _pos_offset_sec_list = _pos_offset_frame_list / fs\n",
    "                    pos_start_sec_list = fns_event_seg_list[idx][\n",
    "                        1] * hop + _pos_offset_sec_list  \n",
    "            \n",
    "            \"\"\"\n",
    "            load audio returns: [anchor, pos1, pos2,..pos_n]\n",
    "            \"\"\"\n",
    "            #print(self.fns_event_seg_list[idx])\n",
    "            start_sec_list = np.concatenate(\n",
    "                ([anchor_start_sec], pos_start_sec_list))\n",
    "            \n",
    "            xs = load_audio_multi_start(fns_event_seg_list[idx][0],\n",
    "                                        start_sec_list, dur, fs,\n",
    "                                        amp_mode)  # xs: ((1+n_pos)),T)\n",
    "\n",
    "            if Xa_batch is None:\n",
    "                Xa_batch = xs[0, :].reshape((1, -1))\n",
    "            else:\n",
    "                Xa_batch = np.vstack((Xa_batch, xs[0, :].reshape(\n",
    "                    (1, -1))))  # Xa_batch: (n_anchor, T)\n",
    "                \n",
    "        return Xa_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getitem(idx, index_event, n_anchor, fns_event_seg_list):\n",
    "    \"\"\" Get anchor (original) and positive (replica) samples. \"\"\"\n",
    "    #print(f\"idx:{idx}\")\n",
    "    index_anchor_for_batch = index_event[idx *\n",
    "                                n_anchor:(idx + 1) *\n",
    "                                n_anchor]\n",
    "    #print(f\"index_anchor_for_batch:{index_anchor_for_batch}\")\n",
    "    \n",
    "    if len(index_anchor_for_batch) == 0:\n",
    "        return None\n",
    "     \n",
    "    Xa_batch = batch_load(index_anchor_for_batch, fns_event_seg_list)\n",
    "    \n",
    "    #print(f\"Xa_batch:{Xa_batch}\")\n",
    "\n",
    "    global bg_sel_indices, speech_sel_indices\n",
    "\n",
    "    Xa_batch = np.expand_dims(Xa_batch,\n",
    "                                1).astype(np.float32)  # (n_anchor, 1, T)\n",
    "    #print(f\"Xa_batch_expandido:{Xa_batch}\")\n",
    "    \n",
    "    return Xa_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiopath = '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/test-query-db-500-30s/db/000/000134.wav'\n",
    "audio_list = [audiopath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_list = get_seg_list(fns_list=audio_list,\n",
    "                     segment_mode='all',\n",
    "                     fs=8000,\n",
    "                     duration=1.,\n",
    "                     hop=.5)\n",
    "\n",
    "n_samples = len(seg_list)\n",
    "index_event = np.arange(n_samples)\n",
    "n_anchor=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = len(index_event) // n_anchor + (1 if len(index_event) % n_anchor != 0 else 0)#len(seg_list)\n",
    "#print(f\"index_event:{index_event}\")\n",
    "\n",
    "for i in range(n_iter):\n",
    "    #print(i)\n",
    "    X = getitem(i, index_event, n_anchor, seg_list)\n",
    "\n",
    "    if X is None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_RA.fp_RA.melspec.melspectrogram_RA import get_melspec_layer\n",
    "from model_RA.fp_RA.nnfp import get_fingerprinter\n",
    "\n",
    "m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "m_fp = get_fingerprinter(cfg, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.concat(X, axis=0)\n",
    "feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "m_fp.trainable = False\n",
    "emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)\n",
    "\n",
    "emb_gf = m_fp.div_enc(emb_f)\n",
    "emb_gf = tf.math.l2_normalize(emb_gf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(59, 128), dtype=float32, numpy=\n",
       "array([[-0.02876278,  0.0361596 , -0.04542529, ..., -0.05875982,\n",
       "         0.04338404,  0.16598956],\n",
       "       [-0.05113657,  0.04920626, -0.02506815, ..., -0.04597016,\n",
       "         0.02481091,  0.13902223],\n",
       "       [-0.01189004, -0.00121552, -0.03751804, ...,  0.02125106,\n",
       "         0.02168985,  0.17631531],\n",
       "       ...,\n",
       "       [ 0.02640655,  0.03909785, -0.0130725 , ..., -0.03039054,\n",
       "         0.07897712,  0.18853524],\n",
       "       [-0.0010752 ,  0.05746509, -0.00945702, ..., -0.05243146,\n",
       "         0.00590391,  0.14370023],\n",
       "       [-0.01910625,  0.02702098, -0.03873452, ..., -0.05920405,\n",
       "        -0.03557371,  0.11459503]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 59 (59, 128) ./logs/emb//query-134/\n"
     ]
    }
   ],
   "source": [
    "dim = cfg['MODEL']['EMB_SZ']\n",
    "n_items = len(X) #ds[key].n_samples\n",
    "arr_shape = (n_items, dim)\n",
    "\n",
    "key = 'query-134'\n",
    "\n",
    "output_root_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + \\\n",
    "            f'/{key}/'\n",
    "\n",
    "os.makedirs(output_root_dir, exist_ok=True)\n",
    "\n",
    "print(dim, n_items, arr_shape, output_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                dtype='float32',\n",
    "                mode='w+',\n",
    "                shape=arr_shape)\n",
    "np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "bsz = 125\n",
    "arr[i * bsz:(i + 1) * bsz, :] = emb_gf.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[-0.02876278,  0.0361596 , -0.04542529, ..., -0.05875982,\n",
       "          0.04338404,  0.16598956],\n",
       "        [-0.05113657,  0.04920626, -0.02506815, ..., -0.04597016,\n",
       "          0.02481091,  0.13902223],\n",
       "        [-0.01189004, -0.00121552, -0.03751804, ...,  0.02125106,\n",
       "          0.02168985,  0.17631531],\n",
       "        ...,\n",
       "        [ 0.02640655,  0.03909785, -0.0130725 , ..., -0.03039054,\n",
       "          0.07897712,  0.18853524],\n",
       "        [-0.0010752 ,  0.05746509, -0.00945702, ..., -0.05243146,\n",
       "          0.00590391,  0.14370023],\n",
       "        [-0.01910625,  0.02702098, -0.03873452, ..., -0.05920405,\n",
       "         -0.03557371,  0.11459503]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcurses\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m))))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval_RA\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_index_faiss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_index\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval_RA\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprint_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrintTable\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import click\n",
    "import curses\n",
    "import numpy as np\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))\n",
    "from eval_RA.utils.get_index_faiss import get_index\n",
    "from eval_RA.utils.print_table import PrintTable\n",
    "\n",
    "\n",
    "def load_memmap_data(source_dir,\n",
    "                     fname,\n",
    "                     append_extra_length=None,\n",
    "                     shape_only=False,\n",
    "                     display=True):\n",
    "    path_shape = source_dir + fname + '_shape.npy'\n",
    "    path_data = source_dir + fname + '.mm'\n",
    "    data_shape = np.load(path_shape)\n",
    "    if shape_only:\n",
    "        return data_shape\n",
    "\n",
    "    if append_extra_length:\n",
    "        data_shape[0] += append_extra_length\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r+',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    else:\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    if display:\n",
    "        print(f'Load {data_shape[0]:,} items from \\033[32m{path_data}\\033[0m.')\n",
    "    return data, data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = cfg['MODEL']['EMB_SZ']\n",
    "n_items = len(X) #ds[key].n_samples\n",
    "arr_shape = (n_items, dim)\n",
    "print(arr_shape)\n",
    "key = 'query-134'\n",
    "\n",
    "output_root_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + \\\n",
    "            f'/{key}/'\n",
    "\n",
    "\n",
    "arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                dtype='float32',\n",
    "                mode='w+',\n",
    "                shape=arr_shape)\n",
    "np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)\n",
    "\n",
    "i=0\n",
    "arr[i * bsz:(i + 1) * bsz, :] = emb.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate\n",
    "sz_check = dict() # for warning message\n",
    "for key in ds.keys():\n",
    "    bsz = int(cfg['BSZ']['TS_BATCH_SZ'])  # Do not use ds.bsz here.\n",
    "    # n_items = len(ds[key]) * bsz\n",
    "    n_items = ds[key].n_samples\n",
    "    dim = cfg['MODEL']['EMB_SZ']\n",
    "    \"\"\"\n",
    "    Why use \"memmap\"?\n",
    "\n",
    "    • First, we need to store a huge uncompressed embedding vectors until\n",
    "        constructing a compressed DB with IVF-PQ (using FAISS). Handling a\n",
    "        huge ndarray is not a memory-safe way: \"memmap\" consume 0 memory.\n",
    "\n",
    "    • Second, Faiss-GPU does not support reconstruction of DB from\n",
    "        compressed DB (index). In eval/eval_faiss.py, we need uncompressed\n",
    "        vectors to calaulate sequence-level matching score. The created\n",
    "        \"memmap\" will be reused at that point.\n",
    "\n",
    "    Reference:\n",
    "        https://numpy.org/doc/stable/reference/generated/numpy.memmap.html\n",
    "\n",
    "    \"\"\"\n",
    "    # Create memmap, and save shapes\n",
    "    assert n_items > 0\n",
    "    arr_shape = (n_items, dim)\n",
    "    arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                    dtype='float32',\n",
    "                    mode='w+',\n",
    "                    shape=arr_shape)\n",
    "    np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)\n",
    "\n",
    "    # Fingerprinting loop\n",
    "    tf.print(\n",
    "        f\"=== Generating fingerprint from \\x1b[1;32m'{key}'\\x1b[0m \" +\n",
    "        f\"bsz={bsz}, {n_items} items, d={dim}\"+ \" ===\")\n",
    "    progbar = Progbar(len(ds[key]))\n",
    "\n",
    "    \"\"\" Parallelism to speed up preprocessing------------------------- \"\"\"\n",
    "    enq = tf.keras.utils.OrderedEnqueuer(ds[key],\n",
    "                                            use_multiprocessing=True,\n",
    "                                            shuffle=False)\n",
    "    enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "                max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "    i = 0\n",
    "    while i < len(enq.sequence):\n",
    "        progbar.update(i)\n",
    "        X, _ = next(enq.get())\n",
    "        emb = test_step(X, m_pre, m_fp)\n",
    "        arr[i * bsz:(i + 1) * bsz, :] = emb.numpy() # Writing on disk.\n",
    "        i += 1\n",
    "    progbar.update(i, finalize=True)\n",
    "    enq.stop()\n",
    "    \"\"\" End of Parallelism-------------------------------------------- \"\"\"\n",
    "\n",
    "    tf.print(f'=== Succesfully stored {arr_shape[0]} fingerprint to {output_root_dir} ===')\n",
    "    sz_check[key] = len(arr)\n",
    "    arr.flush(); del(arr) # Close memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = len(seg_list)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    X = ds.__getitem__(i)\n",
    "        \n",
    "getitem(idx, index_event, n_anchor, seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_root_dir = cfg['DIR']['SOURCE_ROOT_DIR']\n",
    "source_fps = sorted(\n",
    "            glob.glob(source_root_dir + 'val-query-db-500-30s/' +\n",
    "                      '**/*.wav', recursive=True))[:250]\n",
    "       \n",
    "ds_query = genUnbalSequence(\n",
    "    source_fps,\n",
    "    val_batch_sz,\n",
    "    val_n_anchor,\n",
    "    dur,\n",
    "    hop,\n",
    "    fs,\n",
    "    shuffle=False,\n",
    "    random_offset_anchor=False,\n",
    "    bg_mix_parameter=[val_use_bg_aug, val_bg_fps, val_snr],\n",
    "    ir_mix_parameter=[val_use_ir_aug, val_ir_fps],\n",
    "    speech_mix_parameter=[val_use_speech_aug, val_speech_fps,\n",
    "                            val_snr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_event_seg_list = get_fns_seg_list(audio_list,\n",
    "                                        seg_mode,\n",
    "                                        fs,\n",
    "                                        dur,\n",
    "                                        hop=hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fns_event_seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns_event_seg_list[3][1] * dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "for idx in fns_event_seg_list:\n",
    "    print(fns_event_seg_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=str()\n",
    "seg_start_sec=0.0#float()\n",
    "offset_sec=0.0,\n",
    "seg_length_sec=float()\n",
    "seg_pad_offset_sec=0.0\n",
    "fs=8000\n",
    "amp_mode='normal'\n",
    "\n",
    "for offset_idx, filename_audio in enumerate(audio_list):\n",
    "    filename = filename_audio\n",
    "\n",
    "#print(filename)\n",
    "for idx in len(fns_event_seg_list):\n",
    "    \n",
    "fns_event_seg_list[idx][1] * dur\n",
    "start_frame_idx = np.floor((seg_start_sec + offset_sec) * fs).astype(int)\n",
    "seg_length_frame = np.floor(seg_length_sec * fs).astype(int)\n",
    "end_frame_idx = start_frame_idx + seg_length_frame\n",
    "\n",
    "print(start_frame_idx, seg_length_frame, end_frame_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=str()\n",
    "seg_start_sec=float()\n",
    "offset_sec=0.0,\n",
    "seg_length_sec=float()\n",
    "seg_pad_offset_sec=0.0\n",
    "fs=8000\n",
    "amp_mode='normal'\n",
    "\n",
    "for offset_idx, filename_audio in enumerate(audio_list):\n",
    "    filename = filename_audio\n",
    "\n",
    "#print(filename)\n",
    "start_frame_idx = np.floor((seg_start_sec + offset_sec) * fs).astype(int)\n",
    "seg_length_frame = np.floor(seg_length_sec * fs).astype(int)\n",
    "end_frame_idx = start_frame_idx + seg_length_frame\n",
    "\n",
    "print(start_frame_idx, seg_length_frame, end_frame_idx)\n",
    "\n",
    "# Get file-info\n",
    "file_ext = filename[-3:]\n",
    "#print(start_frame_idx, end_frame_idx)\n",
    "\n",
    "if file_ext == 'wav':\n",
    "    pt_wav = wave.open(filename, 'r')\n",
    "    pt_wav.setpos(start_frame_idx)\n",
    "    x = pt_wav.readframes(end_frame_idx - start_frame_idx)\n",
    "    x = np.frombuffer(x, dtype=np.int16)\n",
    "    x = x / 2**15  # dtype=float\n",
    "else:\n",
    "    raise NotImplementedError(file_ext)\n",
    "\n",
    "# Max Normalize, random amplitude\n",
    "if amp_mode == 'normal':\n",
    "    pass\n",
    "elif amp_mode == 'max_normalize':\n",
    "    _x_max = np.max(np.abs(x))\n",
    "    if _x_max != 0:\n",
    "        x = x / _x_max\n",
    "else:\n",
    "    raise ValueError('amp_mode={}'.format(amp_mode))\n",
    "\n",
    "# padding process. it works only when win_size> audio_size and padding='random'\n",
    "audio_arr = np.zeros(int(seg_length_sec * fs))\n",
    "seg_pad_offset_idx = int(seg_pad_offset_sec * fs)\n",
    "audio_arr[seg_pad_offset_idx:seg_pad_offset_idx + len(x)] = x\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/dataset/public/Fingerprinting/query_procura/000134.wav']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m audioDir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/dataset/public/Fingerprinting/query_procura\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m source_fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m      3\u001b[0m             glob\u001b[38;5;241m.\u001b[39mglob(audioDir \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m      4\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/*.wav\u001b[39m\u001b[38;5;124m'\u001b[39m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m----> 6\u001b[0m ds_query \u001b[38;5;241m=\u001b[39m \u001b[43mgenUnbalSequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_fps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_batch_sz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_n_anchor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdur\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_offset_anchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbg_mix_parameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_use_bg_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_bg_fps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_snr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mir_mix_parameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_use_ir_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ir_fps\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeech_mix_parameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_use_speech_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_speech_fps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mval_snr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/dev/rodrigoalmeida/neural-audio-fp/model_RA/utils/dataloader_keras.py:149\u001b[0m, in \u001b[0;36mgenUnbalSequence.__init__\u001b[0;34m(self, fns_event_list, bsz, n_anchor, duration, hop, fs, shuffle, seg_mode, amp_mode, random_offset_anchor, offset_margin_hop_rate, bg_mix_parameter, ir_mix_parameter, speech_mix_parameter, reduce_items_p, reduce_batch_first_half, experimental_mode, drop_the_last_non_full_batch)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m#print(f\"self.n_samples, self.index_event: {self.n_samples, self.index_event}\")\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbg_mix \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfns_bg_seg_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_fns_seg_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns_bg_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bg_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfns_bg_seg_list)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/dev/rodrigoalmeida/neural-audio-fp/model_RA/utils/audio_utils.py:159\u001b[0m, in \u001b[0;36mget_fns_seg_list\u001b[0;34m(fns_list, segment_mode, fs, duration, hop)\u001b[0m\n\u001b[1;32m    155\u001b[0m fns_event_seg_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m#print(f\"fns_list={fns_list}\")\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m offset_idx, filename \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfns_list\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Get audio info\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m#print(f\"filename={filename}\")\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     n_frames_in_seg \u001b[38;5;241m=\u001b[39m fs \u001b[38;5;241m*\u001b[39m duration\n\u001b[1;32m    163\u001b[0m     n_frames_in_hop \u001b[38;5;241m=\u001b[39m fs \u001b[38;5;241m*\u001b[39m hop  \u001b[38;5;66;03m# 2019 09.05\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "audioDir = '/mnt/dataset/public/Fingerprinting/query_procura'\n",
    "source_fps = sorted(\n",
    "            glob.glob(audioDir +\n",
    "                      '/*.wav', recursive=True))\n",
    "\n",
    "ds_query = genUnbalSequence(\n",
    "    source_fps,\n",
    "    val_batch_sz,\n",
    "    val_n_anchor,\n",
    "    dur,\n",
    "    hop,\n",
    "    fs,\n",
    "    shuffle=False,\n",
    "    random_offset_anchor=False,\n",
    "    bg_mix_parameter=[val_use_bg_aug, val_bg_fps, val_snr],\n",
    "    ir_mix_parameter=[val_use_ir_aug, val_ir_fps],\n",
    "    speech_mix_parameter=[val_use_speech_aug, val_speech_fps,\n",
    "                            val_snr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_fps = sorted(\n",
    "            glob.glob(audiopath, recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_event_seg_list = get_fns_seg_list(source_fps,\n",
    "                                        seg_mode,\n",
    "                                        fs,\n",
    "                                        dur,\n",
    "                                        hop=hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = len(fns_event_seg_list)\n",
    "for i in range(n_iter):\n",
    "        X = fns_event_seg_list.__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/val-query-db-500-30s/db/000/000458.wav', '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/val-query-db-500-30s/db/000/000736.wav']\n",
      "self.n_samples, self.index_event: (60, array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59]))\n"
     ]
    }
   ],
   "source": [
    "dataset=Dataset(cfg)\n",
    "ds = dataset.get_val_ds(max_song=2) # max 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.ir_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(X, m_pre, m_fp):\n",
    "    \n",
    "    X=X[0]\n",
    "    feat = m_pre(X)  # (nA, F, T, 1)\n",
    "\n",
    "    m_fp.trainable = False\n",
    "\n",
    "    emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)\n",
    "    emb_gf = m_fp.div_enc(emb_f)\n",
    "    emb_gf = tf.math.l2_normalize(emb_gf, axis=1)\n",
    "    return emb_gf # f(.), L2(f(.)), L2(g(f(.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_RA.fp_RA.melspec.melspectrogram_RA import get_melspec_layer\n",
    "from model_RA.fp_RA.nnfp import get_fingerprinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "m_fp = get_fingerprinter(cfg, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter=1\n",
      "X_depois:Tensor(\"X:0\", shape=(60, 1, 8000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "max_n_samples=3000\n",
    "bsz=120\n",
    "n_iter = min(len(ds), max_n_samples // bsz)\n",
    "print(f\"n_iter={n_iter}\")\n",
    "emb=dict()\n",
    "for i in range(n_iter):\n",
    "        X = ds.__getitem__(i)\n",
    "        emb['g(f)'] = test_step(X, m_pre, m_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.concat(X, axis=0)\n",
    "feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "m_fp.trainable = False\n",
    "emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    \"\"\"\n",
    "    Extract features from an audio file using librosa.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_path : (str)\n",
    "        Path to the audio file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features : (np.ndarray)\n",
    "        Extracted feature vector.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    return mfcc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eval_RA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval_RA\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_index_faiss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_index\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eval_RA'"
     ]
    }
   ],
   "source": [
    "from eval_RA.utils.get_index_faiss import get_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrong number or type of arguments for overloaded function 'new_IndexFlatL2'.\n  Possible C/C++ prototypes are:\n    faiss::IndexFlatL2::IndexFlatL2(faiss::Index::idx_t)\n    faiss::IndexFlatL2::IndexFlatL2()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m extract_features(audio_path)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape to match expected input shape\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Perform the search\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m indices, distances \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistances: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistances\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(emb_dir, query_vector, index_type, use_gpu, max_train, k)\u001b[0m\n\u001b[1;32m     28\u001b[0m db, db_shape \u001b[38;5;241m=\u001b[39m load_memmap_data(emb_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create and train FAISS index\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Add items to index\u001b[39;00m\n\u001b[1;32m     34\u001b[0m index\u001b[38;5;241m.\u001b[39madd(db)\n",
      "Cell \u001b[0;32mIn[2], line 63\u001b[0m, in \u001b[0;36mget_index\u001b[0;34m(index_type, data, shape, use_gpu, max_train)\u001b[0m\n\u001b[1;32m     60\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m       \u001b[38;5;66;03m# number of subquantizers\u001b[39;00m\n\u001b[1;32m     61\u001b[0m nbits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m   \u001b[38;5;66;03m# bits per code\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m quantizer \u001b[38;5;241m=\u001b[39m \u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexFlatL2\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexIVFPQ(quantizer, d, nlist, m, nbits)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_gpu:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfpy/lib/python3.9/site-packages/faiss/swigfaiss.py:1980\u001b[0m, in \u001b[0;36mIndexFlatL2.__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1980\u001b[0m     _swigfaiss\u001b[38;5;241m.\u001b[39mIndexFlatL2_swiginit(\u001b[38;5;28mself\u001b[39m, \u001b[43m_swigfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_IndexFlatL2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Wrong number or type of arguments for overloaded function 'new_IndexFlatL2'.\n  Possible C/C++ prototypes are:\n    faiss::IndexFlatL2::IndexFlatL2(faiss::Index::idx_t)\n    faiss::IndexFlatL2::IndexFlatL2()\n"
     ]
    }
   ],
   "source": [
    "def predict(emb_dir, query_vector, index_type='ivfpq', use_gpu=True, max_train=1e7, k=1):\n",
    "    \"\"\"\n",
    "    Search for the closest match to the query vector in the database.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    emb_dir : (str)\n",
    "        Directory where the {db, dummy_db}.mm files are located.\n",
    "    query_vector : (np.ndarray)\n",
    "        Query vector to search for.\n",
    "    index_type : (str)\n",
    "        Type of FAISS index.\n",
    "    use_gpu : (bool)\n",
    "        Whether to use GPU.\n",
    "    max_train : (int)\n",
    "        Maximum number of items for index training.\n",
    "    k : (int)\n",
    "        Number of top results to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    indices : (np.ndarray)\n",
    "        Indices of the closest matches in the database.\n",
    "    distances : (np.ndarray)\n",
    "        Distances to the closest matches.\n",
    "    \"\"\"\n",
    "    # Load database\n",
    "    db, db_shape = load_memmap_data(emb_dir, 'db')\n",
    "\n",
    "    # Create and train FAISS index\n",
    "    index = get_index(index_type, db, db_shape, use_gpu, max_train)\n",
    "\n",
    "    # Add items to index\n",
    "    index.add(db)\n",
    "\n",
    "    # Search for the query vector\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    return indices, distances\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    emb_dir = '/mnt/dev/rodrigoalmeida/neural-audio-fp/logs/emb/CHECK_BFTRI_100/101'  # embeddings directory\n",
    "    audio_path = '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/test-query-db-500-30s/db/000/000134.wav'  # query audio file\n",
    "\n",
    "    # Extract features from the query audio\n",
    "    query_vector = extract_features(audio_path).reshape(1, -1)  # Reshape to match expected input shape\n",
    "\n",
    "    # Perform the search\n",
    "    indices, distances = predict(emb_dir, query_vector)\n",
    "    print(f\"Indices: {indices}\")\n",
    "    print(f\"Distances: {distances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 16:15:50.364946: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\"\"\" generate.py \"\"\"\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from model_RA.dataset_RA import Dataset\n",
    "from model_RA.fp_RA.melspec.melspectrogram_RA import get_melspec_layer\n",
    "from model_RA.fp_RA.nnfp import get_fingerprinter\n",
    "\n",
    "\n",
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_fp\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_root_dir, checkpoint_name, checkpoint_index,\n",
    "                    m_fp):\n",
    "    \"\"\" Load a trained fingerprinter \"\"\"\n",
    "    # Create checkpoint\n",
    "    checkpoint = tf.train.Checkpoint(model=m_fp)\n",
    "    checkpoint_dir = checkpoint_root_dir + f'/{checkpoint_name}/'\n",
    "    c_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir,\n",
    "                                           max_to_keep=None)\n",
    "\n",
    "    # Load\n",
    "    if checkpoint_index == None:\n",
    "        tf.print(\"\\x1b[1;32mArgument 'checkpoint_index' was not specified.\\x1b[0m\")\n",
    "        tf.print('\\x1b[1;32mSearching for the latest checkpoint...\\x1b[0m')\n",
    "        latest_checkpoint = c_manager.latest_checkpoint\n",
    "        if latest_checkpoint:\n",
    "            checkpoint_index = int(latest_checkpoint.split(sep='ckpt-')[-1])\n",
    "            status = checkpoint.restore(latest_checkpoint)\n",
    "            status.expect_partial()\n",
    "            tf.print(f'---Restored from {c_manager.latest_checkpoint}---')\n",
    "        else:\n",
    "            raise FileNotFoundError(f'Cannot find checkpoint in {checkpoint_dir}')\n",
    "    else:\n",
    "        checkpoint_fpath = checkpoint_dir + 'ckpt-' + str(checkpoint_index)\n",
    "        status = checkpoint.restore(checkpoint_fpath) # Let TF to handle error cases.\n",
    "        status.expect_partial()\n",
    "        tf.print(f'---Restored from {checkpoint_fpath}---')\n",
    "    return checkpoint_index\n",
    "\n",
    "\n",
    "def prevent_overwrite(key, target_path):\n",
    "    if (key == 'dummy_db') & os.path.exists(target_path):\n",
    "        answer = input(f'{target_path} exists. Will you overwrite (y/N)?')\n",
    "        if answer.lower() not in ['y', 'yes']: sys.exit()\n",
    "\n",
    "\n",
    "def get_data_source(cfg, source_root_dir, skip_dummy):\n",
    "    dataset = Dataset(cfg)\n",
    "    ds = dict()\n",
    "    if source_root_dir:\n",
    "        ds['custom_source'] = dataset.get_custom_db_ds(source_root_dir)\n",
    "    else:\n",
    "        if skip_dummy:\n",
    "            tf.print(\"Excluding \\033[33m'dummy_db'\\033[0m from source.\")\n",
    "            pass\n",
    "        else:\n",
    "            ds['dummy_db'] = dataset.get_test_dummy_db_ds()\n",
    "\n",
    "        if dataset.datasel_test_query_db in ['unseen_icassp', 'unseen_syn']:\n",
    "            ds['query'], ds['db'] = dataset.get_test_query_db_ds()\n",
    "        else:\n",
    "            raise ValueError(dataset.datasel_test_query_db)\n",
    "\n",
    "    tf.print(f'\\x1b[1;32mData source: {ds.keys()}\\x1b[0m',\n",
    "             f'{dataset.datasel_test_query_db}')\n",
    "    return ds\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(X, m_pre, m_fp):\n",
    "    \"\"\" Test step used for generating fingerprint \"\"\"\n",
    "    # X is not (Xa, Xp) here. The second element is reduced now.\n",
    "    m_fp.trainable = False\n",
    "    return m_fp(m_pre(X))  # (BSZ, Dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = cfg['MODEL']['EMB_SZ']\n",
    "\n",
    "assert n_items > 0\n",
    "arr_shape = (n_items, dim)\n",
    "arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                dtype='float32',\n",
    "                mode='w+',\n",
    "                shape=arr_shape)\n",
    "np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)\n",
    "\n",
    "arr[i * bsz:(i + 1) * bsz, :] = emb.numpy() # Writing on disk.\n",
    "i += 1\n",
    "\n",
    "\n",
    "sz_check[key] = len(arr)\n",
    "arr.flush(); del(arr) # Close memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = cfg['MODEL']['EMB_SZ']\n",
    "n_items = len(X) #ds[key].n_samples\n",
    "arr_shape = (n_items, dim)\n",
    "print(arr_shape)\n",
    "key = 'query-134'\n",
    "\n",
    "output_root_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + \\\n",
    "            f'/{key}/'\n",
    "\n",
    "\n",
    "arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                dtype='float32',\n",
    "                mode='w+',\n",
    "                shape=arr_shape)\n",
    "np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)\n",
    "\n",
    "i=0\n",
    "arr[i * bsz:(i + 1) * bsz, :] = emb.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fingerprint(cfg,\n",
    "                         checkpoint_name,\n",
    "                         checkpoint_index,\n",
    "                         source_root_dir,\n",
    "                         output_root_dir,\n",
    "                         skip_dummy):\n",
    "    \"\"\"\n",
    "    After run, the output (generated fingerprints) directory will be:\n",
    "      .\n",
    "      └──logs\n",
    "         └── emb\n",
    "             └── CHECKPOINT_NAME\n",
    "                 └── CHECKPOINT_INDEX\n",
    "                     ├── db.mm\n",
    "                     ├── db_shape.npy\n",
    "                     ├── dummy_db.mm\n",
    "                     ├── dummy_db_shape.npy\n",
    "                     ├── query.mm\n",
    "                     └── query_shape.npy\n",
    "    \"\"\"\n",
    "    # Build and load checkpoint\n",
    "    m_pre, m_fp = build_fp(cfg)\n",
    "    checkpoint_root_dir = cfg['DIR']['LOG_ROOT_DIR'] + 'checkpoint/'\n",
    "    checkpoint_index = load_checkpoint(checkpoint_root_dir, checkpoint_name,\n",
    "                                       checkpoint_index, m_fp)\n",
    "\n",
    "    # Get data source\n",
    "    \"\"\" ds = {'key1': <Dataset>, 'key2': <Dataset>, ...} \"\"\"\n",
    "    ds = get_data_source(cfg, source_root_dir, skip_dummy)\n",
    "\n",
    "    # Make output directory\n",
    "    if output_root_dir:\n",
    "        output_root_dir = output_root_dir + f'/{checkpoint_name}/{checkpoint_index}/'\n",
    "    else:\n",
    "        output_root_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + \\\n",
    "            f'/{checkpoint_name}/{checkpoint_index}/'\n",
    "    os.makedirs(output_root_dir, exist_ok=True)\n",
    "    if not skip_dummy:\n",
    "        prevent_overwrite('dummy_db', f'{output_root_dir}/dummy_db.mm')\n",
    "\n",
    "    # Generate\n",
    "    sz_check = dict() # for warning message\n",
    "    for key in ds.keys():\n",
    "        bsz = int(cfg['BSZ']['TS_BATCH_SZ'])  # Do not use ds.bsz here.\n",
    "        # n_items = len(ds[key]) * bsz\n",
    "        n_items = ds[key].n_samples\n",
    "        dim = cfg['MODEL']['EMB_SZ']\n",
    "        \"\"\"\n",
    "        Why use \"memmap\"?\n",
    "\n",
    "        • First, we need to store a huge uncompressed embedding vectors until\n",
    "          constructing a compressed DB with IVF-PQ (using FAISS). Handling a\n",
    "          huge ndarray is not a memory-safe way: \"memmap\" consume 0 memory.\n",
    "\n",
    "        • Second, Faiss-GPU does not support reconstruction of DB from\n",
    "          compressed DB (index). In eval/eval_faiss.py, we need uncompressed\n",
    "          vectors to calaulate sequence-level matching score. The created\n",
    "          \"memmap\" will be reused at that point.\n",
    "\n",
    "        Reference:\n",
    "            https://numpy.org/doc/stable/reference/generated/numpy.memmap.html\n",
    "\n",
    "        \"\"\"\n",
    "        # Create memmap, and save shapes\n",
    "        assert n_items > 0\n",
    "        arr_shape = (n_items, dim)\n",
    "        arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                        dtype='float32',\n",
    "                        mode='w+',\n",
    "                        shape=arr_shape)\n",
    "        np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)\n",
    "\n",
    "        # Fingerprinting loop\n",
    "        tf.print(\n",
    "            f\"=== Generating fingerprint from \\x1b[1;32m'{key}'\\x1b[0m \" +\n",
    "            f\"bsz={bsz}, {n_items} items, d={dim}\"+ \" ===\")\n",
    "        progbar = Progbar(len(ds[key]))\n",
    "\n",
    "        \"\"\" Parallelism to speed up preprocessing------------------------- \"\"\"\n",
    "        enq = tf.keras.utils.OrderedEnqueuer(ds[key],\n",
    "                                              use_multiprocessing=True,\n",
    "                                              shuffle=False)\n",
    "        enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "                  max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "        i = 0\n",
    "        while i < len(enq.sequence):\n",
    "            progbar.update(i)\n",
    "            X, _ = next(enq.get())\n",
    "            emb = test_step(X, m_pre, m_fp)\n",
    "            arr[i * bsz:(i + 1) * bsz, :] = emb.numpy() # Writing on disk.\n",
    "            i += 1\n",
    "        progbar.update(i, finalize=True)\n",
    "        enq.stop()\n",
    "        \"\"\" End of Parallelism-------------------------------------------- \"\"\"\n",
    "\n",
    "        tf.print(f'=== Succesfully stored {arr_shape[0]} fingerprint to {output_root_dir} ===')\n",
    "        sz_check[key] = len(arr)\n",
    "        arr.flush(); del(arr) # Close memmap\n",
    "\n",
    "    if 'custom_source' in ds.keys():\n",
    "        pass;\n",
    "    elif sz_check['db'] != sz_check['query']:\n",
    "        print(\"\\033[93mWarning: 'db' and 'query' size does not match. This can cause a problem in evaluataion stage.\\033[0m\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default_RA.yaml\n",
      "file entrada: /mnt/dataset/public/Fingerprinting/query_procura/000020.wav\n",
      "similaridade:0.14010010659694672\n",
      "similaridade:0.15846888720989227\n",
      "similaridade:-0.02840178646147251\n",
      "similaridade:-0.14455148577690125\n",
      "similaridade:-0.13392269611358643\n",
      "similaridade:-0.13182249665260315\n",
      "similaridade:-0.16113074123859406\n",
      "similaridade:0.1485816389322281\n",
      "similaridade:0.1693640947341919\n",
      "similaridade:0.07374265044927597\n",
      "similaridade:-0.1766311377286911\n",
      "similaridade:-0.08311345428228378\n",
      "similaridade:0.11754923313856125\n",
      "similaridade:0.013537664897739887\n",
      "similaridade:-0.15107092261314392\n",
      "similaridade:0.0838080570101738\n",
      "similaridade:-0.025540970265865326\n",
      "similaridade:0.010827061720192432\n",
      "similaridade:0.08970451354980469\n",
      "similaridade:-0.0755641981959343\n",
      "similaridade:-0.04691004008054733\n",
      "similaridade:-0.02019057236611843\n",
      "similaridade:0.020417416468262672\n",
      "similaridade:-0.13800644874572754\n",
      "similaridade:-0.05044283717870712\n",
      "similaridade:0.08835076540708542\n",
      "similaridade:-0.028636585921049118\n",
      "similaridade:-0.009502426721155643\n",
      "similaridade:-0.08959860354661942\n",
      "similaridade:-0.03003242239356041\n",
      "similaridade:0.11581569164991379\n",
      "similaridade:0.0631348192691803\n",
      "similaridade:-0.11053323745727539\n",
      "similaridade:0.026208829134702682\n",
      "similaridade:0.11207941174507141\n",
      "similaridade:-0.1048874482512474\n",
      "similaridade:-0.00787235889583826\n",
      "similaridade:0.028276002034544945\n",
      "similaridade:0.18598812818527222\n",
      "similaridade:0.11696354299783707\n",
      "similaridade:0.16529667377471924\n",
      "similaridade:0.10575246810913086\n",
      "similaridade:0.15608428418636322\n",
      "similaridade:0.0034088201355189085\n",
      "similaridade:-0.1475086361169815\n",
      "similaridade:-0.04975490644574165\n",
      "similaridade:0.043508827686309814\n",
      "similaridade:0.03694242611527443\n",
      "similaridade:0.10842558741569519\n",
      "similaridade:-0.081061951816082\n",
      "similaridade:-0.007608425337821245\n",
      "similaridade:-0.1758512705564499\n",
      "similaridade:-0.0434323251247406\n",
      "similaridade:0.06782301515340805\n",
      "similaridade:0.07832096517086029\n",
      "similaridade:0.12695984542369843\n",
      "similaridade:0.16338707506656647\n",
      "similaridade:0.11888160556554794\n",
      "similaridade:0.17171384394168854\n",
      "similaridade:-0.12228327244520187\n",
      "similaridade:-0.05801098421216011\n",
      "similaridade:0.18177424371242523\n",
      "similaridade:0.12228325009346008\n",
      "similaridade:0.20825321972370148\n",
      "similaridade:0.08883862942457199\n",
      "similaridade:0.31346598267555237\n",
      "similaridade:-0.07805406302213669\n",
      "similaridade:0.015076199546456337\n",
      "similaridade:-0.0727720782160759\n",
      "similaridade:0.06462845206260681\n",
      "similaridade:-0.007724788971245289\n",
      "similaridade:-0.18242858350276947\n",
      "similaridade:0.005175486672669649\n",
      "similaridade:-0.006254483480006456\n",
      "similaridade:0.11154568195343018\n",
      "similaridade:-0.040072884410619736\n",
      "similaridade:-0.04450574144721031\n",
      "similaridade:0.107954241335392\n",
      "similaridade:0.11364200711250305\n",
      "similaridade:0.04375888779759407\n",
      "similaridade:-0.0011569747002795339\n",
      "similaridade:-0.012525496073067188\n",
      "similaridade:0.046769578009843826\n",
      "similaridade:0.1136321946978569\n",
      "similaridade:0.21349041163921356\n",
      "similaridade:-0.09100903570652008\n",
      "similaridade:-0.16497935354709625\n",
      "similaridade:0.21037502586841583\n",
      "similaridade:0.08236262947320938\n",
      "similaridade:-0.07699476927518845\n",
      "similaridade:-0.025436950847506523\n",
      "similaridade:-0.0658426508307457\n",
      "similaridade:0.04497456178069115\n",
      "similaridade:0.052912238985300064\n",
      "similaridade:-0.17269234359264374\n",
      "similaridade:-0.04591967537999153\n",
      "similaridade:0.008832369931042194\n",
      "similaridade:0.07355792075395584\n",
      "similaridade:0.023821385577321053\n",
      "similaridade:-0.07470479607582092\n",
      "similaridade:-0.005728077609091997\n",
      "similaridade:0.09157463908195496\n",
      "similaridade:0.03910853713750839\n",
      "similaridade:0.15349861979484558\n",
      "similaridade:-0.03093668259680271\n",
      "similaridade:-0.1566668003797531\n",
      "similaridade:-0.057095881551504135\n",
      "similaridade:-0.0329703651368618\n",
      "similaridade:0.06761136651039124\n",
      "similaridade:0.13697101175785065\n",
      "similaridade:0.06413659453392029\n",
      "similaridade:0.0544111505150795\n",
      "similaridade:0.01782228983938694\n",
      "similaridade:0.04461691901087761\n",
      "similaridade:-0.0003980398760177195\n",
      "similaridade:-0.14177919924259186\n",
      "similaridade:0.04521601274609566\n",
      "similaridade:0.004412796813994646\n",
      "similaridade:-0.021743101999163628\n",
      "similaridade:0.10560186207294464\n",
      "similaridade:0.044378723949193954\n",
      "similaridade:-0.0626591369509697\n",
      "similaridade:0.00798563752323389\n",
      "similaridade:-0.045247603207826614\n",
      "similaridade:-0.10909496992826462\n",
      "similaridade:-0.04410599544644356\n",
      "similaridade:0.09316273778676987\n",
      "similaridade:-0.09484045207500458\n",
      "similaridade:0.022844599559903145\n",
      "similaridade:0.030478233471512794\n",
      "similaridade:0.12166750431060791\n",
      "similaridade:0.15761485695838928\n",
      "similaridade:-0.12868867814540863\n",
      "similaridade:-0.09744970500469208\n",
      "similaridade:0.13190089166164398\n",
      "similaridade:0.06845571845769882\n",
      "similaridade:0.03237101063132286\n",
      "similaridade:-0.08279561251401901\n",
      "similaridade:0.06859948486089706\n",
      "similaridade:0.1604427844285965\n",
      "similaridade:0.03548349440097809\n",
      "similaridade:-0.06403281539678574\n",
      "similaridade:0.018302733078598976\n",
      "similaridade:-0.10605323314666748\n",
      "similaridade:0.221949964761734\n",
      "similaridade:-0.11158877611160278\n",
      "similaridade:-0.015832072123885155\n",
      "similaridade:-0.08141347765922546\n",
      "similaridade:-0.23035848140716553\n",
      "similaridade:0.06512422114610672\n",
      "similaridade:-0.01392353419214487\n",
      "similaridade:0.26298466324806213\n",
      "similaridade:-0.07102438807487488\n",
      "similaridade:0.0566580593585968\n",
      "similaridade:0.17465363442897797\n",
      "similaridade:0.021835684776306152\n",
      "similaridade:-0.15896041691303253\n",
      "similaridade:0.02083689160645008\n",
      "similaridade:-0.04156304895877838\n",
      "similaridade:-0.09981115907430649\n",
      "similaridade:0.13110804557800293\n",
      "similaridade:0.2030104398727417\n",
      "similaridade:0.11108996719121933\n",
      "similaridade:0.16337628662586212\n",
      "similaridade:0.06881002336740494\n",
      "similaridade:0.026885559782385826\n",
      "similaridade:0.01819526217877865\n",
      "similaridade:0.029124515131115913\n",
      "similaridade:0.025118131190538406\n",
      "similaridade:-0.18621350824832916\n",
      "similaridade:0.13329949975013733\n",
      "similaridade:0.10235392302274704\n",
      "similaridade:-0.18560028076171875\n",
      "similaridade:0.03021889552474022\n",
      "similaridade:0.03880864754319191\n",
      "similaridade:-0.06475120037794113\n",
      "similaridade:0.01409487146884203\n",
      "similaridade:-0.015907322987914085\n",
      "similaridade:0.039275746792554855\n",
      "similaridade:-0.13498437404632568\n",
      "similaridade:0.18076595664024353\n",
      "similaridade:-0.03149360045790672\n",
      "similaridade:0.08517827838659286\n",
      "similaridade:0.1829725056886673\n",
      "similaridade:-0.11656469851732254\n",
      "similaridade:0.21042315661907196\n",
      "similaridade:-0.11051276326179504\n",
      "similaridade:0.1061854362487793\n",
      "similaridade:-0.09727650135755539\n",
      "similaridade:0.17790454626083374\n",
      "similaridade:0.11656036972999573\n",
      "similaridade:0.15177735686302185\n",
      "similaridade:-0.23585006594657898\n",
      "similaridade:-0.023760000243782997\n",
      "similaridade:0.08150622993707657\n",
      "similaridade:0.22218847274780273\n",
      "similaridade:0.11176195740699768\n",
      "similaridade:-0.017969906330108643\n",
      "similaridade:0.0050019328482449055\n",
      "similaridade:-0.072520412504673\n",
      "similaridade:0.03652728348970413\n",
      "similaridade:-0.0883772149682045\n",
      "similaridade:0.07299673557281494\n",
      "similaridade:0.06864704936742783\n",
      "similaridade:0.162192240357399\n",
      "similaridade:-0.06577209383249283\n",
      "similaridade:-0.19800426065921783\n",
      "similaridade:-0.08918610215187073\n",
      "similaridade:-0.11941282451152802\n",
      "similaridade:-0.04974888265132904\n",
      "similaridade:0.1716223508119583\n",
      "similaridade:-0.25292348861694336\n",
      "similaridade:0.028830723837018013\n",
      "similaridade:0.03185846284031868\n",
      "similaridade:0.08160796016454697\n",
      "similaridade:0.07056136429309845\n",
      "similaridade:0.20702722668647766\n",
      "similaridade:0.09260933101177216\n",
      "similaridade:-0.2672741413116455\n",
      "similaridade:0.13905742764472961\n",
      "similaridade:-0.027636829763650894\n",
      "similaridade:0.029576392844319344\n",
      "similaridade:-0.032631468027830124\n",
      "similaridade:0.08851567655801773\n",
      "similaridade:0.05225343629717827\n",
      "similaridade:-0.05617959424853325\n",
      "similaridade:0.15459217131137848\n",
      "similaridade:-0.07554694265127182\n",
      "similaridade:0.15126658976078033\n",
      "similaridade:-0.07988420128822327\n",
      "similaridade:-0.030312566086649895\n",
      "similaridade:0.039079371839761734\n",
      "similaridade:0.03308675065636635\n",
      "similaridade:0.08903732150793076\n",
      "similaridade:-0.07410197705030441\n",
      "similaridade:0.08051276952028275\n",
      "similaridade:0.18161918222904205\n",
      "similaridade:0.08444585651159286\n",
      "similaridade:0.17987950146198273\n",
      "similaridade:0.1461353898048401\n",
      "similaridade:0.23104426264762878\n",
      "similaridade:-0.03210819512605667\n",
      "similaridade:0.1364498883485794\n",
      "similaridade:-0.11980712413787842\n",
      "similaridade:0.1883891224861145\n",
      "similaridade:-0.09210889786481857\n",
      "similaridade:0.09973135590553284\n",
      "similaridade:0.012565807439386845\n",
      "similaridade:-0.16429446637630463\n",
      "similaridade:-0.021279873326420784\n",
      "similaridade:-0.1313769519329071\n",
      "similaridade:0.1433984339237213\n",
      "similaridade:-0.13276465237140656\n",
      "similaridade:-0.1640564650297165\n",
      "similaridade:0.04739132523536682\n",
      "similaridade:-0.14706949889659882\n",
      "similaridade:-0.029105868190526962\n",
      "similaridade:-0.13776558637619019\n",
      "similaridade:0.030490204691886902\n",
      "similaridade:0.042196933180093765\n",
      "similaridade:0.20460928976535797\n",
      "similaridade:-0.11040880531072617\n",
      "similaridade:0.10132764279842377\n",
      "similaridade:-0.0476280078291893\n",
      "similaridade:-0.08899569511413574\n",
      "similaridade:-0.13523031771183014\n",
      "similaridade:-0.11033421009778976\n",
      "similaridade:0.052093252539634705\n",
      "similaridade:0.019101105630397797\n",
      "similaridade:-0.017028747126460075\n",
      "similaridade:-0.008768283762037754\n",
      "similaridade:0.15041476488113403\n",
      "similaridade:-0.04420628771185875\n",
      "similaridade:-0.022602053359150887\n",
      "similaridade:-0.07181601226329803\n",
      "similaridade:0.042871855199337006\n",
      "similaridade:0.0964561477303505\n",
      "similaridade:-0.02112572081387043\n",
      "similaridade:0.04351473227143288\n",
      "similaridade:0.0874243900179863\n",
      "similaridade:0.06589590758085251\n",
      "similaridade:-0.18709298968315125\n",
      "similaridade:0.08668431639671326\n",
      "similaridade:-0.0752456858754158\n",
      "similaridade:-0.11496874690055847\n",
      "similaridade:0.13694216310977936\n",
      "similaridade:-0.011274472810328007\n",
      "similaridade:0.07822024077177048\n",
      "similaridade:0.02050384320318699\n",
      "similaridade:0.12676452100276947\n",
      "similaridade:-0.05889043211936951\n",
      "similaridade:0.08554352074861526\n",
      "similaridade:-0.11717595905065536\n",
      "similaridade:0.016750136390328407\n",
      "similaridade:-0.03708996623754501\n",
      "similaridade:-7.773377728881314e-05\n",
      "similaridade:-0.2607775628566742\n",
      "similaridade:-0.035127799957990646\n",
      "similaridade:-0.006660808809101582\n",
      "similaridade:0.17766927182674408\n",
      "similaridade:-0.1778227537870407\n",
      "similaridade:0.123989999294281\n",
      "similaridade:0.050946470350027084\n",
      "similaridade:-0.2745634913444519\n",
      "similaridade:-0.06748490780591965\n",
      "similaridade:-0.07740598917007446\n",
      "similaridade:-0.0532618910074234\n",
      "similaridade:-0.13596144318580627\n",
      "similaridade:0.02638401836156845\n",
      "similaridade:0.3125208914279938\n",
      "similaridade:-0.01316453330218792\n",
      "similaridade:-0.06332911550998688\n",
      "similaridade:0.1627754271030426\n",
      "similaridade:0.07134579122066498\n",
      "similaridade:0.03494114801287651\n",
      "similaridade:-0.07285623997449875\n",
      "similaridade:-0.02794281765818596\n",
      "similaridade:-0.0048285857774317265\n",
      "similaridade:0.05636879801750183\n",
      "similaridade:0.0073906416073441505\n",
      "similaridade:0.2277194857597351\n",
      "similaridade:0.016819583252072334\n",
      "similaridade:-0.154817134141922\n",
      "similaridade:-0.014458238147199154\n",
      "similaridade:-0.18372297286987305\n",
      "similaridade:0.22097258269786835\n",
      "similaridade:0.22601452469825745\n",
      "similaridade:0.05104971304535866\n",
      "similaridade:0.18767322599887848\n",
      "similaridade:0.2091701775789261\n",
      "similaridade:-0.01241719163954258\n",
      "similaridade:-0.15876246988773346\n",
      "similaridade:0.11251509934663773\n",
      "similaridade:-0.035976458340883255\n",
      "similaridade:-0.052234385162591934\n",
      "similaridade:0.06494654715061188\n",
      "similaridade:0.07894913852214813\n",
      "similaridade:0.04080304875969887\n",
      "similaridade:-0.028199413791298866\n",
      "similaridade:0.034447770565748215\n",
      "similaridade:0.149708554148674\n",
      "similaridade:0.19013525545597076\n",
      "similaridade:0.08430875092744827\n",
      "similaridade:-0.03939610347151756\n",
      "similaridade:-0.03195786848664284\n",
      "similaridade:0.06757208704948425\n",
      "similaridade:0.11840543150901794\n",
      "similaridade:-0.051519449800252914\n",
      "similaridade:0.05740521475672722\n",
      "similaridade:-0.14455141127109528\n",
      "similaridade:0.07867445051670074\n",
      "similaridade:-0.009678349830210209\n",
      "similaridade:0.03678099811077118\n",
      "similaridade:-0.02961963415145874\n",
      "similaridade:0.08711156994104385\n",
      "similaridade:0.09982219338417053\n",
      "similaridade:-0.09734358638525009\n",
      "similaridade:-0.015563824214041233\n",
      "similaridade:-0.07431665807962418\n",
      "similaridade:0.02333214320242405\n",
      "similaridade:0.06694626808166504\n",
      "similaridade:0.21235717833042145\n",
      "similaridade:0.1672063022851944\n",
      "similaridade:0.2121405154466629\n",
      "similaridade:-0.15318824350833893\n",
      "similaridade:0.08658046275377274\n",
      "similaridade:-0.14097197353839874\n",
      "similaridade:-0.03349779173731804\n",
      "similaridade:0.023510660976171494\n",
      "similaridade:0.05868854001164436\n",
      "similaridade:-0.16546261310577393\n",
      "similaridade:-0.027166562154889107\n",
      "similaridade:0.07948052138090134\n",
      "similaridade:-0.12766899168491364\n",
      "similaridade:0.2585230767726898\n",
      "similaridade:0.11410510540008545\n",
      "similaridade:-0.13001568615436554\n",
      "similaridade:-0.14695444703102112\n",
      "similaridade:-0.03065401129424572\n",
      "similaridade:0.013589819893240929\n",
      "similaridade:-0.004801113624125719\n",
      "similaridade:-0.022075580433011055\n",
      "similaridade:-0.08136624842882156\n",
      "similaridade:0.022999094799160957\n",
      "similaridade:-0.048602018505334854\n",
      "similaridade:-0.14225710928440094\n",
      "similaridade:0.16980867087841034\n",
      "similaridade:-0.13263164460659027\n",
      "similaridade:0.16715459525585175\n",
      "similaridade:0.035655613988637924\n",
      "similaridade:0.07195088267326355\n",
      "similaridade:-0.0039335512556135654\n",
      "similaridade:0.01768018864095211\n",
      "similaridade:0.04029275104403496\n",
      "similaridade:0.17408186197280884\n",
      "similaridade:-0.13732276856899261\n",
      "similaridade:0.002939492929726839\n",
      "similaridade:0.054878149181604385\n",
      "similaridade:-0.013893024064600468\n",
      "similaridade:0.1465172916650772\n",
      "similaridade:0.015945473685860634\n",
      "similaridade:-0.08528808504343033\n",
      "similaridade:0.17177194356918335\n",
      "similaridade:-0.04525603726506233\n",
      "similaridade:0.0634060874581337\n",
      "similaridade:-0.2622225880622864\n",
      "similaridade:-0.040087614208459854\n",
      "similaridade:-0.1960987150669098\n",
      "similaridade:0.035950977355241776\n",
      "similaridade:0.13936765491962433\n",
      "similaridade:0.11976096779108047\n",
      "similaridade:0.01783187873661518\n",
      "similaridade:0.05082506313920021\n",
      "similaridade:0.21062316000461578\n",
      "similaridade:0.09493818134069443\n",
      "similaridade:-0.033470090478658676\n",
      "similaridade:0.010435597039759159\n",
      "similaridade:-0.09949635714292526\n",
      "similaridade:-0.11527716368436813\n",
      "similaridade:-0.05950826033949852\n",
      "similaridade:0.06907930970191956\n",
      "similaridade:0.09857461601495743\n",
      "similaridade:0.036124151200056076\n",
      "similaridade:0.14362011849880219\n",
      "similaridade:0.019179577007889748\n",
      "similaridade:0.12360905110836029\n",
      "similaridade:-0.0065782819874584675\n",
      "similaridade:-0.08311659842729568\n",
      "similaridade:0.11981915682554245\n",
      "similaridade:0.04947490990161896\n",
      "similaridade:0.1812952756881714\n",
      "similaridade:-0.06262704730033875\n",
      "similaridade:0.08978146314620972\n",
      "similaridade:-0.18024832010269165\n",
      "similaridade:0.2690761387348175\n",
      "similaridade:0.1528499275445938\n",
      "similaridade:-0.01782863400876522\n",
      "similaridade:0.10873281210660934\n",
      "similaridade:0.030420977622270584\n",
      "similaridade:-0.11291619390249252\n",
      "similaridade:0.05924424156546593\n",
      "similaridade:-0.0505848154425621\n",
      "similaridade:-0.08825614303350449\n",
      "similaridade:-0.02130366675555706\n",
      "similaridade:-0.05076814815402031\n",
      "similaridade:-0.018816975876688957\n",
      "similaridade:-0.17724116146564484\n",
      "similaridade:-0.015406460501253605\n",
      "similaridade:0.05756330117583275\n",
      "similaridade:-0.07087182253599167\n",
      "similaridade:0.15055477619171143\n",
      "similaridade:0.07963447272777557\n",
      "similaridade:0.06678537279367447\n",
      "similaridade:0.033570025116205215\n",
      "similaridade:-0.012125753797590733\n",
      "similaridade:0.08434843271970749\n",
      "similaridade:0.04788384586572647\n",
      "similaridade:0.04755000025033951\n",
      "similaridade:-0.033637821674346924\n",
      "similaridade:-0.09891672432422638\n",
      "similaridade:0.2151281088590622\n",
      "similaridade:0.17719562351703644\n",
      "similaridade:-0.02638183906674385\n",
      "similaridade:-0.040286000818014145\n",
      "similaridade:0.10289943218231201\n",
      "similaridade:0.04718038812279701\n",
      "similaridade:0.12780331075191498\n",
      "similaridade:0.038037288933992386\n",
      "similaridade:0.15142974257469177\n",
      "similaridade:0.044914018362760544\n",
      "similaridade:-0.14650915563106537\n",
      "similaridade:0.29379725456237793\n",
      "similaridade:-0.02241445519030094\n",
      "similaridade:0.08256447315216064\n",
      "similaridade:-0.10861025005578995\n",
      "similaridade:-0.20125453174114227\n",
      "similaridade:-0.19032169878482819\n",
      "similaridade:0.16858932375907898\n",
      "similaridade:0.11833422631025314\n",
      "similaridade:-0.10358225554227829\n",
      "similaridade:0.10349275171756744\n",
      "similaridade:-0.08821520209312439\n",
      "similaridade:0.05745850130915642\n",
      "similaridade:-0.18430419266223907\n",
      "similaridade:0.08537006378173828\n",
      "similaridade:0.07903111726045609\n",
      "similaridade:0.1243574395775795\n",
      "similaridade:0.03827377036213875\n",
      "similaridade:0.03790367767214775\n",
      "similaridade:0.12647569179534912\n",
      "similaridade:0.1810290366411209\n",
      "similaridade:0.2876476049423218\n",
      "similaridade:0.22260022163391113\n",
      "similaridade:0.00015468151832465082\n",
      "similaridade:0.051601748913526535\n",
      "similaridade:0.11078042536973953\n",
      "similaridade:0.11930140107870102\n",
      "similaridade:0.012999651953577995\n",
      "similaridade:0.06654660403728485\n",
      "similaridade:-0.09913112968206406\n",
      "similaridade:0.311646431684494\n",
      "similaridade:-0.05093703046441078\n",
      "similaridade:-0.05969015881419182\n",
      "similaridade:0.16195951402187347\n",
      "similaridade:0.06761222332715988\n",
      "similaridade:-0.09500299394130707\n",
      "similaridade:0.14151664078235626\n",
      "similaridade:0.14033639430999756\n",
      "similaridade:-0.15963482856750488\n",
      "similaridade:0.15818171203136444\n",
      "similaridade:-0.002611391479149461\n",
      "similaridade:-0.1350434124469757\n",
      "similaridade:0.24419063329696655\n",
      "similaridade:0.021210284903645515\n",
      "similaridade:-0.111720971763134\n",
      "similaridade:0.14482522010803223\n",
      "similaridade:-0.12702564895153046\n",
      "similaridade:0.07966851443052292\n",
      "similaridade:-0.17098823189735413\n",
      "similaridade:0.22295932471752167\n",
      "similaridade:-0.05162624642252922\n",
      "similaridade:0.16293121874332428\n",
      "similaridade:0.01366481650620699\n",
      "similaridade:-0.055748630315065384\n",
      "similaridade:-0.15307237207889557\n",
      "similaridade:-0.12022773176431656\n",
      "similaridade:0.048885513097047806\n",
      "similaridade:-0.09368579089641571\n",
      "similaridade:-0.0042311218567192554\n",
      "similaridade:-0.00023629334464203566\n",
      "similaridade:0.14501745998859406\n",
      "similaridade:-0.1549464762210846\n",
      "similaridade:0.11623276770114899\n",
      "similaridade:-0.13337905704975128\n",
      "similaridade:-0.04953690618276596\n",
      "similaridade:0.021723488345742226\n",
      "similaridade:-0.08449094742536545\n",
      "similaridade:-0.04541894420981407\n",
      "similaridade:0.05021582543849945\n",
      "similaridade:0.22190406918525696\n",
      "similaridade:0.2459787279367447\n",
      "similaridade:-0.14493826031684875\n",
      "similaridade:0.08881840854883194\n",
      "similaridade:0.19071991741657257\n",
      "similaridade:0.06058989092707634\n",
      "similaridade:0.16169655323028564\n",
      "similaridade:-0.0068202996626496315\n",
      "similaridade:0.15300621092319489\n",
      "similaridade:-0.04462268948554993\n",
      "similaridade:0.14520953595638275\n",
      "similaridade:0.1667809635400772\n",
      "similaridade:0.09673453122377396\n",
      "similaridade:0.05361755192279816\n",
      "similaridade:0.26978635787963867\n",
      "similaridade:-0.1049441546201706\n",
      "similaridade:0.10092508047819138\n",
      "similaridade:0.04899142310023308\n",
      "similaridade:0.2403927892446518\n",
      "similaridade:-0.040812063962221146\n",
      "similaridade:-0.24369028210639954\n",
      "similaridade:0.17883498966693878\n",
      "similaridade:-0.0038955288473516703\n",
      "similaridade:0.034784745424985886\n",
      "similaridade:0.047556210309267044\n",
      "similaridade:-0.021910717710852623\n",
      "similaridade:0.08284535259008408\n",
      "similaridade:0.17238450050354004\n",
      "similaridade:-0.05686897411942482\n",
      "similaridade:-0.1016523614525795\n",
      "similaridade:0.1776634007692337\n",
      "similaridade:0.08954819291830063\n",
      "similaridade:0.1269383281469345\n",
      "similaridade:-0.12203660607337952\n",
      "similaridade:-0.06549202650785446\n",
      "similaridade:0.06136210262775421\n",
      "similaridade:0.01724296249449253\n",
      "similaridade:0.07541552931070328\n",
      "similaridade:0.004206877667456865\n",
      "similaridade:-0.22234803438186646\n",
      "similaridade:0.17918699979782104\n",
      "similaridade:-0.04389851167798042\n",
      "similaridade:0.06440199166536331\n",
      "similaridade:0.059799548238515854\n",
      "similaridade:-0.11350452899932861\n",
      "similaridade:0.03309407830238342\n",
      "similaridade:0.002170637482777238\n",
      "similaridade:-0.21061153709888458\n",
      "similaridade:0.03956810384988785\n",
      "similaridade:0.12600544095039368\n",
      "similaridade:0.16164976358413696\n",
      "similaridade:-0.108803890645504\n",
      "similaridade:0.05556381866335869\n",
      "similaridade:-0.10990345478057861\n",
      "similaridade:0.24316969513893127\n",
      "similaridade:-0.03341837227344513\n",
      "similaridade:0.2223130613565445\n",
      "similaridade:-0.039755310863256454\n",
      "similaridade:-0.08277242630720139\n",
      "similaridade:-0.07649808377027512\n",
      "similaridade:-0.069064199924469\n",
      "similaridade:-0.00703451270237565\n",
      "similaridade:-0.0684141293168068\n",
      "similaridade:0.042175550013780594\n",
      "similaridade:0.21542584896087646\n",
      "similaridade:-0.13497596979141235\n",
      "similaridade:-0.07660416513681412\n",
      "similaridade:0.04255995154380798\n",
      "similaridade:0.06668306142091751\n",
      "similaridade:0.12084897607564926\n",
      "similaridade:-0.11719320714473724\n",
      "similaridade:0.0909658819437027\n",
      "similaridade:-0.07746980339288712\n",
      "similaridade:3.8826841773698106e-05\n",
      "similaridade:0.09938258677721024\n",
      "similaridade:-0.1666683405637741\n",
      "similaridade:0.03377702459692955\n",
      "similaridade:-0.20815101265907288\n",
      "similaridade:0.05715930089354515\n",
      "similaridade:0.1328965425491333\n",
      "similaridade:0.010248777456581593\n",
      "similaridade:0.1691344529390335\n",
      "similaridade:0.06772448867559433\n",
      "similaridade:-0.006943949032574892\n",
      "similaridade:0.09755382686853409\n",
      "similaridade:0.1068250834941864\n",
      "similaridade:0.06881832331418991\n",
      "similaridade:-0.05378352478146553\n",
      "similaridade:0.12913648784160614\n",
      "similaridade:0.3091040551662445\n",
      "similaridade:0.058807674795389175\n",
      "similaridade:-0.09081870317459106\n",
      "similaridade:0.1415681093931198\n",
      "similaridade:0.225487619638443\n",
      "similaridade:-0.26027777791023254\n",
      "similaridade:0.18548312783241272\n",
      "similaridade:0.15969449281692505\n",
      "similaridade:-0.01860698312520981\n",
      "similaridade:0.10958826541900635\n",
      "similaridade:0.0970768854022026\n",
      "similaridade:-0.08439938724040985\n",
      "similaridade:-0.12782299518585205\n",
      "similaridade:0.2622981369495392\n",
      "similaridade:0.045109644532203674\n",
      "similaridade:-0.025282884016633034\n",
      "similaridade:-0.20627610385417938\n",
      "similaridade:0.08384709060192108\n",
      "similaridade:-0.016746370121836662\n",
      "similaridade:-0.0010506772669032216\n",
      "similaridade:-0.019855881109833717\n",
      "similaridade:0.12621456384658813\n",
      "similaridade:0.17281557619571686\n",
      "similaridade:0.0031083854846656322\n",
      "similaridade:0.1533908098936081\n",
      "No match found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pickle\n",
    "from model_RA.fp_RA.melspec.melspectrogram_RA import get_melspec_layer\n",
    "from model_RA.fp_RA.nnfp import get_fingerprinter\n",
    "\n",
    "# Configurações de ambiente\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Função para limpar a GPU\n",
    "\"\"\"def clean_gpu():\n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()\n",
    "clean_gpu()\n",
    "\n",
    "# Configuração da GPU no TensorFlow\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Funções principais (assumindo que essas funções já estão definidas anteriormente)\n",
    "def build_fp(cfg):\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "\n",
    "    return m_pre, m_fp\n",
    "\n",
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def predict(X, m_fp):\n",
    "    emb_gf = m_fp(X)\n",
    "    return emb_gf\n",
    "\n",
    "def load_model():\n",
    "    checkpoint_name_dir = \"./logs/CHECK_BFTRI_100\"\n",
    "    config = \"default_RA\"\n",
    "    cfg = load_config(config)\n",
    "    _, m_fp = build_fp(cfg)\n",
    "    checkpoint = tf.train.Checkpoint(m_fp)\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_name_dir))\n",
    "    return m_fp\n",
    "\n",
    "def run(filepath, fs, m_fp):\n",
    "    if isinstance(filepath, str):\n",
    "        print(f\"file entrada: {filepath}\")\n",
    "        signal, fs = librosa.load(filepath, mono=True, sr=8000)\n",
    "\n",
    "    if fs != 8000:\n",
    "        signal = librosa.resample(signal, fs, 8000)\n",
    "        fs = 8000\n",
    "\n",
    "    fs = 8000\n",
    "    win_sz = fs\n",
    "    hop_sz = int(fs / 2)\n",
    "    if len(signal) < win_sz:\n",
    "        signal = librosa.util.pad_center(signal, size=win_sz, mode='constant')\n",
    "    if len(signal) > 1.5 * win_sz:\n",
    "        frames = np.transpose(librosa.util.frame(signal, frame_length=win_sz, hop_length=hop_sz))\n",
    "    else:\n",
    "        frames = signal[:fs][None, :]\n",
    "\n",
    "    X = frames[np.newaxis, np.newaxis, ...]\n",
    "    X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    X = tf.transpose(X, perm=[2, 0, 1, 3])\n",
    "\n",
    "    emb = predict(X, m_fp)\n",
    "    tf.config.run_functions_eagerly(True)\n",
    "    return emb.numpy()\n",
    "\n",
    "# Função para carregar impressões digitais da base de dados\n",
    "def load_database_fingerprints(database_path):\n",
    "    with open(database_path, 'rb') as f:\n",
    "        database_fingerprints = pickle.load(f)\n",
    "    return database_fingerprints\n",
    "\n",
    "def load_database_fingerprints_folder(database_folder):\n",
    "    database_fingerprints = []\n",
    "    \n",
    "    # Percorrer todos os arquivos na pasta\n",
    "    for filename in os.listdir(database_folder):\n",
    "        file_path = os.path.join(database_folder, filename)\n",
    "        \n",
    "        # Verificar se o arquivo é um arquivo pickle\n",
    "        if os.path.isfile(file_path) and file_path.endswith('.pkl'):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                fingerprint = pickle.load(f)\n",
    "                database_fingerprints.append(fingerprint)\n",
    "    \n",
    "    return database_fingerprints\n",
    "\n",
    "# Função para calcular a similaridade entre dois vetores\n",
    "def calculate_similarity(emb1, emb2):\n",
    "    #return np.dot(emb1[0], emb2[0])\n",
    "    return np.dot(emb1[0], emb2[0]) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "\n",
    "# Função principal para prever se o query está na base de dados\n",
    "def predict_query(query_file, database_fingerprints, similarity_threshold=0.8):\n",
    "    # Carrega o modelo\n",
    "    model_fp = load_model()\n",
    "    \n",
    "    # Carrega e processa o arquivo de áudio do query\n",
    "    signal, sampling_rate = librosa.load(query_file, sr=None)\n",
    "    \n",
    "    # Gera a impressão digital do áudio do query\n",
    "    emb_vector = run(query_file, sampling_rate, model_fp)\n",
    "    \n",
    "    # Verifica a similaridade com cada impressão digital na base de dados\n",
    "    for db_emb in database_fingerprints:\n",
    "        #print(f\"db_emb:{db_emb.shape}\")\n",
    "        #print(f\"emb_vector:{emb_vector.shape}\")\n",
    "        #print(f\"dot:{np.dot(emb_vector[0], db_emb[0])}\")\n",
    "        #print(f\"linalog:{np.linalg.norm(db_emb)}\")\n",
    "        print(f\"similaridade:{np.dot(emb_vector[0].flatten(), db_emb[0].flatten()) / (np.linalg.norm(emb_vector[0].flatten()) * np.linalg.norm(db_emb[0].flatten()))}\")\n",
    "        similarity = calculate_similarity(emb_vector.flatten(), db_emb.flatten())\n",
    "        if similarity >= similarity_threshold:\n",
    "            print(f\"Match found with similarity: {similarity}\")\n",
    "            return True\n",
    "    \n",
    "    print(\"No match found.\")\n",
    "    return False\n",
    "\n",
    "# Exemplo de uso\n",
    "database_path = '/mnt/dataset/public/Fingerprinting/features/fma_full/000'\n",
    "#query_file = '/mnt/dataset/public/Fingerprinting/query_procura/000134.wav'\n",
    "#query_file = '/mnt/dataset/public/Fingerprinting/query_procura/000003.wav'\n",
    "query_file = '/mnt/dataset/public/Fingerprinting/query_procura/000020.wav'\n",
    "#query_file = '/mnt/dataset/public/Fingerprinting/query_procura/000003.wav'\n",
    "database_fingerprints = load_database_fingerprints_folder(database_path)\n",
    "is_in_database = predict_query(query_file, database_fingerprints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
