{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 15:51:02.230016: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=128\n",
    "unit_dim=[32, 1]\n",
    "def arquitetura_densas_teste(input):\n",
    "        x = tf.keras.layers.Dense(unit_dim[0], activation='elu')(input)\n",
    "        x = tf.keras.layers.Dense(unit_dim[1])(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camadas_densas_teste():\n",
    "        q = 128\n",
    "        y_list = [0]*q\n",
    "\n",
    "        input = tf.ones(shape=(120, 256, 32, 1))\n",
    "        x = tf.reshape(input, shape=[input.shape[0], q, -1])\n",
    "\n",
    "        x_split = tf.split(x, num_or_size_splits=128, axis=1)\n",
    "\n",
    "        #Dados as 128 redes, \n",
    "        for v in enumerate(x_split):\n",
    "                y_list[v] = tf.keras.Sequential(camadas_densas(v))\n",
    "\n",
    "        return tf.keras.layers.Concatenate(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "div_enc_layer() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 113\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fingerprinting_model\n\u001b[1;32m    112\u001b[0m conv_layer \u001b[38;5;241m=\u001b[39m create_sequential_front_conv()\n\u001b[0;32m--> 113\u001b[0m enc_layer \u001b[38;5;241m=\u001b[39m \u001b[43mdiv_enc_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m finger_model \u001b[38;5;241m=\u001b[39m get_fingerprinting(conv_layer, enc_layer)\n\u001b[1;32m    117\u001b[0m y \u001b[38;5;241m=\u001b[39m finger_model(tf\u001b[38;5;241m.\u001b[39mones(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m120\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: div_enc_layer() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "def convlayer(hidden_ch=128,\n",
    "              strides=[(1,1),(1,1)],\n",
    "              norm='layer_norm2d'):\n",
    "    \n",
    "    \n",
    "    conv2d_1x3 = tf.keras.layers.Conv2D(hidden_ch,\n",
    "                                        kernel_size=(1, 3),\n",
    "                                        strides=strides[0],\n",
    "                                        padding='SAME',\n",
    "                                        dilation_rate=(1, 1),\n",
    "                                        kernel_initializer='glorot_uniform',\n",
    "                                        bias_initializer='zeros')\n",
    "    conv2d_3x1 = tf.keras.layers.Conv2D(hidden_ch,\n",
    "                                        kernel_size=(3, 1),\n",
    "                                        strides=strides[1],\n",
    "                                        padding='SAME',\n",
    "                                        dilation_rate=(1, 1),\n",
    "                                        kernel_initializer='glorot_uniform',\n",
    "                                        bias_initializer='zeros')\n",
    "    \n",
    "    if norm == 'layer_norm1d':\n",
    "        BN_1x3 = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "        BN_3x1 = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "    elif norm == 'layer_norm2d':\n",
    "        BN_1x3 = tf.keras.layers.LayerNormalization(axis=(1, 2, 3))\n",
    "        BN_3x1 = tf.keras.layers.LayerNormalization(axis=(1, 2, 3))\n",
    "    else:\n",
    "        BN_1x3 = tf.keras.layers.BatchNormalization(axis=-1) # Fix axis: 2020 Apr20\n",
    "        BN_3x1 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        \n",
    "    forward = tf.keras.Sequential([conv2d_1x3,\n",
    "                                    tf.keras.layers.ELU(),\n",
    "                                    BN_1x3,\n",
    "                                    conv2d_3x1,\n",
    "                                    tf.keras.layers.ELU(),\n",
    "                                    BN_3x1\n",
    "                                    ])\n",
    "    \n",
    "    return forward\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def denselayer(input, q=128, unit_dim=[32, 1]):\n",
    "    \n",
    "    def arquiteturas_densas(input):\n",
    "        x = tf.keras.layers.Dense(unit_dim[0], activation='elu')(input)\n",
    "        x = tf.keras.layers.Dense(unit_dim[1])(x)\n",
    "        return x\n",
    "    \n",
    "    def camadas_densas(input):\n",
    "        y_list = [0]*q # lista vazia de tamanho 128, para guardar as 128 redes\n",
    "\n",
    "        #input = tf.ones((120, 1, 1, 1024))\n",
    "        x = tf.reshape(input, shape=[input.shape[0], q, -1])\n",
    "\n",
    "        x_split = tf.split(x, num_or_size_splits=128, axis=1) # faz o split em 128 vetores de igual tamanho (8)\n",
    "\n",
    "        #Dados as 128 redes\n",
    "        for v in enumerate(x_split):\n",
    "                y_list[v] = tf.keras.Sequential(arquiteturas_densas(input=v))\n",
    "\n",
    "        return y_list\n",
    "    \n",
    "    #concatena a lista, ficando com um emb de 128\n",
    "    return tf.keras.layers.Concatenate(camadas_densas(input=input))\n",
    "\n",
    "\n",
    "def create_sequential_front_conv(input_shape=(256,32,1),\n",
    "                                    emb_sz=128, # q\n",
    "                                    front_hidden_ch=[128, 128, 256, 256, 512, 512, 1024, 1024],\n",
    "                                    front_strides=[[(1,2), (2,1)], [(1,2), (2,1)],\n",
    "                                                   [(1,2), (2,1)], [(1,2), (2,1)],\n",
    "                                                   [(1,1), (2,1)], [(1,2), (2,1)],\n",
    "                                                   [(1,1), (2,1)], [(1,2), (2,1)]],\n",
    "                                    norm='layer_norm2d'):\n",
    "\n",
    "    front_conv = tf.keras.Sequential(name='ConvLayers')\n",
    "    if ((front_hidden_ch[-1] % emb_sz) != 0):\n",
    "        front_hidden_ch[-1] = ((front_hidden_ch[-1]//emb_sz) + 1) * emb_sz\n",
    "\n",
    "    for i in range(len(front_strides)):\n",
    "        front_conv.add(convlayer(hidden_ch=front_hidden_ch[i], strides=front_strides[i], norm=norm))\n",
    "    front_conv.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    return front_conv\n",
    "\n",
    "\n",
    "\n",
    "def div_enc_layer(input, emb_sz=128, fc_unit_dim=[32,1]):\n",
    "    \n",
    "    div_enc = tf.keras.Sequential(name=\"DivEnclayer\")\n",
    "    div_enc.add(denselayer(input, q=emb_sz, unit_dim=fc_unit_dim))\n",
    "\n",
    "    return div_enc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_fingerprinting(conv_model, div_enc):\n",
    "    \n",
    "    fingerprinting_model = tf.keras.Sequential(name='Fingerprinting')\n",
    "    fingerprinting_model.add(conv_model)\n",
    "    fingerprinting_model.add(div_enc)\n",
    "    fingerprinting_model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
    "    \n",
    "    return fingerprinting_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "conv_layer = create_sequential_front_conv()\n",
    "enc_layer = div_enc_layer()\n",
    "\n",
    "finger_model = get_fingerprinting(conv_layer, enc_layer)\n",
    "\n",
    "y = finger_model(tf.ones(shape=(120, 256, 32, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer(hidden_ch=128,\n",
    "              strides=[(1,1),(1,1)],\n",
    "              norm='layer_norm2d'):\n",
    "    \n",
    "    \n",
    "    conv2d_1x3 = tf.keras.layers.Conv2D(hidden_ch,\n",
    "                                        kernel_size=(1, 3),\n",
    "                                        strides=strides[0],\n",
    "                                        padding='SAME',\n",
    "                                        dilation_rate=(1, 1),\n",
    "                                        kernel_initializer='glorot_uniform',\n",
    "                                        bias_initializer='zeros')\n",
    "    conv2d_3x1 = tf.keras.layers.Conv2D(hidden_ch,\n",
    "                                        kernel_size=(3, 1),\n",
    "                                        strides=strides[1],\n",
    "                                        padding='SAME',\n",
    "                                        dilation_rate=(1, 1),\n",
    "                                        kernel_initializer='glorot_uniform',\n",
    "                                        bias_initializer='zeros')\n",
    "    \n",
    "    if norm == 'layer_norm1d':\n",
    "        BN_1x3 = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "        BN_3x1 = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "    elif norm == 'layer_norm2d':\n",
    "        BN_1x3 = tf.keras.layers.LayerNormalization(axis=(1, 2, 3))\n",
    "        BN_3x1 = tf.keras.layers.LayerNormalization(axis=(1, 2, 3))\n",
    "    else:\n",
    "        BN_1x3 = tf.keras.layers.BatchNormalization(axis=-1) # Fix axis: 2020 Apr20\n",
    "        BN_3x1 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        \n",
    "    forward = tf.keras.Sequential([conv2d_1x3,\n",
    "                                    tf.keras.layers.ELU(),\n",
    "                                    BN_1x3,\n",
    "                                    conv2d_3x1,\n",
    "                                    tf.keras.layers.ELU(),\n",
    "                                    BN_3x1\n",
    "                                    ])\n",
    "    \n",
    "    return forward\n",
    "\n",
    "\n",
    "def divenclayer(input, q=128, unit_dim=[32, 1]):\n",
    "    \n",
    "    def arquiteturas_densas(input):\n",
    "        x = tf.keras.layers.Dense(unit_dim[0], activation='elu')(input)\n",
    "        x = tf.keras.layers.Dense(unit_dim[1])(x)\n",
    "        return x\n",
    "    \n",
    "    def camadas_densas(input):\n",
    "        y_list = [0]*q # lista vazia de tamanho 128, para guardar as 128 redes\n",
    "\n",
    "        #input = tf.ones((120, 1, 1, 1024))\n",
    "        x = tf.reshape(input, shape=[input.shape[0], q, -1])\n",
    "\n",
    "        x_split = tf.split(x, num_or_size_splits=128, axis=1) # faz o split em 128 vetores de igual tamanho (8)\n",
    "\n",
    "        #Dados as 128 redes\n",
    "        for v in enumerate(x_split):\n",
    "                y_list[v] = tf.keras.Sequential(arquiteturas_densas(input=v))\n",
    "\n",
    "        return y_list\n",
    "    \n",
    "    #concatena a lista, ficando com um emb de 128\n",
    "    return tf.keras.layers.Concatenate(camadas_densas(input=input))\n",
    "    \n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    #tf.split(value, num_or_size_splits, axis=0, num=None, name='split')\n",
    "\n",
    "    x_split = tf.split(value=input, num_or_size_splits=q, name='split')\n",
    "\n",
    "    y_list = [0]*q \n",
    "\n",
    "    #Dados as 128 redes, \n",
    "    for v in enumerate(x_split):\n",
    "        #for k in enumerate(v):\n",
    "        y_list[v] = tf.keras.Sequential(camadas_densas(v))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    1 camada - split, divir em 128 partes, deve sair uma lista de pedaços, vour fazer um for a partir dos dados do split, e vou fazer o y= split(x), um x_list = tf.keras\n",
    "    vou dar um for em cima do negocio,, y=denseparallel (x)\n",
    "\n",
    "\n",
    "    x_list = tf.keras.layers.split (x)\n",
    "\n",
    "    y_list=[0]*128\n",
    "\n",
    "    for v in enumerate(x_split):\n",
    "        for k, enumerate(x_list):\n",
    "            y[k] = denseparallel(v)\n",
    "        #aloca a lista e no for já indexo a list adireto\n",
    "    \n",
    "        x=tf.keras.concatenado(x_list)\n",
    "\n",
    "    \n",
    "    def construct_layers():\n",
    "        layers = list()\n",
    "        for _ in range(q): # q: num_slices\n",
    "            layers.append(tf.keras.Sequential([tf.keras.layers.Dense(unit_dim[0], activation='elu'),\n",
    "                                               tf.keras.layers.Dense(unit_dim[1])]))\n",
    "        return layers\n",
    "            \n",
    "    x = tf.reshape(x, shape=[x.shape[0], q, -1])\n",
    "    \n",
    "    out = list()\n",
    "    for i in range(q):\n",
    "        out.append(construct_layers[i](x[:, i, :]))\n",
    "    \n",
    "    return tf.concat(out, axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequential_front_conv(input_shape=(256,32,1),\n",
    "                                    emb_sz=128, # q\n",
    "                                    front_hidden_ch=[128, 128, 256, 256, 512, 512, 1024, 1024],\n",
    "                                    front_strides=[[(1,2), (2,1)], [(1,2), (2,1)],\n",
    "                                                   [(1,2), (2,1)], [(1,2), (2,1)],\n",
    "                                                   [(1,1), (2,1)], [(1,2), (2,1)],\n",
    "                                                   [(1,1), (2,1)], [(1,2), (2,1)]],\n",
    "                                    norm='layer_norm2d'):\n",
    "\n",
    "    front_conv = tf.keras.Sequential(name='ConvLayers')\n",
    "    if ((front_hidden_ch[-1] % emb_sz) != 0):\n",
    "        front_hidden_ch[-1] = ((front_hidden_ch[-1]//emb_sz) + 1) * emb_sz\n",
    "\n",
    "    for i in range(len(front_strides)):\n",
    "        front_conv.add(convlayer(hidden_ch=front_hidden_ch[i], strides=front_strides[i], norm=norm))\n",
    "    front_conv.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    return front_conv\n",
    "\n",
    "def div_enc_layer(emb_sz=128, fc_unit_dim=[32,1], norm='layer_norm2d'):\n",
    "    \n",
    "    div_enc = tf.keras.Sequential(name=\"DivEnclayer\")\n",
    "    div_enc.add(divenclayer(q=emb_sz, unit_dim=fc_unit_dim))\n",
    "    #div_enc.add(DivEncLayer(q=emb_sz, unit_dim=fc_unit_dim, norm=norm))\n",
    "\n",
    "    return div_enc\n",
    "\n",
    "\n",
    "def get_fingerprinting(conv_model, div_enc):\n",
    "    \n",
    "    fingerprinting_model = tf.keras.Sequential(name='Fingerprinting')\n",
    "    fingerprinting_model.add(conv_model)\n",
    "    fingerprinting_model.add(div_enc)\n",
    "    fingerprinting_model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
    "    \n",
    "    return fingerprinting_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "divenclayer.<locals>.camadas_densas() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m conv_layer \u001b[38;5;241m=\u001b[39m create_sequential_front_conv()\n\u001b[0;32m----> 2\u001b[0m enc_layer \u001b[38;5;241m=\u001b[39m \u001b[43mdiv_enc_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m finger_model \u001b[38;5;241m=\u001b[39m get_fingerprinting(conv_layer, enc_layer) \n",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m, in \u001b[0;36mdiv_enc_layer\u001b[0;34m(emb_sz, fc_unit_dim, norm)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdiv_enc_layer\u001b[39m(emb_sz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, fc_unit_dim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m1\u001b[39m], norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_norm2d\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     22\u001b[0m     div_enc \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDivEnclayer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m     div_enc\u001b[38;5;241m.\u001b[39madd(\u001b[43mdivenclayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb_sz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfc_unit_dim\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#div_enc.add(DivEncLayer(q=emb_sz, unit_dim=fc_unit_dim, norm=norm))\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m div_enc\n",
      "Cell \u001b[0;32mIn[7], line 65\u001b[0m, in \u001b[0;36mdivenclayer\u001b[0;34m(q, unit_dim)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m#return tf.keras.layers.Concatenate(y_list)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconcat(y_list)\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcamadas_densas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    #tf.split(value, num_or_size_splits, axis=0, num=None, name='split')\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    return tf.concat(out, axis=1)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: divenclayer.<locals>.camadas_densas() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "conv_layer = create_sequential_front_conv()\n",
    "enc_layer = div_enc_layer()\n",
    "\n",
    "finger_model = get_fingerprinting(conv_layer, enc_layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = finger_model(tf.ones(shape=(120, 256, 32, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Fingerprinting\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ConvLayers (Sequential)     (120, 1024)               16897920  \n",
      "                                                                 \n",
      " DivEnclayer (Sequential)    (120, 128)                41088     \n",
      "                                                                 \n",
      " lambda (Lambda)             (120, 128)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16939008 (64.62 MB)\n",
      "Trainable params: 16939008 (64.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "finger_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Função para criar o bloco de camadas densas\n",
    "def create_dense_block(units: list):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units[0], activation='elu'),\n",
    "        tf.keras.layers.Dense(units[1])\n",
    "    ])\n",
    "\n",
    "# Criar o modelo\n",
    "def create_model(input_shape=(256, 256, 3), num_blocks=128, block_size=8):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Primeiro bloco convolucional e average pooling\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())  # Average pooling para saída 1024\n",
    "    \n",
    "    # Divisão em 128 blocos\n",
    "    split_layer = tf.keras.layers.Lambda(lambda x: tf.split(x, num_blocks, axis=1))\n",
    "    model.add(split_layer)\n",
    "    \n",
    "    # Sequencial de camadas densas para cada bloco\n",
    "    for _ in range(num_blocks):\n",
    "        model.add(create_dense_block(units=[32,1]))\n",
    "    \n",
    "    # Concatenação dos resultados\n",
    "    model.add(tf.keras.layers.Concatenate(axis=1))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Criar o modelo\n",
    "model = create_model()\n",
    "# Sumário do modelo\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivEncLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi-head projection a.k.a. 'divide and encode' layer:\n",
    "        \n",
    "    • The concept of 'divide and encode' was discovered  in Lai et.al.,\n",
    "     'Simultaneous Feature Learning and Hash Coding with Deep Neural Networks',\n",
    "      2015. https://arxiv.org/abs/1504.03410\n",
    "    • It was also adopted in Gfeller et.al. 'Now Playing: Continuo-\n",
    "      us low-power music recognition', 2017. https://arxiv.org/abs/1711.10958\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    q: (int) number of slices as 'slice_length = input_dim / q'\n",
    "    unit_dim: [(int), (int)]\n",
    "    norm: 'layer_norm1d' or 'layer_norm2d' uses 1D-layer normalization on the feature.\n",
    "          'batch_norm' or else uses batch normalization. Default is 'layer_norm2d'.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    x: (B,1,1,C)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    emb: (B,Q)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, q=128, unit_dim=[32, 1], norm='batch_norm'):\n",
    "        super(DivEncLayer, self).__init__()\n",
    "\n",
    "        self.q = q\n",
    "        self.unit_dim = unit_dim\n",
    "        self.norm = norm\n",
    "        \n",
    "        if norm in ['layer_norm1d', 'layer_norm2d']:\n",
    "            self.BN = [tf.keras.layers.LayerNormalization(axis=-1) for i in range(q)]\n",
    "        else:\n",
    "            self.BN = [tf.keras.layers.BatchNormalization(axis=-1) for i in range(q)]\n",
    "            \n",
    "        self.split_fc_layers = self._construct_layers() \n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Prepare output embedding variable for dynamic batch-size \n",
    "        self.slice_length = int(input_shape[-1] / self.q)\n",
    "\n",
    " \n",
    "    def _construct_layers(self):\n",
    "        layers = list()\n",
    "        for i in range(self.q): # q: num_slices\n",
    "            layers.append(tf.keras.Sequential([tf.keras.layers.Dense(self.unit_dim[0], activation='elu'),\n",
    "                                               #self.BN[i],\n",
    "                                               tf.keras.layers.Dense(self.unit_dim[1])]))\n",
    "        return layers\n",
    "\n",
    " \n",
    "    @tf.function\n",
    "    def _split_encoding(self, x_slices):\n",
    "        \"\"\"\n",
    "        Input: (B,Q,S)\n",
    "        Returns: (B,Q)\n",
    "        \n",
    "        \"\"\"\n",
    "        out = list()\n",
    "        for i in range(self.q):\n",
    "            out.append(self.split_fc_layers[i](x_slices[:, i, :]))\n",
    "        return tf.concat(out, axis=1)\n",
    "\n",
    "    \n",
    "    def call(self, x): # x: (B,1,1,2048)\n",
    "        x = tf.reshape(x, shape=[x.shape[0], self.q, -1]) # (B,Q,S); Q=num_slices; S=slice length; (B,128,8 or 16)\n",
    "        return self._split_encoding(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
