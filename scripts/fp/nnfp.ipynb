{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4110b4f6-4549-479b-93c0-ec7875dab754",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **nnfp**\n",
    "\n",
    "Nesta file consta a arquitetura da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f430331-ad9c-40ff-9bc4-7e7480626fbb",
   "metadata": {},
   "source": [
    "Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36fce0de-9aee-4e2e-98df-1eed1b903bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 14:57:44.561224: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-26 14:57:45.224054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\"\"\" nnfp.py\n",
    "\n",
    "'Neural Audio Fingerprint for High-specific Audio Retrieval based on \n",
    "Contrastive Learning', https://arxiv.org/abs/2010.11910\n",
    "\n",
    "USAGE:\n",
    "    \n",
    "    Please see test() in the below.\n",
    "    \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad20fb41-04e4-4b09-94c4-4711ff5481d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "- hidden_ch - número de canais/filtros de saída da convolução.\n",
    "- strides - tuple com os strides para cada uma das convoluções, a primeira é apra a convolução 1x3 e a segunda é para a convolução 3x1.\n",
    "- norm - tipo de normalização a ser aplicado\n",
    "- As duas convoluções:\n",
    "    - conv2d_1x3 - Convolução 1x3 que opera na direção do eixo temporal.\n",
    "    - conv2d_3x1 - Convolução 3x1 que opera na direção do eixo frequência.\n",
    "    \n",
    "Em ***conv2d_1x3*** é definido o tamanho do *kernel_size*, os *strides[0]* para a primeira convolução.O *padding='SAME'* a ser aplicado à entrada durante a convolução, em que *'SAME'* significa que o preenchimento e aplicado para que a saída tenha a mesma altura e largura que a entrada. *dilation_rate* controla o espaçamento entre os elementos do kernel ao longo da entrada, (1,1) indica que não há espacamento. *kernel_initializer* inicializa os pesos de forma aleatória, seguindo uma distribuição uniforme. *bias_initializer* método de inicialiação do bias, inicializa com zeros.\n",
    "\n",
    "```python\n",
    "self.conv2d_1x3 = tf.keras.layers.Conv2D(hidden_ch,\n",
    "                                            kernel_size=(1, 3),\n",
    "                                            strides=strides[0],\n",
    "                                            padding='SAME',\n",
    "                                            dilation_rate=(1, 1),\n",
    "                                            kernel_initializer='glorot_uniform',\n",
    "                                            bias_initializer='zeros')\n",
    "```\n",
    "Em ***conv2d_3x1*** é semelhante à ***conv2d_1x3***, mas opera noutra direção, daí definir tamanho do *kernel_size* como (3,1).\n",
    "```python\n",
    "self.conv2d_3x1 = tf.keras.layers.Conv2D(hidden_ch,\n",
    "                                            kernel_size=(3, 1),\n",
    "                                            strides=strides[1],\n",
    "                                            padding='SAME',\n",
    "                                            dilation_rate=(1, 1),\n",
    "                                            kernel_initializer='glorot_uniform',\n",
    "                                            bias_initializer='zeros')\n",
    "```\n",
    "No método *call* recebe *x* (tensor de espetrograma de áudio) como entrada e passa pelo *forward*. *x* passa pela convolução 1x3, seguido da função de ativação ELU e normalização. Depois *x* passa pela convolução 3x1, seguido da função de ativação ELU e normalização.\n",
    "```python\n",
    " self.forward = tf.keras.Sequential([self.conv2d_1x3,\n",
    "                                            tf.keras.layers.ELU(),\n",
    "                                            self.BN_1x3,\n",
    "                                            self.conv2d_3x1,\n",
    "                                            tf.keras.layers.ELU(),\n",
    "                                            self.BN_3x1\n",
    "                                            ])\n",
    "```\n",
    "\n",
    "**ConvLayer** é projetada para extrair as características do áudio bidimensionais, capturandos padrões tanto no eixo temporal como no eixo de frequência do espetrograma de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb2b7b85-9b5f-4fba-ae58-b77b9cc6a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Separable convolution layer\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    hidden_ch: (int)\n",
    "    strides: [(int, int), (int, int)]\n",
    "    norm: 'layer_norm1d' for normalization on Freq axis. (default)\n",
    "          'layer_norm2d' for normalization on on FxT space \n",
    "          'batch_norm' or else, batch-normalization\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    x: (B,F,T,1)\n",
    "    \n",
    "    [Conv1x3]>>[ELU]>>[BN]>>[Conv3x1]>>[ELU]>>[BN]\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    x: (B,F,T,C) with {F=F/stride, T=T/stride, C=hidden_ch}\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 hidden_ch=128,\n",
    "                 strides=[(1,1),(1,1)],\n",
    "                 norm='layer_norm2d'):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.conv2d_1x3 = tf.keras.layers.Conv2D(hidden_ch,\n",
    "                                                 kernel_size=(1, 3),\n",
    "                                                 strides=strides[0],\n",
    "                                                 padding='SAME',\n",
    "                                                 dilation_rate=(1, 1),\n",
    "                                                 kernel_initializer='glorot_uniform',\n",
    "                                                 bias_initializer='zeros')\n",
    "        self.conv2d_3x1 = tf.keras.layers.Conv2D(hidden_ch,\n",
    "                                                 kernel_size=(3, 1),\n",
    "                                                 strides=strides[1],\n",
    "                                                 padding='SAME',\n",
    "                                                 dilation_rate=(1, 1),\n",
    "                                                 kernel_initializer='glorot_uniform',\n",
    "                                                 bias_initializer='zeros')\n",
    "        \n",
    "        if norm == 'layer_norm1d':\n",
    "            self.BN_1x3 = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "            self.BN_3x1 = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "        elif norm == 'layer_norm2d':\n",
    "            self.BN_1x3 = tf.keras.layers.LayerNormalization(axis=(1, 2, 3))\n",
    "            self.BN_3x1 = tf.keras.layers.LayerNormalization(axis=(1, 2, 3))\n",
    "        else:\n",
    "            self.BN_1x3 = tf.keras.layers.BatchNormalization(axis=-1) # Fix axis: 2020 Apr20\n",
    "            self.BN_3x1 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "            \n",
    "        self.forward = tf.keras.Sequential([self.conv2d_1x3,\n",
    "                                            tf.keras.layers.ELU(),\n",
    "                                            self.BN_1x3,\n",
    "                                            self.conv2d_3x1,\n",
    "                                            tf.keras.layers.ELU(),\n",
    "                                            self.BN_3x1\n",
    "                                            ])\n",
    "\n",
    "       \n",
    "    def call(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea9f9b-315f-43ac-a50b-906651f16e93",
   "metadata": {
    "tags": []
   },
   "source": [
    "- q - número de slices em que a entrada será dividida. O que determina quantas projeções distintas serão calculadas.\n",
    "- unit_dim - lista que contém o número de unidades (neuŕonios) para cada camada totalmente conectada em cada projeção. A primeira entrada determina o número de unidades para a primeira camada totalmente conectada, e a segunda entrada determina o número de unidades para a segunda camada totalemnte conectada.\n",
    "- norm - tipo de normalização\n",
    "\n",
    "<br>O método *call*, *tf.reshape(x, shape=[x.shape[0], self.q, -1])* a entrada *x* é remodelada para que a sua forma que (B,Q,S), onde *'B'* é o tamanho do batch, *'Q'* o número de slices e *'S'* é o comprimento de cada slice. *self._split_encoding(x)*, calcula as projeções de cada slice e concatena-as ao longo da dimensão do batch, retornando um tensor (B,Q) que contém as projeções de todos os slices.\n",
    "```python\n",
    "def call(self, x): # x: (B,1,1,2048)\n",
    "        x = tf.reshape(x, shape=[x.shape[0], self.q, -1]) # (B,Q,S); Q=num_slices; S=slice length; (B,128,8 or 16)\n",
    "        return self._split_encoding(x)\n",
    "```\n",
    "\n",
    "<br>Para neste caso, com d=128, e de acordo com a tabela 1 do artigo:\n",
    "<br> $g(.):=L2 \\triangleleft Concat \\triangleleft C^{1 \\leftarrow 32}_{1*1} \\triangleleft ELU<C^{32 \\leftarrow 8}_{1*1} \\triangleleft Split^{h/d}(.) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820971c1-c399-4009-964d-7e3789fed7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivEncLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi-head projection a.k.a. 'divide and encode' layer:\n",
    "        \n",
    "    • The concept of 'divide and encode' was discovered  in Lai et.al.,\n",
    "     'Simultaneous Feature Learning and Hash Coding with Deep Neural Networks',\n",
    "      2015. https://arxiv.org/abs/1504.03410\n",
    "    • It was also adopted in Gfeller et.al. 'Now Playing: Continuo-\n",
    "      us low-power music recognition', 2017. https://arxiv.org/abs/1711.10958\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    q: (int) number of slices as 'slice_length = input_dim / q'\n",
    "    unit_dim: [(int), (int)]\n",
    "    norm: 'layer_norm1d' or 'layer_norm2d' uses 1D-layer normalization on the feature.\n",
    "          'batch_norm' or else uses batch normalization. Default is 'layer_norm2d'.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    x: (B,1,1,C)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    emb: (B,Q)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, q=128, unit_dim=[32, 1], norm='batch_norm'):\n",
    "        super(DivEncLayer, self).__init__()\n",
    "\n",
    "        self.q = q\n",
    "        self.unit_dim = unit_dim\n",
    "        self.norm = norm\n",
    "        \n",
    "        if norm in ['layer_norm1d', 'layer_norm2d']:\n",
    "            self.BN = [tf.keras.layers.LayerNormalization(axis=-1) for i in range(q)]\n",
    "        else:\n",
    "            self.BN = [tf.keras.layers.BatchNormalization(axis=-1) for i in range(q)]\n",
    "            \n",
    "        self.split_fc_layers = self._construct_layers() \n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Prepare output embedding variable for dynamic batch-size \n",
    "        self.slice_length = int(input_shape[-1] / self.q)\n",
    "\n",
    " \n",
    "    def _construct_layers(self):\n",
    "        layers = list()\n",
    "        for i in range(self.q): # q: num_slices\n",
    "            layers.append(tf.keras.Sequential([tf.keras.layers.Dense(self.unit_dim[0], activation='elu'),\n",
    "                                               #self.BN[i],\n",
    "                                               tf.keras.layers.Dense(self.unit_dim[1])]))\n",
    "        return layers\n",
    "\n",
    " \n",
    "    @tf.function\n",
    "    def _split_encoding(self, x_slices):\n",
    "        \"\"\"\n",
    "        Input: (B,Q,S)\n",
    "        Returns: (B,Q)\n",
    "        \n",
    "        \"\"\"\n",
    "        out = list()\n",
    "        for i in range(self.q):\n",
    "            out.append(self.split_fc_layers[i](x_slices[:, i, :]))\n",
    "        return tf.concat(out, axis=1)\n",
    "\n",
    "    \n",
    "    def call(self, x): # x: (B,1,1,2048)\n",
    "        x = tf.reshape(x, shape=[x.shape[0], self.q, -1]) # (B,Q,S); Q=num_slices; S=slice length; (B,128,8 or 16)\n",
    "        return self._split_encoding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70243f58-c184-46f8-ae3e-51b3135595a9",
   "metadata": {},
   "source": [
    "Tem como input - x: (B,F,T,1).\n",
    "<br>Tem como return um embedding (B,Q).\n",
    "<br>O construtor *\\_\\_init\\_\\_* da class:\n",
    "- Por padrão a entrada dos melEspetrogramas é (256,32,1), o que indica que os espetrogramas tem uma frequência de 256 e tempo 32.\n",
    "- front_hidden_ch e front_strides definem a arquitetura das camadas convolucionais da frente.\n",
    "    - *front_hidden_ch* - Lista que definie o número de canais para cada camada convilucional da frente.\n",
    "    - *front_strides* - Lista de listas que define o stride para cada camada convolucional da frente.\n",
    "- *emb_sz* - define o tamanho para cada embedding.\n",
    "- *fc_unit_dim* - é uma lista com as dimensões das camadas totalmente conectadas após as camdas camadas convolucionais, o valor padrão é [32,1].\n",
    "- *norm* - tipo de normalização, neste caso será *layer_norm2d* on FxT space.\n",
    "- *use_L2layer* - indica se a cadama L2 deve ser usada ou não (boolean).\n",
    "\n",
    "<br>*front_conv* é uma sequência de camadas **convolucionais** da frente, definida em *front_hidden_ch* e *front_strides*.\n",
    "<br>*div_enc* é uma camada de **divisão** e **codificação** de modo a reduzir a dimensão da saída para o tamanho do embedding.\n",
    "```python\n",
    "# Front (sep-)conv layers\n",
    "for i in range(self.n_clayers):\n",
    "    self.front_conv.add(ConvLayer(hidden_ch=front_hidden_ch[i],\n",
    "        strides=front_strides[i], norm=norm))\n",
    "self.front_conv.add(tf.keras.layers.Flatten()) # (B,F',T',C) >> (B,D)\n",
    "```\n",
    "\n",
    "O loop percorre todas as camadas convolucionais definidas pela variável *self.n_clayers* (que define o número de camadas convolucionais na frente da rede). De seguida, adiciona uma camada convolucional à sequência *self.front_conv*. *hidden_ch=front_hidden_ch[i]* especifica o número de canais para a atual camada convolucional, onde *i* representa o índice da camada. * strides=front_strides[i]* espeficia o stride para a camada convolucional atual. Após adicionar todas as camadas convolucionais, uma camada de achatamento é adicionar à sequência de moro a trnasformar os tensores tridimensionais resultantes das camadas em vetores unidimenionais (B,F',T',C) >> (B,D). B é o tamanho do batch, e D o número de elementos do tensor resultante.\n",
    "\n",
    "\n",
    "<br>O método *call* define como os dados fluem no modelo, recebe inputs como entrada (tensor de espetograma de áudio), passa os dados pela sequência de camadas convolucionais da frente (*front_conv*) para **extrair as características**. Em seguida, passa as características pela camada de divisão e codificação (*div_enc*) praa obter os respetivos embeddings. Se *use_L2layer* for verdadeiro, normaliza os embeddings com normalização L2. Por fim retorna o **embeddings**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6f71d0-29bc-4394-a804-17fc8481d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerPrinter(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Fingerprinter: 'Neural Audio Fingerprint for High-specific Audio Retrieval\n",
    "        based on Contrastive Learning', https://arxiv.org/abs/2010.11910\n",
    "    \n",
    "    IN >> [Convlayer]x8 >> [DivEncLayer] >> [L2Normalizer] >> OUT \n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    input_shape: tuple (int), not including the batch size\n",
    "    front_hidden_ch: (list)\n",
    "    front_strides: (list)\n",
    "    emb_sz: (int) default=128\n",
    "    fc_unit_dim: (list) default=[32,1]\n",
    "    norm: 'layer_norm1d' for normalization on Freq axis. \n",
    "          'layer_norm2d' for normalization on on FxT space (default).\n",
    "          'batch_norm' or else, batch-normalization.\n",
    "    use_L2layer: True (default)\n",
    "    \n",
    "    • Note: batch-normalization will not work properly with TPUs.\n",
    "                    \n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    x: (B,F,T,1)\n",
    "    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    emb: (B,Q) \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_shape=(256,32,1),\n",
    "                 front_hidden_ch=[128, 128, 256, 256, 512, 512, 1024, 1024],\n",
    "                 front_strides=[[(1,2), (2,1)], [(1,2), (2,1)],\n",
    "                                [(1,2), (2,1)], [(1,2), (2,1)],\n",
    "                                [(1,1), (2,1)], [(1,2), (2,1)],\n",
    "                                [(1,1), (2,1)], [(1,2), (2,1)]],\n",
    "                 emb_sz=128, # q\n",
    "                 fc_unit_dim=[32,1],\n",
    "                 norm='layer_norm2d',\n",
    "                 use_L2layer=True):\n",
    "        super(FingerPrinter, self).__init__()\n",
    "        self.front_hidden_ch = front_hidden_ch\n",
    "        self.front_strides = front_strides\n",
    "        self.emb_sz=emb_sz\n",
    "        self.norm = norm\n",
    "        self.use_L2layer = use_L2layer\n",
    "        \n",
    "        self.n_clayers = len(front_strides)\n",
    "        self.front_conv = tf.keras.Sequential(name='ConvLayers')\n",
    "        if ((front_hidden_ch[-1] % emb_sz) != 0):\n",
    "            front_hidden_ch[-1] = ((front_hidden_ch[-1]//emb_sz) + 1) * emb_sz                \n",
    "        \n",
    "        # Front (sep-)conv layers\n",
    "        for i in range(self.n_clayers):\n",
    "            self.front_conv.add(ConvLayer(hidden_ch=front_hidden_ch[i],\n",
    "                strides=front_strides[i], norm=norm))\n",
    "        self.front_conv.add(tf.keras.layers.Flatten()) # (B,F',T',C) >> (B,D)\n",
    "            \n",
    "        # Divide & Encoder layer\n",
    "        self.div_enc = DivEncLayer(q=emb_sz, unit_dim=fc_unit_dim, norm=norm)\n",
    "\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        x = self.front_conv(inputs) # (B,D) with D = (T/2^4) x last_hidden_ch\n",
    "        x = self.div_enc(x) # (B,Q)\n",
    "        if self.use_L2layer:\n",
    "            return tf.math.l2_normalize(x, axis=1) \n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b23f0-91ce-4d6b-923f-a03324e41804",
   "metadata": {
    "tags": []
   },
   "source": [
    "Esta função é chamada no ficheiro *trainer.py*. Tem o input_shape definido, emb_sz e o model norm (*layer_norm2d*, pre-definido) vai buscar à config file.\n",
    "<br>O formato de entrada do modelo é definido como (256,32,1), ou seja, de 3 dimensões.\n",
    "- 256 - número de frequênicas (bandas) no espetrograma de áudio.\n",
    "- 32 - número de frames de tempo no espetrograma.\n",
    "- 1 - número de canais de cor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336e2f5b-40cf-47a9-a5ca-b2963b3cae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fingerprinter(cfg, trainable=False):\n",
    "    \"\"\"\n",
    "    Input length : 1s or 2s\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    cfg : (dict)\n",
    "        created from the '.yaml' located in /config dicrectory\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    <tf.keras.Model> FingerPrinter object\n",
    "    \n",
    "    \"\"\"\n",
    "    input_shape = (256, 32, 1) \n",
    "    emb_sz = cfg['MODEL']['EMB_SZ']\n",
    "    norm = cfg['MODEL']['BN']\n",
    "    fc_unit_dim = [32, 1]\n",
    "    \n",
    "    m = FingerPrinter(input_shape=input_shape,\n",
    "                      emb_sz=emb_sz,\n",
    "                      fc_unit_dim=fc_unit_dim,\n",
    "                      norm=norm)\n",
    "    m.trainable = trainable\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7842d9-6151-448f-bd37-a3fc3e44bd65",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2312360-530c-407d-9aa6-8cb8767a4a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTotal params: 19,224,576\\nTrainable params: 19,224,576\\nNon-trainable params: 0\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test():\n",
    "    input_1s = tf.constant(np.random.randn(3,256,32,1), dtype=tf.float32) # BxFxTx1\n",
    "    fprinter = FingerPrinter(emb_sz=128, fc_unit_dim=[32, 1], norm='layer_norm2d')\n",
    "    emb_1s = fprinter(input_1s) # BxD\n",
    "    \n",
    "    input_2s = tf.constant(np.random.randn(3,256,63,1), dtype=tf.float32) # BxFxTx1\n",
    "    fprinter = FingerPrinter(emb_sz=128, fc_unit_dim=[32, 1], norm='layer_norm2d')\n",
    "    emb_2s = fprinter(input_2s)\n",
    "    #%timeit -n 10 fprinter(_input) # 27.9ms\n",
    "\"\"\"\n",
    "Total params: 19,224,576\n",
    "Trainable params: 19,224,576\n",
    "Non-trainable params: 0\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
