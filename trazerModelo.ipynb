{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "from model.fp.nnfp import get_fingerprinter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default.yaml\n"
     ]
    }
   ],
   "source": [
    "config:str = \"default\"  \n",
    "cfg = load_config(config)\n",
    "\n",
    "checkpoint_root_dir = '/mnt/dev/rodrigoalmeida/NeuralNetworks/neural-audio-fp/logs/checkpoint/'\n",
    "checkpoint_name:str = 'CHECKPOINT_BSZ_120'\n",
    "checkpoint_index:int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_root_dir, checkpoint_name, checkpoint_index,\n",
    "                    m_fp):\n",
    "    \"\"\" Load a trained fingerprinter \"\"\"\n",
    "    # Create checkpoint\n",
    "    checkpoint = tf.train.Checkpoint(model=m_fp)\n",
    "    checkpoint_dir = checkpoint_root_dir + f'/{checkpoint_name}/'\n",
    "    c_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir,\n",
    "                                           max_to_keep=None)\n",
    "\n",
    "    # Load\n",
    "    if checkpoint_index == None:\n",
    "        tf.print(\"\\x1b[1;32mArgument 'checkpoint_index' was not specified.\\x1b[0m\")\n",
    "        tf.print('\\x1b[1;32mSearching for the latest checkpoint...\\x1b[0m')\n",
    "        latest_checkpoint = c_manager.latest_checkpoint\n",
    "        if latest_checkpoint:\n",
    "            checkpoint_index = int(latest_checkpoint.split(sep='ckpt-')[-1])\n",
    "            status = checkpoint.restore(latest_checkpoint)\n",
    "            status.expect_partial()\n",
    "            tf.print(f'---Restored from {c_manager.latest_checkpoint}---')\n",
    "        else:\n",
    "            raise FileNotFoundError(f'Cannot find checkpoint in {checkpoint_dir}')\n",
    "    else:\n",
    "        checkpoint_fpath = checkpoint_dir + 'ckpt-' + str(checkpoint_index)\n",
    "        status = checkpoint.restore(checkpoint_fpath) # Let TF to handle error cases.\n",
    "        status.expect_partial()\n",
    "        tf.print(f'---Restored from {checkpoint_fpath}---')\n",
    "    return checkpoint_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(model=meuModelo)\n",
    "c_manager = tf.train.CheckpointManager(checkpoint, checkpoint_root_dir+checkpoint_name, max_to_keep=None)\n",
    "\n",
    "latest_checkpoint = c_manager.latest_checkpoint\n",
    "latest_checkpoint\n",
    "checkpoint_index = int(latest_checkpoint.split(sep='ckpt-')[-1])\n",
    "checkpoint_fpath =  checkpoint_root_dir+checkpoint_name + 'ckpt-' + str(checkpoint_index)\n",
    "status = checkpoint.restore(checkpoint_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus object at 0x7537d01a9bd0>\n"
     ]
    }
   ],
   "source": [
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meuModelo = get_fingerprinter(cfg, trainable=False)\n",
    "\n",
    "#checkpoint_index = load_checkpoint(checkpoint_root_dir, checkpoint_name, 100, meuModelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(np.random.randn(1,256,32,1), dtype=tf.float32) # BxFxTx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_1s = meuModelo(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "def convlayer(hidden_ch=128,\n",
    "              strides=[(1,1),(1,1)],\n",
    "              norm='layer_norm2d'):\n",
    "    conv2d_1x3 = tf.keras.layers.Conv2D(hidden_ch,\n",
    "                                        kernel_size=(1, 3),\n",
    "                                        strides=strides[0],\n",
    "                                        padding='SAME',\n",
    "                                        dilation_rate=(1, 1),\n",
    "                                        kernel_initializer='glorot_uniform',\n",
    "                                        bias_initializer='zeros')\n",
    "    conv2d_3x1 = tf.keras.layers.Conv2D(hidden_ch,\n",
    "                                        kernel_size=(3, 1),\n",
    "                                        strides=strides[1],\n",
    "                                        padding='SAME',\n",
    "                                        dilation_rate=(1, 1),\n",
    "                                        kernel_initializer='glorot_uniform',\n",
    "                                        bias_initializer='zeros')\n",
    "    if norm == 'layer_norm1d':\n",
    "        BN_1x3 = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "        BN_3x1 = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "    elif norm == 'layer_norm2d':\n",
    "        BN_1x3 = tf.keras.layers.LayerNormalization(axis=(1, 2, 3))\n",
    "        BN_3x1 = tf.keras.layers.LayerNormalization(axis=(1, 2, 3))\n",
    "    else:\n",
    "        BN_1x3 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        BN_3x1 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        \n",
    "    forward = tf.keras.Sequential([conv2d_1x3,\n",
    "                                   tf.keras.layers.ELU(),\n",
    "                                   BN_1x3,\n",
    "                                   conv2d_3x1,\n",
    "                                   tf.keras.layers.ELU(),\n",
    "                                   BN_3x1\n",
    "                                   ])\n",
    "    \n",
    "    return forward\n",
    "\n",
    "\n",
    "\n",
    "def create_sequential_front_conv(input_shape=(256,32,1),\n",
    "                                 emb_sz=128,\n",
    "                                 front_hidden_ch=[128, 128, 256, 256, 512, 512, 1024, 1024],\n",
    "                                 front_strides=[[(1,2), (2,1)], [(1,2), (2,1)],\n",
    "                                                [(1,2), (2,1)], [(1,2), (2,1)],\n",
    "                                                [(1,1), (2,1)], [(1,2), (2,1)],\n",
    "                                                [(1,1), (2,1)], [(1,2), (2,1)]],\n",
    "                                 norm='layer_norm2d'):\n",
    "    front_conv = tf.keras.Sequential(name='ConvLayers')\n",
    "    if ((front_hidden_ch[-1] % emb_sz) != 0):\n",
    "        front_hidden_ch[-1] = ((front_hidden_ch[-1]//emb_sz) + 1) * emb_sz\n",
    "\n",
    "    for i in range(len(front_strides)):\n",
    "        front_conv.add(convlayer(hidden_ch=front_hidden_ch[i], strides=front_strides[i], norm=norm))\n",
    "    front_conv.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    return front_conv\n",
    "\n",
    "\n",
    "\n",
    "def auxiliar(input1):\n",
    "    conv_layer = create_sequential_front_conv(input_shape=(256,32,1),\n",
    "                                               emb_sz=128,\n",
    "                                               front_hidden_ch=[128, 128, 256, 256, 512, 512, 1024, 1024],\n",
    "                                               front_strides=[[(1,2), (2,1)], [(1,2), (2,1)],\n",
    "                                                              [(1,2), (2,1)], [(1,2), (2,1)],\n",
    "                                                              [(1,1), (2,1)], [(1,2), (2,1)],\n",
    "                                                              [(1,1), (2,1)], [(1,2), (2,1)]],\n",
    "                                               norm='layer_norm2d')\n",
    "\n",
    "    unit_dim = [32, 1]\n",
    "    q = 128\n",
    "    arquiteturas_densas = tf.keras.Sequential([tf.keras.layers.Dense(unit_dim[0], activation='elu'),\n",
    "                                               tf.keras.layers.Dense(unit_dim[1])])\n",
    "\n",
    "    x = input1\n",
    "    #x reshape\n",
    "    x = conv_layer(x)\n",
    "\n",
    "    y_list = [0] * q\n",
    "    x_split = tf.split(x, num_or_size_splits=128, axis=1)\n",
    "\n",
    "    for v, k in enumerate(x_split):\n",
    "        y_list[v] = arquiteturas_densas(k)\n",
    "\n",
    "    out = tf.concat(y_list, axis=1)\n",
    "    output = tf.math.l2_normalize(out, axis=1)\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_fingerprinting(input1):\n",
    "    output = auxiliar(input1)\n",
    "    fingerprinting_model = Model(inputs=input1, outputs=output)\n",
    "    return fingerprinting_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functional_model=get_fingerprinting(x)\n",
    "functional_model.set_weights(meuModelo.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirWeights = '/home/rodrigo/Documents/neural-audio-fp/ModeloGuardadoFolder/'\n",
    "#module_no_signatures_path = os.path.join(tmpdir, 'module_no_signatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(meuModelo, dirWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meuModelo.save_weights('/home/rodrigo/Documents/neural-audio-fp/ModeloGuardadoFolder/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=meuModelo.front_conv.layers[0].conv2d_1x3.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"finger_printer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ConvLayers (Sequential)     (2, 1024)                 16897920  \n",
      "                                                                 \n",
      " div_enc_layer (DivEncLayer  multiple                  41088     \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16939008 (64.62 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 16939008 (64.62 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "meuModelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ConvLayers\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_layer (ConvLayer)      (2, 128, 16, 128)         1622656   \n",
      "                                                                 \n",
      " conv_layer_1 (ConvLayer)    (2, 64, 8, 128)           491776    \n",
      "                                                                 \n",
      " conv_layer_2 (ConvLayer)    (2, 32, 4, 256)           492032    \n",
      "                                                                 \n",
      " conv_layer_3 (ConvLayer)    (2, 16, 2, 256)           442880    \n",
      "                                                                 \n",
      " conv_layer_4 (ConvLayer)    (2, 8, 2, 512)            1229824   \n",
      "                                                                 \n",
      " conv_layer_5 (ConvLayer)    (2, 4, 1, 512)            1586176   \n",
      "                                                                 \n",
      " conv_layer_6 (ConvLayer)    (2, 2, 1, 1024)           4732928   \n",
      "                                                                 \n",
      " conv_layer_7 (ConvLayer)    (2, 1, 1, 1024)           6299648   \n",
      "                                                                 \n",
      " flatten (Flatten)           (2, 1024)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16897920 (64.46 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 16897920 (64.46 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "meuModelo.front_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meuModelo.div_enc.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meuModelo.div_enc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
