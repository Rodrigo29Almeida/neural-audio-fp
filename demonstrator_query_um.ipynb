{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_RA.utils.dataloader_keras import genUnbalSequence\n",
    "#import tensorflow as tf\n",
    "#from model_RA.dataset_RA import Dataset\n",
    "import glob\n",
    "#from model.utils.audio_utils import (bg_mix_batch, ir_aug_batch, load_audio,\n",
    "#                                     get_fns_seg_list, load_audio_multi_start)\n",
    "from model.utils.audio_utils import load_audio_multi_start\n",
    "import tensorflow as tf\n",
    "import wave\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memmap_data(source_dir, fname, append_extra_length=None, shape_only=False):\n",
    "    \"\"\"\n",
    "    Load data and datashape from the file path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source_dir : (str)\n",
    "        Directory where the files are located.\n",
    "    fname : (str)\n",
    "        File name except extension.\n",
    "    append_extra_length : None or (int)\n",
    "        Length to append empty vector when loading memmap.\n",
    "    shape_only : (bool), optional\n",
    "        Return only shape. The default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (data, data_shape)\n",
    "    \"\"\"\n",
    "    path_shape = os.path.join(source_dir, fname + '_shape.npy')\n",
    "    path_data = os.path.join(source_dir, fname + '.mm')\n",
    "    data_shape = np.load(path_shape)\n",
    "    if shape_only:\n",
    "        return data_shape\n",
    "\n",
    "    if append_extra_length:\n",
    "        data_shape[0] += append_extra_length\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r+',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    else:\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    return data, data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load audio\n",
    "#features\n",
    "#nnfp\n",
    "#generate\n",
    "#predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default_RA.yaml\n"
     ]
    }
   ],
   "source": [
    "config = \"default_RA\"\n",
    "cfg = load_config(config)\n",
    "#checkpoint_name = \"Checks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSZ\n",
    "tr_batch_sz = cfg['BSZ']['TR_BATCH_SZ']\n",
    "tr_n_anchor = cfg['BSZ']['TR_N_ANCHOR']\n",
    "val_batch_sz = cfg['BSZ']['VAL_BATCH_SZ']\n",
    "val_n_anchor = cfg['BSZ']['VAL_N_ANCHOR']\n",
    "ts_batch_sz = cfg['BSZ']['TS_BATCH_SZ']\n",
    "\n",
    "# Model parameters\n",
    "dur = cfg['MODEL']['DUR']\n",
    "hop = cfg['MODEL']['HOP']\n",
    "fs = cfg['MODEL']['FS']\n",
    "\n",
    "# Time-domain augmentation parameter\n",
    "tr_snr = cfg['TD_AUG']['TR_SNR']\n",
    "ts_snr = cfg['TD_AUG']['TS_SNR']\n",
    "val_snr = cfg['TD_AUG']['VAL_SNR']\n",
    "tr_use_bg_aug = cfg['TD_AUG']['TR_BG_AUG']\n",
    "ts_use_bg_aug = cfg['TD_AUG']['TS_BG_AUG']\n",
    "val_use_bg_aug = cfg['TD_AUG']['VAL_BG_AUG']\n",
    "tr_use_ir_aug = cfg['TD_AUG']['TR_IR_AUG']\n",
    "ts_use_ir_aug = cfg['TD_AUG']['TS_IR_AUG']\n",
    "val_use_ir_aug = cfg['TD_AUG']['VAL_IR_AUG']\n",
    "tr_use_speech_aug = cfg['TD_AUG']['TR_SPEECH_AUG']\n",
    "ts_use_speech_aug = cfg['TD_AUG']['TS_SPEECH_AUG']\n",
    "val_use_speech_aug = cfg['TD_AUG']['VAL_SPEECH_AUG']\n",
    "\n",
    "val_bg_fps = None\n",
    "val_ir_fps = None\n",
    "val_speech_fps = None\n",
    "\n",
    "seg_mode ='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seg_list(fns_list=[],\n",
    "                     segment_mode='all',\n",
    "                     fs=22050,\n",
    "                     duration=1,\n",
    "                     hop=None):\n",
    "    \"\"\"\n",
    "    return: fns_event_seg_list\n",
    "        \n",
    "        [[filename, seg_idx, offset_min, offset_max], [ ... ] , ... [ ... ]]\n",
    "        \n",
    "        offset_min is 0 or negative integer\n",
    "        offset_max is 0 or positive integer\n",
    "        \n",
    "    \"\"\"\n",
    "    if hop == None: hop = duration\n",
    "    fns_event_seg_list = []\n",
    "\n",
    "    #print(f\"fns_list={fns_list}\")\n",
    "\n",
    "    for offset_idx, filename in enumerate(fns_list):\n",
    "        # Get audio info\n",
    "        #print(f\"filename={filename}\")\n",
    "        n_frames_in_seg = fs * duration\n",
    "        n_frames_in_hop = fs * hop  # 2019 09.05\n",
    "        file_ext = filename[-3:]\n",
    "\n",
    "        if file_ext == 'wav':\n",
    "            pt_wav = wave.open(filename, 'r')\n",
    "            _fs = pt_wav.getframerate()\n",
    "\n",
    "            if fs != _fs:\n",
    "                raise ValueError('Sample rate should be {} but got {}'.format(\n",
    "                    str(fs), str(_fs)))\n",
    "\n",
    "            n_frames = pt_wav.getnframes()\n",
    "            #n_segs = n_frames // n_frames_in_seg\n",
    "            if n_frames > n_frames_in_seg:\n",
    "                n_segs = (n_frames - n_frames_in_seg +\n",
    "                          n_frames_in_hop) // n_frames_in_hop\n",
    "            else:\n",
    "                n_segs = 1\n",
    "\n",
    "            n_segs = int(n_segs)\n",
    "            assert (n_segs > 0)\n",
    "            residual_frames = np.max([\n",
    "                0,\n",
    "                n_frames - ((n_segs - 1) * n_frames_in_hop + n_frames_in_seg)\n",
    "            ])\n",
    "            pt_wav.close()\n",
    "        else:\n",
    "            raise NotImplementedError(file_ext)\n",
    "\n",
    "        # 'all', 'random_oneshot', 'first'\n",
    "        if segment_mode == 'all':\n",
    "            for seg_idx in range(n_segs):\n",
    "                offset_min, offset_max = int(-1 *\n",
    "                                             n_frames_in_hop), n_frames_in_hop\n",
    "                if seg_idx == 0:  # first seg\n",
    "                    offset_min = 0\n",
    "                if seg_idx == (n_segs - 1):  # last seg\n",
    "                    offset_max = residual_frames\n",
    "\n",
    "                fns_event_seg_list.append(\n",
    "                    [filename, seg_idx, offset_min, offset_max])\n",
    "        elif segment_mode == 'random_oneshot':\n",
    "            seg_idx = np.random.randint(0, n_segs)\n",
    "            offset_min, offset_max = n_frames_in_hop, n_frames_in_hop\n",
    "            if seg_idx == 0:  # first seg\n",
    "                offset_min = 0\n",
    "            if seg_idx == (n_segs - 1):  # last seg\n",
    "                offset_max = residual_frames\n",
    "            fns_event_seg_list.append(\n",
    "                [filename, seg_idx, offset_min, offset_max])\n",
    "        elif segment_mode == 'first':\n",
    "            seg_idx = 0\n",
    "            offset_min, offset_max = 0, 0\n",
    "            fns_event_seg_list.append(\n",
    "                [filename, seg_idx, offset_min, offset_max])\n",
    "        else:\n",
    "            raise NotImplementedError(segment_mode)\n",
    "\n",
    "    return fns_event_seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"audiopath = '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/test-query-db-500-30s/db/000/000134.wav'\\naudio_list =[audiopath]\\n\\nfns_event_seg_list = get_fns_seg_list(audio_list,\\n                                        seg_mode,\\n                                        fs,\\n                                        dur,\\n                                        hop=hop)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"audiopath = '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/test-query-db-500-30s/db/000/000134.wav'\n",
    "audio_list =[audiopath]\n",
    "\n",
    "fns_event_seg_list = get_fns_seg_list(audio_list,\n",
    "                                        seg_mode,\n",
    "                                        fs,\n",
    "                                        dur,\n",
    "                                        hop=hop)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_margin_hop_rate=0.4\n",
    "offset_margin_frame = int(hop * offset_margin_hop_rate * fs)\n",
    "random_offset_anchor=False\n",
    "n_pos_per_anchor = round((120 - 60) / 60)\n",
    "amp_mode='normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_load(anchor_idx_list, fns_event_seg_list):\n",
    "        Xa_batch = None\n",
    "        \n",
    "        for idx in anchor_idx_list:  # idx: index for one sample\n",
    "            pos_start_sec_list = []\n",
    "            # fns_event_seg_list = [[filename, seg_idx, offset_min, offset_max], [ ... ] , ... [ ... ]]\n",
    "            offset_min, offset_max = fns_event_seg_list[idx][\n",
    "                2], fns_event_seg_list[idx][3]\n",
    "            \n",
    "            anchor_offset_min = np.max([offset_min, -offset_margin_frame])\n",
    "            anchor_offset_max = np.min([offset_max, offset_margin_frame])\n",
    "            \n",
    "            \n",
    "            _anchor_offset_frame = 0\n",
    "            anchor_start_sec = fns_event_seg_list[idx][1] * hop\n",
    "\n",
    "\n",
    "            \"\"\" Calculate multiple(=self.n_pos_per_anchor) pos_start_sec. \"\"\"\n",
    "            if n_pos_per_anchor > 0:\n",
    "                pos_offset_min = np.max([\n",
    "                    (_anchor_offset_frame - offset_margin_frame),\n",
    "                    offset_min\n",
    "                ])\n",
    "                pos_offset_max = np.min([\n",
    "                    (_anchor_offset_frame + offset_margin_frame),\n",
    "                    offset_max\n",
    "                ])\n",
    "\n",
    "                if pos_offset_min==pos_offset_max==0:\n",
    "                    # Only the case of running extras/dataset2wav.py \n",
    "                    # as offset_margin_hot_rate=0\n",
    "                    pos_start_sec_list = fns_event_seg_list[idx][\n",
    "                        1] * hop\n",
    "                    pos_start_sec_list = [pos_start_sec_list]\n",
    "                    print('!!!!!!!!!!!!!!!!!!!!!!')\n",
    "                    print(f\"pos_start_sec_list:{pos_start_sec_list}\")\n",
    "                    print(f\"[anchor_start_sec]:{[anchor_start_sec]}\")\n",
    "\n",
    "                else:\n",
    "                    # Otherwise, we apply random offset to replicas \n",
    "                    _pos_offset_frame_list = np.random.randint(\n",
    "                        low=pos_offset_min,\n",
    "                        high=pos_offset_max,\n",
    "                        size=n_pos_per_anchor)\n",
    "                    _pos_offset_sec_list = _pos_offset_frame_list / fs\n",
    "                    pos_start_sec_list = fns_event_seg_list[idx][\n",
    "                        1] * hop + _pos_offset_sec_list  \n",
    "            \n",
    "            \"\"\"\n",
    "            load audio returns: [anchor, pos1, pos2,..pos_n]\n",
    "            \"\"\"\n",
    "            #print(self.fns_event_seg_list[idx])\n",
    "            start_sec_list = np.concatenate(\n",
    "                ([anchor_start_sec], pos_start_sec_list))\n",
    "            \n",
    "            xs = load_audio_multi_start(fns_event_seg_list[idx][0],\n",
    "                                        start_sec_list, dur, fs,\n",
    "                                        amp_mode)  # xs: ((1+n_pos)),T)\n",
    "\n",
    "            if Xa_batch is None:\n",
    "                Xa_batch = xs[0, :].reshape((1, -1))\n",
    "            else:\n",
    "                Xa_batch = np.vstack((Xa_batch, xs[0, :].reshape(\n",
    "                    (1, -1))))  # Xa_batch: (n_anchor, T)\n",
    "                \n",
    "        return Xa_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getitem(idx, index_event, n_anchor, fns_event_seg_list):\n",
    "    \"\"\" Get anchor (original) and positive (replica) samples. \"\"\"\n",
    "    #print(f\"idx:{idx}\")\n",
    "    index_anchor_for_batch = index_event[idx *\n",
    "                                n_anchor:(idx + 1) *\n",
    "                                n_anchor]\n",
    "    #print(f\"index_anchor_for_batch:{index_anchor_for_batch}\")\n",
    "    \n",
    "    if len(index_anchor_for_batch) == 0:\n",
    "        return None\n",
    "     \n",
    "    Xa_batch = batch_load(index_anchor_for_batch, fns_event_seg_list)\n",
    "    \n",
    "    #print(f\"Xa_batch:{Xa_batch}\")\n",
    "\n",
    "    global bg_sel_indices, speech_sel_indices\n",
    "\n",
    "    Xa_batch = np.expand_dims(Xa_batch,\n",
    "                                1).astype(np.float32)  # (n_anchor, 1, T)\n",
    "    #print(f\"Xa_batch_expandido:{Xa_batch}\")\n",
    "    \n",
    "    return Xa_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiopath = '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/test-query-db-500-30s/db/000/000134.wav'\n",
    "audio_list = [audiopath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_list = get_seg_list(fns_list=audio_list,\n",
    "                     segment_mode='all',\n",
    "                     fs=8000,\n",
    "                     duration=1.,\n",
    "                     hop=.5)\n",
    "\n",
    "n_samples = len(seg_list)\n",
    "index_event = np.arange(n_samples)\n",
    "n_anchor=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = len(index_event) // n_anchor + (1 if len(index_event) % n_anchor != 0 else 0)#len(seg_list)\n",
    "#print(f\"index_event:{index_event}\")\n",
    "\n",
    "for i in range(n_iter):\n",
    "    #print(i)\n",
    "    X = getitem(i, index_event, n_anchor, seg_list)\n",
    "\n",
    "    if X is None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_RA.fp_RA.melspec.melspectrogram_RA import get_melspec_layer\n",
    "from model_RA.fp_RA.nnfp import get_fingerprinter\n",
    "\n",
    "m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "m_fp = get_fingerprinter(cfg, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.concat(X, axis=0)\n",
    "feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "m_fp.trainable = False\n",
    "emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)\n",
    "\n",
    "emb_gf = m_fp.div_enc(emb_f)\n",
    "emb_gf = tf.math.l2_normalize(emb_gf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(59, 128), dtype=float32, numpy=\n",
       "array([[-0.02876278,  0.0361596 , -0.04542529, ..., -0.05875982,\n",
       "         0.04338404,  0.16598956],\n",
       "       [-0.05113657,  0.04920626, -0.02506815, ..., -0.04597016,\n",
       "         0.02481091,  0.13902223],\n",
       "       [-0.01189004, -0.00121552, -0.03751804, ...,  0.02125106,\n",
       "         0.02168985,  0.17631531],\n",
       "       ...,\n",
       "       [ 0.02640655,  0.03909785, -0.0130725 , ..., -0.03039054,\n",
       "         0.07897712,  0.18853524],\n",
       "       [-0.0010752 ,  0.05746509, -0.00945702, ..., -0.05243146,\n",
       "         0.00590391,  0.14370023],\n",
       "       [-0.01910625,  0.02702098, -0.03873452, ..., -0.05920405,\n",
       "        -0.03557371,  0.11459503]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 59 (59, 128) ./logs/emb//query-134/\n"
     ]
    }
   ],
   "source": [
    "dim = cfg['MODEL']['EMB_SZ']\n",
    "n_items = len(X) #ds[key].n_samples\n",
    "arr_shape = (n_items, dim)\n",
    "\n",
    "key = 'query-134'\n",
    "\n",
    "output_root_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + \\\n",
    "            f'/{key}/'\n",
    "\n",
    "os.makedirs(output_root_dir, exist_ok=True)\n",
    "\n",
    "print(dim, n_items, arr_shape, output_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                dtype='float32',\n",
    "                mode='w+',\n",
    "                shape=arr_shape)\n",
    "np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "bsz = 125\n",
    "arr[i * bsz:(i + 1) * bsz, :] = emb_gf.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[-0.02876278,  0.0361596 , -0.04542529, ..., -0.05875982,\n",
       "          0.04338404,  0.16598956],\n",
       "        [-0.05113657,  0.04920626, -0.02506815, ..., -0.04597016,\n",
       "          0.02481091,  0.13902223],\n",
       "        [-0.01189004, -0.00121552, -0.03751804, ...,  0.02125106,\n",
       "          0.02168985,  0.17631531],\n",
       "        ...,\n",
       "        [ 0.02640655,  0.03909785, -0.0130725 , ..., -0.03039054,\n",
       "          0.07897712,  0.18853524],\n",
       "        [-0.0010752 ,  0.05746509, -0.00945702, ..., -0.05243146,\n",
       "          0.00590391,  0.14370023],\n",
       "        [-0.01910625,  0.02702098, -0.03873452, ..., -0.05920405,\n",
       "         -0.03557371,  0.11459503]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcurses\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m))))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval_RA\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_index_faiss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_index\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval_RA\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprint_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrintTable\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import click\n",
    "import curses\n",
    "import numpy as np\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))\n",
    "from eval_RA.utils.get_index_faiss import get_index\n",
    "from eval_RA.utils.print_table import PrintTable\n",
    "\n",
    "\n",
    "def load_memmap_data(source_dir,\n",
    "                     fname,\n",
    "                     append_extra_length=None,\n",
    "                     shape_only=False,\n",
    "                     display=True):\n",
    "    path_shape = source_dir + fname + '_shape.npy'\n",
    "    path_data = source_dir + fname + '.mm'\n",
    "    data_shape = np.load(path_shape)\n",
    "    if shape_only:\n",
    "        return data_shape\n",
    "\n",
    "    if append_extra_length:\n",
    "        data_shape[0] += append_extra_length\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r+',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    else:\n",
    "        data = np.memmap(path_data, dtype='float32', mode='r',\n",
    "                         shape=(data_shape[0], data_shape[1]))\n",
    "    if display:\n",
    "        print(f'Load {data_shape[0]:,} items from \\033[32m{path_data}\\033[0m.')\n",
    "    return data, data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = cfg['MODEL']['EMB_SZ']\n",
    "n_items = len(X) #ds[key].n_samples\n",
    "arr_shape = (n_items, dim)\n",
    "print(arr_shape)\n",
    "key = 'query-134'\n",
    "\n",
    "output_root_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + \\\n",
    "            f'/{key}/'\n",
    "\n",
    "\n",
    "arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                dtype='float32',\n",
    "                mode='w+',\n",
    "                shape=arr_shape)\n",
    "np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)\n",
    "\n",
    "i=0\n",
    "arr[i * bsz:(i + 1) * bsz, :] = emb.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate\n",
    "sz_check = dict() # for warning message\n",
    "for key in ds.keys():\n",
    "    bsz = int(cfg['BSZ']['TS_BATCH_SZ'])  # Do not use ds.bsz here.\n",
    "    # n_items = len(ds[key]) * bsz\n",
    "    n_items = ds[key].n_samples\n",
    "    dim = cfg['MODEL']['EMB_SZ']\n",
    "    \"\"\"\n",
    "    Why use \"memmap\"?\n",
    "\n",
    "    • First, we need to store a huge uncompressed embedding vectors until\n",
    "        constructing a compressed DB with IVF-PQ (using FAISS). Handling a\n",
    "        huge ndarray is not a memory-safe way: \"memmap\" consume 0 memory.\n",
    "\n",
    "    • Second, Faiss-GPU does not support reconstruction of DB from\n",
    "        compressed DB (index). In eval/eval_faiss.py, we need uncompressed\n",
    "        vectors to calaulate sequence-level matching score. The created\n",
    "        \"memmap\" will be reused at that point.\n",
    "\n",
    "    Reference:\n",
    "        https://numpy.org/doc/stable/reference/generated/numpy.memmap.html\n",
    "\n",
    "    \"\"\"\n",
    "    # Create memmap, and save shapes\n",
    "    assert n_items > 0\n",
    "    arr_shape = (n_items, dim)\n",
    "    arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                    dtype='float32',\n",
    "                    mode='w+',\n",
    "                    shape=arr_shape)\n",
    "    np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)\n",
    "\n",
    "    # Fingerprinting loop\n",
    "    tf.print(\n",
    "        f\"=== Generating fingerprint from \\x1b[1;32m'{key}'\\x1b[0m \" +\n",
    "        f\"bsz={bsz}, {n_items} items, d={dim}\"+ \" ===\")\n",
    "    progbar = Progbar(len(ds[key]))\n",
    "\n",
    "    \"\"\" Parallelism to speed up preprocessing------------------------- \"\"\"\n",
    "    enq = tf.keras.utils.OrderedEnqueuer(ds[key],\n",
    "                                            use_multiprocessing=True,\n",
    "                                            shuffle=False)\n",
    "    enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "                max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "    i = 0\n",
    "    while i < len(enq.sequence):\n",
    "        progbar.update(i)\n",
    "        X, _ = next(enq.get())\n",
    "        emb = test_step(X, m_pre, m_fp)\n",
    "        arr[i * bsz:(i + 1) * bsz, :] = emb.numpy() # Writing on disk.\n",
    "        i += 1\n",
    "    progbar.update(i, finalize=True)\n",
    "    enq.stop()\n",
    "    \"\"\" End of Parallelism-------------------------------------------- \"\"\"\n",
    "\n",
    "    tf.print(f'=== Succesfully stored {arr_shape[0]} fingerprint to {output_root_dir} ===')\n",
    "    sz_check[key] = len(arr)\n",
    "    arr.flush(); del(arr) # Close memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = len(seg_list)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    X = ds.__getitem__(i)\n",
    "        \n",
    "getitem(idx, index_event, n_anchor, seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_root_dir = cfg['DIR']['SOURCE_ROOT_DIR']\n",
    "source_fps = sorted(\n",
    "            glob.glob(source_root_dir + 'val-query-db-500-30s/' +\n",
    "                      '**/*.wav', recursive=True))[:250]\n",
    "       \n",
    "ds_query = genUnbalSequence(\n",
    "    source_fps,\n",
    "    val_batch_sz,\n",
    "    val_n_anchor,\n",
    "    dur,\n",
    "    hop,\n",
    "    fs,\n",
    "    shuffle=False,\n",
    "    random_offset_anchor=False,\n",
    "    bg_mix_parameter=[val_use_bg_aug, val_bg_fps, val_snr],\n",
    "    ir_mix_parameter=[val_use_ir_aug, val_ir_fps],\n",
    "    speech_mix_parameter=[val_use_speech_aug, val_speech_fps,\n",
    "                            val_snr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_event_seg_list = get_fns_seg_list(audio_list,\n",
    "                                        seg_mode,\n",
    "                                        fs,\n",
    "                                        dur,\n",
    "                                        hop=hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fns_event_seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns_event_seg_list[3][1] * dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "for idx in fns_event_seg_list:\n",
    "    print(fns_event_seg_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=str()\n",
    "seg_start_sec=0.0#float()\n",
    "offset_sec=0.0,\n",
    "seg_length_sec=float()\n",
    "seg_pad_offset_sec=0.0\n",
    "fs=8000\n",
    "amp_mode='normal'\n",
    "\n",
    "for offset_idx, filename_audio in enumerate(audio_list):\n",
    "    filename = filename_audio\n",
    "\n",
    "#print(filename)\n",
    "for idx in len(fns_event_seg_list):\n",
    "    \n",
    "fns_event_seg_list[idx][1] * dur\n",
    "start_frame_idx = np.floor((seg_start_sec + offset_sec) * fs).astype(int)\n",
    "seg_length_frame = np.floor(seg_length_sec * fs).astype(int)\n",
    "end_frame_idx = start_frame_idx + seg_length_frame\n",
    "\n",
    "print(start_frame_idx, seg_length_frame, end_frame_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=str()\n",
    "seg_start_sec=float()\n",
    "offset_sec=0.0,\n",
    "seg_length_sec=float()\n",
    "seg_pad_offset_sec=0.0\n",
    "fs=8000\n",
    "amp_mode='normal'\n",
    "\n",
    "for offset_idx, filename_audio in enumerate(audio_list):\n",
    "    filename = filename_audio\n",
    "\n",
    "#print(filename)\n",
    "start_frame_idx = np.floor((seg_start_sec + offset_sec) * fs).astype(int)\n",
    "seg_length_frame = np.floor(seg_length_sec * fs).astype(int)\n",
    "end_frame_idx = start_frame_idx + seg_length_frame\n",
    "\n",
    "print(start_frame_idx, seg_length_frame, end_frame_idx)\n",
    "\n",
    "# Get file-info\n",
    "file_ext = filename[-3:]\n",
    "#print(start_frame_idx, end_frame_idx)\n",
    "\n",
    "if file_ext == 'wav':\n",
    "    pt_wav = wave.open(filename, 'r')\n",
    "    pt_wav.setpos(start_frame_idx)\n",
    "    x = pt_wav.readframes(end_frame_idx - start_frame_idx)\n",
    "    x = np.frombuffer(x, dtype=np.int16)\n",
    "    x = x / 2**15  # dtype=float\n",
    "else:\n",
    "    raise NotImplementedError(file_ext)\n",
    "\n",
    "# Max Normalize, random amplitude\n",
    "if amp_mode == 'normal':\n",
    "    pass\n",
    "elif amp_mode == 'max_normalize':\n",
    "    _x_max = np.max(np.abs(x))\n",
    "    if _x_max != 0:\n",
    "        x = x / _x_max\n",
    "else:\n",
    "    raise ValueError('amp_mode={}'.format(amp_mode))\n",
    "\n",
    "# padding process. it works only when win_size> audio_size and padding='random'\n",
    "audio_arr = np.zeros(int(seg_length_sec * fs))\n",
    "seg_pad_offset_idx = int(seg_pad_offset_sec * fs)\n",
    "audio_arr[seg_pad_offset_idx:seg_pad_offset_idx + len(x)] = x\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/dataset/public/Fingerprinting/query_procura/000134.wav']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m audioDir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/dataset/public/Fingerprinting/query_procura\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m source_fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m      3\u001b[0m             glob\u001b[38;5;241m.\u001b[39mglob(audioDir \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m      4\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/*.wav\u001b[39m\u001b[38;5;124m'\u001b[39m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m----> 6\u001b[0m ds_query \u001b[38;5;241m=\u001b[39m \u001b[43mgenUnbalSequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_fps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_batch_sz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_n_anchor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdur\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_offset_anchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbg_mix_parameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_use_bg_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_bg_fps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_snr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mir_mix_parameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_use_ir_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ir_fps\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeech_mix_parameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_use_speech_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_speech_fps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mval_snr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/dev/rodrigoalmeida/neural-audio-fp/model_RA/utils/dataloader_keras.py:149\u001b[0m, in \u001b[0;36mgenUnbalSequence.__init__\u001b[0;34m(self, fns_event_list, bsz, n_anchor, duration, hop, fs, shuffle, seg_mode, amp_mode, random_offset_anchor, offset_margin_hop_rate, bg_mix_parameter, ir_mix_parameter, speech_mix_parameter, reduce_items_p, reduce_batch_first_half, experimental_mode, drop_the_last_non_full_batch)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m#print(f\"self.n_samples, self.index_event: {self.n_samples, self.index_event}\")\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbg_mix \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfns_bg_seg_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_fns_seg_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns_bg_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bg_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfns_bg_seg_list)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/dev/rodrigoalmeida/neural-audio-fp/model_RA/utils/audio_utils.py:159\u001b[0m, in \u001b[0;36mget_fns_seg_list\u001b[0;34m(fns_list, segment_mode, fs, duration, hop)\u001b[0m\n\u001b[1;32m    155\u001b[0m fns_event_seg_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m#print(f\"fns_list={fns_list}\")\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m offset_idx, filename \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfns_list\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Get audio info\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m#print(f\"filename={filename}\")\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     n_frames_in_seg \u001b[38;5;241m=\u001b[39m fs \u001b[38;5;241m*\u001b[39m duration\n\u001b[1;32m    163\u001b[0m     n_frames_in_hop \u001b[38;5;241m=\u001b[39m fs \u001b[38;5;241m*\u001b[39m hop  \u001b[38;5;66;03m# 2019 09.05\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "audioDir = '/mnt/dataset/public/Fingerprinting/query_procura'\n",
    "source_fps = sorted(\n",
    "            glob.glob(audioDir +\n",
    "                      '/*.wav', recursive=True))\n",
    "\n",
    "ds_query = genUnbalSequence(\n",
    "    source_fps,\n",
    "    val_batch_sz,\n",
    "    val_n_anchor,\n",
    "    dur,\n",
    "    hop,\n",
    "    fs,\n",
    "    shuffle=False,\n",
    "    random_offset_anchor=False,\n",
    "    bg_mix_parameter=[val_use_bg_aug, val_bg_fps, val_snr],\n",
    "    ir_mix_parameter=[val_use_ir_aug, val_ir_fps],\n",
    "    speech_mix_parameter=[val_use_speech_aug, val_speech_fps,\n",
    "                            val_snr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_fps = sorted(\n",
    "            glob.glob(audiopath, recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_event_seg_list = get_fns_seg_list(source_fps,\n",
    "                                        seg_mode,\n",
    "                                        fs,\n",
    "                                        dur,\n",
    "                                        hop=hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = len(fns_event_seg_list)\n",
    "for i in range(n_iter):\n",
    "        X = fns_event_seg_list.__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/val-query-db-500-30s/db/000/000458.wav', '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/val-query-db-500-30s/db/000/000736.wav']\n",
      "self.n_samples, self.index_event: (60, array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59]))\n"
     ]
    }
   ],
   "source": [
    "dataset=Dataset(cfg)\n",
    "ds = dataset.get_val_ds(max_song=2) # max 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.ir_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(X, m_pre, m_fp):\n",
    "    \n",
    "    X=X[0]\n",
    "    feat = m_pre(X)  # (nA, F, T, 1)\n",
    "\n",
    "    m_fp.trainable = False\n",
    "\n",
    "    emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)\n",
    "    emb_gf = m_fp.div_enc(emb_f)\n",
    "    emb_gf = tf.math.l2_normalize(emb_gf, axis=1)\n",
    "    return emb_gf # f(.), L2(f(.)), L2(g(f(.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_RA.fp_RA.melspec.melspectrogram_RA import get_melspec_layer\n",
    "from model_RA.fp_RA.nnfp import get_fingerprinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "m_fp = get_fingerprinter(cfg, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter=1\n",
      "X_depois:Tensor(\"X:0\", shape=(60, 1, 8000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "max_n_samples=3000\n",
    "bsz=120\n",
    "n_iter = min(len(ds), max_n_samples // bsz)\n",
    "print(f\"n_iter={n_iter}\")\n",
    "emb=dict()\n",
    "for i in range(n_iter):\n",
    "        X = ds.__getitem__(i)\n",
    "        emb['g(f)'] = test_step(X, m_pre, m_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.concat(X, axis=0)\n",
    "feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "m_fp.trainable = False\n",
    "emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    \"\"\"\n",
    "    Extract features from an audio file using librosa.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_path : (str)\n",
    "        Path to the audio file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features : (np.ndarray)\n",
    "        Extracted feature vector.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    return mfcc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eval_RA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval_RA\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_index_faiss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_index\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eval_RA'"
     ]
    }
   ],
   "source": [
    "from eval_RA.utils.get_index_faiss import get_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrong number or type of arguments for overloaded function 'new_IndexFlatL2'.\n  Possible C/C++ prototypes are:\n    faiss::IndexFlatL2::IndexFlatL2(faiss::Index::idx_t)\n    faiss::IndexFlatL2::IndexFlatL2()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m extract_features(audio_path)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape to match expected input shape\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Perform the search\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m indices, distances \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistances: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistances\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(emb_dir, query_vector, index_type, use_gpu, max_train, k)\u001b[0m\n\u001b[1;32m     28\u001b[0m db, db_shape \u001b[38;5;241m=\u001b[39m load_memmap_data(emb_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create and train FAISS index\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Add items to index\u001b[39;00m\n\u001b[1;32m     34\u001b[0m index\u001b[38;5;241m.\u001b[39madd(db)\n",
      "Cell \u001b[0;32mIn[2], line 63\u001b[0m, in \u001b[0;36mget_index\u001b[0;34m(index_type, data, shape, use_gpu, max_train)\u001b[0m\n\u001b[1;32m     60\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m       \u001b[38;5;66;03m# number of subquantizers\u001b[39;00m\n\u001b[1;32m     61\u001b[0m nbits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m   \u001b[38;5;66;03m# bits per code\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m quantizer \u001b[38;5;241m=\u001b[39m \u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexFlatL2\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexIVFPQ(quantizer, d, nlist, m, nbits)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_gpu:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfpy/lib/python3.9/site-packages/faiss/swigfaiss.py:1980\u001b[0m, in \u001b[0;36mIndexFlatL2.__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1980\u001b[0m     _swigfaiss\u001b[38;5;241m.\u001b[39mIndexFlatL2_swiginit(\u001b[38;5;28mself\u001b[39m, \u001b[43m_swigfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_IndexFlatL2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Wrong number or type of arguments for overloaded function 'new_IndexFlatL2'.\n  Possible C/C++ prototypes are:\n    faiss::IndexFlatL2::IndexFlatL2(faiss::Index::idx_t)\n    faiss::IndexFlatL2::IndexFlatL2()\n"
     ]
    }
   ],
   "source": [
    "def predict(emb_dir, query_vector, index_type='ivfpq', use_gpu=True, max_train=1e7, k=1):\n",
    "    \"\"\"\n",
    "    Search for the closest match to the query vector in the database.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    emb_dir : (str)\n",
    "        Directory where the {db, dummy_db}.mm files are located.\n",
    "    query_vector : (np.ndarray)\n",
    "        Query vector to search for.\n",
    "    index_type : (str)\n",
    "        Type of FAISS index.\n",
    "    use_gpu : (bool)\n",
    "        Whether to use GPU.\n",
    "    max_train : (int)\n",
    "        Maximum number of items for index training.\n",
    "    k : (int)\n",
    "        Number of top results to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    indices : (np.ndarray)\n",
    "        Indices of the closest matches in the database.\n",
    "    distances : (np.ndarray)\n",
    "        Distances to the closest matches.\n",
    "    \"\"\"\n",
    "    # Load database\n",
    "    db, db_shape = load_memmap_data(emb_dir, 'db')\n",
    "\n",
    "    # Create and train FAISS index\n",
    "    index = get_index(index_type, db, db_shape, use_gpu, max_train)\n",
    "\n",
    "    # Add items to index\n",
    "    index.add(db)\n",
    "\n",
    "    # Search for the query vector\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    return indices, distances\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    emb_dir = '/mnt/dev/rodrigoalmeida/neural-audio-fp/logs/emb/CHECK_BFTRI_100/101'  # embeddings directory\n",
    "    audio_path = '/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/test-query-db-500-30s/db/000/000134.wav'  # query audio file\n",
    "\n",
    "    # Extract features from the query audio\n",
    "    query_vector = extract_features(audio_path).reshape(1, -1)  # Reshape to match expected input shape\n",
    "\n",
    "    # Perform the search\n",
    "    indices, distances = predict(emb_dir, query_vector)\n",
    "    print(f\"Indices: {indices}\")\n",
    "    print(f\"Distances: {distances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 16:15:50.364946: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\"\"\" generate.py \"\"\"\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from model_RA.dataset_RA import Dataset\n",
    "from model_RA.fp_RA.melspec.melspectrogram_RA import get_melspec_layer\n",
    "from model_RA.fp_RA.nnfp import get_fingerprinter\n",
    "\n",
    "\n",
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_fp\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_root_dir, checkpoint_name, checkpoint_index,\n",
    "                    m_fp):\n",
    "    \"\"\" Load a trained fingerprinter \"\"\"\n",
    "    # Create checkpoint\n",
    "    checkpoint = tf.train.Checkpoint(model=m_fp)\n",
    "    checkpoint_dir = checkpoint_root_dir + f'/{checkpoint_name}/'\n",
    "    c_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir,\n",
    "                                           max_to_keep=None)\n",
    "\n",
    "    # Load\n",
    "    if checkpoint_index == None:\n",
    "        tf.print(\"\\x1b[1;32mArgument 'checkpoint_index' was not specified.\\x1b[0m\")\n",
    "        tf.print('\\x1b[1;32mSearching for the latest checkpoint...\\x1b[0m')\n",
    "        latest_checkpoint = c_manager.latest_checkpoint\n",
    "        if latest_checkpoint:\n",
    "            checkpoint_index = int(latest_checkpoint.split(sep='ckpt-')[-1])\n",
    "            status = checkpoint.restore(latest_checkpoint)\n",
    "            status.expect_partial()\n",
    "            tf.print(f'---Restored from {c_manager.latest_checkpoint}---')\n",
    "        else:\n",
    "            raise FileNotFoundError(f'Cannot find checkpoint in {checkpoint_dir}')\n",
    "    else:\n",
    "        checkpoint_fpath = checkpoint_dir + 'ckpt-' + str(checkpoint_index)\n",
    "        status = checkpoint.restore(checkpoint_fpath) # Let TF to handle error cases.\n",
    "        status.expect_partial()\n",
    "        tf.print(f'---Restored from {checkpoint_fpath}---')\n",
    "    return checkpoint_index\n",
    "\n",
    "\n",
    "def prevent_overwrite(key, target_path):\n",
    "    if (key == 'dummy_db') & os.path.exists(target_path):\n",
    "        answer = input(f'{target_path} exists. Will you overwrite (y/N)?')\n",
    "        if answer.lower() not in ['y', 'yes']: sys.exit()\n",
    "\n",
    "\n",
    "def get_data_source(cfg, source_root_dir, skip_dummy):\n",
    "    dataset = Dataset(cfg)\n",
    "    ds = dict()\n",
    "    if source_root_dir:\n",
    "        ds['custom_source'] = dataset.get_custom_db_ds(source_root_dir)\n",
    "    else:\n",
    "        if skip_dummy:\n",
    "            tf.print(\"Excluding \\033[33m'dummy_db'\\033[0m from source.\")\n",
    "            pass\n",
    "        else:\n",
    "            ds['dummy_db'] = dataset.get_test_dummy_db_ds()\n",
    "\n",
    "        if dataset.datasel_test_query_db in ['unseen_icassp', 'unseen_syn']:\n",
    "            ds['query'], ds['db'] = dataset.get_test_query_db_ds()\n",
    "        else:\n",
    "            raise ValueError(dataset.datasel_test_query_db)\n",
    "\n",
    "    tf.print(f'\\x1b[1;32mData source: {ds.keys()}\\x1b[0m',\n",
    "             f'{dataset.datasel_test_query_db}')\n",
    "    return ds\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(X, m_pre, m_fp):\n",
    "    \"\"\" Test step used for generating fingerprint \"\"\"\n",
    "    # X is not (Xa, Xp) here. The second element is reduced now.\n",
    "    m_fp.trainable = False\n",
    "    return m_fp(m_pre(X))  # (BSZ, Dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = cfg['MODEL']['EMB_SZ']\n",
    "\n",
    "assert n_items > 0\n",
    "arr_shape = (n_items, dim)\n",
    "arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                dtype='float32',\n",
    "                mode='w+',\n",
    "                shape=arr_shape)\n",
    "np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)\n",
    "\n",
    "arr[i * bsz:(i + 1) * bsz, :] = emb.numpy() # Writing on disk.\n",
    "i += 1\n",
    "\n",
    "\n",
    "sz_check[key] = len(arr)\n",
    "arr.flush(); del(arr) # Close memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = cfg['MODEL']['EMB_SZ']\n",
    "n_items = len(X) #ds[key].n_samples\n",
    "arr_shape = (n_items, dim)\n",
    "print(arr_shape)\n",
    "key = 'query-134'\n",
    "\n",
    "output_root_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + \\\n",
    "            f'/{key}/'\n",
    "\n",
    "\n",
    "arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                dtype='float32',\n",
    "                mode='w+',\n",
    "                shape=arr_shape)\n",
    "np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)\n",
    "\n",
    "i=0\n",
    "arr[i * bsz:(i + 1) * bsz, :] = emb.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fingerprint(cfg,\n",
    "                         checkpoint_name,\n",
    "                         checkpoint_index,\n",
    "                         source_root_dir,\n",
    "                         output_root_dir,\n",
    "                         skip_dummy):\n",
    "    \"\"\"\n",
    "    After run, the output (generated fingerprints) directory will be:\n",
    "      .\n",
    "      └──logs\n",
    "         └── emb\n",
    "             └── CHECKPOINT_NAME\n",
    "                 └── CHECKPOINT_INDEX\n",
    "                     ├── db.mm\n",
    "                     ├── db_shape.npy\n",
    "                     ├── dummy_db.mm\n",
    "                     ├── dummy_db_shape.npy\n",
    "                     ├── query.mm\n",
    "                     └── query_shape.npy\n",
    "    \"\"\"\n",
    "    # Build and load checkpoint\n",
    "    m_pre, m_fp = build_fp(cfg)\n",
    "    checkpoint_root_dir = cfg['DIR']['LOG_ROOT_DIR'] + 'checkpoint/'\n",
    "    checkpoint_index = load_checkpoint(checkpoint_root_dir, checkpoint_name,\n",
    "                                       checkpoint_index, m_fp)\n",
    "\n",
    "    # Get data source\n",
    "    \"\"\" ds = {'key1': <Dataset>, 'key2': <Dataset>, ...} \"\"\"\n",
    "    ds = get_data_source(cfg, source_root_dir, skip_dummy)\n",
    "\n",
    "    # Make output directory\n",
    "    if output_root_dir:\n",
    "        output_root_dir = output_root_dir + f'/{checkpoint_name}/{checkpoint_index}/'\n",
    "    else:\n",
    "        output_root_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + \\\n",
    "            f'/{checkpoint_name}/{checkpoint_index}/'\n",
    "    os.makedirs(output_root_dir, exist_ok=True)\n",
    "    if not skip_dummy:\n",
    "        prevent_overwrite('dummy_db', f'{output_root_dir}/dummy_db.mm')\n",
    "\n",
    "    # Generate\n",
    "    sz_check = dict() # for warning message\n",
    "    for key in ds.keys():\n",
    "        bsz = int(cfg['BSZ']['TS_BATCH_SZ'])  # Do not use ds.bsz here.\n",
    "        # n_items = len(ds[key]) * bsz\n",
    "        n_items = ds[key].n_samples\n",
    "        dim = cfg['MODEL']['EMB_SZ']\n",
    "        \"\"\"\n",
    "        Why use \"memmap\"?\n",
    "\n",
    "        • First, we need to store a huge uncompressed embedding vectors until\n",
    "          constructing a compressed DB with IVF-PQ (using FAISS). Handling a\n",
    "          huge ndarray is not a memory-safe way: \"memmap\" consume 0 memory.\n",
    "\n",
    "        • Second, Faiss-GPU does not support reconstruction of DB from\n",
    "          compressed DB (index). In eval/eval_faiss.py, we need uncompressed\n",
    "          vectors to calaulate sequence-level matching score. The created\n",
    "          \"memmap\" will be reused at that point.\n",
    "\n",
    "        Reference:\n",
    "            https://numpy.org/doc/stable/reference/generated/numpy.memmap.html\n",
    "\n",
    "        \"\"\"\n",
    "        # Create memmap, and save shapes\n",
    "        assert n_items > 0\n",
    "        arr_shape = (n_items, dim)\n",
    "        arr = np.memmap(f'{output_root_dir}/{key}.mm',\n",
    "                        dtype='float32',\n",
    "                        mode='w+',\n",
    "                        shape=arr_shape)\n",
    "        np.save(f'{output_root_dir}/{key}_shape.npy', arr_shape)\n",
    "\n",
    "        # Fingerprinting loop\n",
    "        tf.print(\n",
    "            f\"=== Generating fingerprint from \\x1b[1;32m'{key}'\\x1b[0m \" +\n",
    "            f\"bsz={bsz}, {n_items} items, d={dim}\"+ \" ===\")\n",
    "        progbar = Progbar(len(ds[key]))\n",
    "\n",
    "        \"\"\" Parallelism to speed up preprocessing------------------------- \"\"\"\n",
    "        enq = tf.keras.utils.OrderedEnqueuer(ds[key],\n",
    "                                              use_multiprocessing=True,\n",
    "                                              shuffle=False)\n",
    "        enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "                  max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "        i = 0\n",
    "        while i < len(enq.sequence):\n",
    "            progbar.update(i)\n",
    "            X, _ = next(enq.get())\n",
    "            emb = test_step(X, m_pre, m_fp)\n",
    "            arr[i * bsz:(i + 1) * bsz, :] = emb.numpy() # Writing on disk.\n",
    "            i += 1\n",
    "        progbar.update(i, finalize=True)\n",
    "        enq.stop()\n",
    "        \"\"\" End of Parallelism-------------------------------------------- \"\"\"\n",
    "\n",
    "        tf.print(f'=== Succesfully stored {arr_shape[0]} fingerprint to {output_root_dir} ===')\n",
    "        sz_check[key] = len(arr)\n",
    "        arr.flush(); del(arr) # Close memmap\n",
    "\n",
    "    if 'custom_source' in ds.keys():\n",
    "        pass;\n",
    "    elif sz_check['db'] != sz_check['query']:\n",
    "        print(\"\\033[93mWarning: 'db' and 'query' size does not match. This can cause a problem in evaluataion stage.\\033[0m\")\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
