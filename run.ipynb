{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kapre\n",
      "  Downloading kapre-0.3.7.tar.gz (26 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from kapre) (1.24.3)\n",
      "Requirement already satisfied: librosa>=0.7.2 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from kapre) (0.9.2)\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from kapre) (2.13.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (5.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (0.4.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (0.57.1)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (23.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (1.57.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (4.24.0)\n",
      "Requirement already satisfied: setuptools in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (0.33.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->kapre) (0.41.1)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from numba>=0.45.1->librosa>=0.7.2->kapre) (0.40.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa>=0.7.2->kapre) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa>=0.7.2->kapre) (1.15.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (2.3.6)\n",
      "Requirement already satisfied: pycparser in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.7.2->kapre) (2.21)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (3.16.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (3.2.2)\n",
      "Building wheels for collected packages: kapre\n",
      "  Building wheel for kapre (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kapre: filename=kapre-0.3.7-py3-none-any.whl size=29602 sha256=aa736d8961e8cdd3ea324bb8b0094994c936c0045413fbb723932542d58702c8\n",
      "  Stored in directory: /home/dirceusilva/.cache/pip/wheels/b3/04/6b/a7c14b363e7942dad0706127cbf5b5817e51010175fda9026a\n",
      "Successfully built kapre\n",
      "Installing collected packages: kapre\n",
      "Successfully installed kapre-0.3.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kapre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import click\n",
    "import yaml\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" trainer.py \"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from model.dataset import Dataset\n",
    "from model.fp.melspec.melspectrogram import get_melspec_layer\n",
    "from model.fp.specaug_chain.specaug_chain import get_specaug_chain_layer\n",
    "from model.fp.nnfp import get_fingerprinter\n",
    "from model.fp.NTxent_loss_single_gpu import NTxentLoss\n",
    "from model.fp.online_triplet_loss import OnlineTripletLoss\n",
    "from model.fp.lamb_optimizer import LAMB\n",
    "from model.utils.experiment_helper import ExperimentHelper\n",
    "from model.utils.mini_search_subroutines import mini_search_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_specaug: spec-augmentation layer.\n",
    "    m_specaug = get_specaug_chain_layer(cfg, trainable=False)\n",
    "    #assert(m_specaug.bypass==False) # Detachable by setting m_specaug.bypass.\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_specaug, m_fp\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(X, m_pre, m_specaug, m_fp, loss_obj, helper):\n",
    "    \"\"\" Train step \"\"\"\n",
    "    # X: (Xa, Xp)\n",
    "    # Xa: anchors or originals, s.t. [xa_0, xa_1,...]\n",
    "    # Xp: augmented replicas, s.t. [xp_0, xp_1] with xp_n = rand_aug(xa_n).\n",
    "    n_anchors = len(X[0])\n",
    "    X = tf.concat(X, axis=0)\n",
    "    feat = m_specaug(m_pre(X))  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = True\n",
    "    with tf.GradientTape() as t:\n",
    "        emb = m_fp(feat)  # (BSZ, Dim)\n",
    "        loss, sim_mtx, _ = loss_obj.compute_loss(\n",
    "            emb[:n_anchors, :], emb[n_anchors:, :]) # {emb_org, emb_rep}\n",
    "    g = t.gradient(loss, m_fp.trainable_variables)\n",
    "    helper.optimizer.apply_gradients(zip(g, m_fp.trainable_variables))\n",
    "    avg_loss = helper.update_tr_loss(loss) # To tensorboard.\n",
    "    return avg_loss, sim_mtx # avg_loss: average within the current epoch\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def val_step(X, m_pre, m_fp, loss_obj, helper):\n",
    "    \"\"\" Validation step \"\"\"\n",
    "    n_anchors = len(X[0])\n",
    "    X = tf.concat(X, axis=0)\n",
    "    feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = False\n",
    "    emb = m_fp(feat)  # (BSZ, Dim)\n",
    "    loss, sim_mtx, _ = loss_obj.compute_loss(\n",
    "        emb[:n_anchors, :], emb[n_anchors:, :]) # {emb_org, emb_rep}\n",
    "    avg_loss = helper.update_val_loss(loss) # To tensorboard.\n",
    "    return avg_loss, sim_mtx\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(X, m_pre, m_fp):\n",
    "    \"\"\" Test step used for mini-search-validation \"\"\"\n",
    "    X = tf.concat(X, axis=0)\n",
    "    feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = False\n",
    "    emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)\n",
    "    emb_f_postL2 = tf.math.l2_normalize(emb_f, axis=1)\n",
    "    emb_gf = m_fp.div_enc(emb_f)\n",
    "    emb_gf = tf.math.l2_normalize(emb_gf, axis=1)\n",
    "    return emb_f, emb_f_postL2, emb_gf # f(.), L2(f(.)), L2(g(f(.))\n",
    "\n",
    "\n",
    "def mini_search_validation(ds, m_pre, m_fp, mode='argmin',\n",
    "                           scopes=[1, 3, 5, 9, 11, 19], max_n_samples=3000):\n",
    "    \"\"\" Mini-search-validation \"\"\"\n",
    "    # Construct mini-DB\n",
    "    key_strs = ['f', 'L2(f)', 'g(f)']\n",
    "    m_fp.trainable = False\n",
    "    (db, query, emb, dim) = (dict(), dict(), dict(), dict())\n",
    "    dim['f'] = dim['L2(f)'] = m_fp.front_hidden_ch[-1]\n",
    "    dim['g(f)'] = m_fp.emb_sz\n",
    "    bsz = ds.bsz\n",
    "    n_anchor = bsz // 2\n",
    "    n_iter = min(len(ds), max_n_samples // bsz)\n",
    "    for k in key_strs:\n",
    "        (db[k], query[k]) = (tf.zeros((0, dim[k])), tf.zeros((0, dim[k])))\n",
    "    for i in range(n_iter):\n",
    "        X = ds.__getitem__(i)\n",
    "        emb['f'], emb['L2(f)'], emb['g(f)'] = test_step(X, m_pre, m_fp)\n",
    "        for k in key_strs:\n",
    "            db[k] = tf.concat((db[k], emb[k][:n_anchor, :]), axis=0)\n",
    "            query[k] = tf.concat((query[k], emb[k][n_anchor:, :]), axis=0)\n",
    "\n",
    "    # Search test\n",
    "    accs_by_scope = dict()\n",
    "    for k in key_strs:\n",
    "        tf.print(f'======= mini-search-validation: \\033[31m{mode} \\033[33m{k} \\033[0m=======' + '\\033[0m')\n",
    "        query[k] = tf.expand_dims(query[k], axis=1) # (nQ, d) --> (nQ, 1, d)\n",
    "        accs_by_scope[k], _ = mini_search_eval(\n",
    "            query[k], db[k], scopes, mode, display=True)\n",
    "    return accs_by_scope, scopes, key_strs\n",
    "\n",
    "\n",
    "def trainer(cfg, checkpoint_name):\n",
    "    # Dataloader\n",
    "    dataset = Dataset(cfg)\n",
    "\n",
    "    # Build models.\n",
    "    m_pre, m_specaug, m_fp = build_fp(cfg)\n",
    "\n",
    "    # Learning schedule\n",
    "    total_nsteps = cfg['TRAIN']['MAX_EPOCH'] * len(dataset.get_train_ds())\n",
    "    if cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS':\n",
    "        lr_schedule = tf.keras.experimental.CosineDecay(\n",
    "            initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "            decay_steps=total_nsteps,\n",
    "            alpha=1e-06)\n",
    "    elif cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS-RESTART':\n",
    "        lr_schedule = tf.keras.experimental.CosineDecayRestarts(\n",
    "            initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "            first_decay_steps=int(total_nsteps * 0.1),\n",
    "            num_periods=0.5,\n",
    "            alpha=2e-06)\n",
    "    else:\n",
    "        lr_schedule = float(cfg['TRAIN']['LR'])\n",
    "\n",
    "    # Optimizer\n",
    "    if cfg['TRAIN']['OPTIMIZER'].upper() == 'LAMB':\n",
    "        opt = LAMB(learning_rate=lr_schedule)\n",
    "    elif cfg['TRAIN']['OPTIMIZER'].upper() == 'ADAM':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['TRAIN']['OPTIMIZER'])\n",
    "\n",
    "    # Experiment helper: see utils.experiment_helper.py for details.\n",
    "    helper = ExperimentHelper(\n",
    "        checkpoint_name=checkpoint_name,\n",
    "        optimizer=opt,\n",
    "        model_to_checkpoint=m_fp,\n",
    "        cfg=cfg)\n",
    "\n",
    "    # Loss objects\n",
    "    if cfg['LOSS']['LOSS_MODE'].upper() == 'NTXENT': # Default\n",
    "        loss_obj_train = NTxentLoss(\n",
    "            n_org=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            n_rep=cfg['BSZ']['TR_BATCH_SZ'] - cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            tau=cfg['LOSS']['TAU'])\n",
    "        loss_obj_val = NTxentLoss(\n",
    "            n_org=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            n_rep=cfg['BSZ']['VAL_BATCH_SZ'] - cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            tau=cfg['LOSS']['TAU'])\n",
    "    elif cfg['LOSS']['LOSS_MODE'].upper() == 'ONLINE-TRIPLET': # Now-playing\n",
    "        loss_obj_train = OnlineTripletLoss(\n",
    "            bsz=cfg['BSZ']['TR_BATCH_SZ'],\n",
    "            n_anchor=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            mode = 'semi-hard',\n",
    "            margin=cfg['LOSS']['MARGIN'])\n",
    "        loss_obj_val = OnlineTripletLoss(\n",
    "            bsz=cfg['BSZ']['VAL_BATCH_SZ'],\n",
    "            n_anchor=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            mode = 'all', # use 'all' mode for validation\n",
    "            margin=0.)\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['LOSS']['LOSS_MODE'])\n",
    "\n",
    "    # Training loop\n",
    "    ep_start = helper.epoch\n",
    "    ep_max = cfg['TRAIN']['MAX_EPOCH']\n",
    "    for ep in range(ep_start, ep_max + 1):\n",
    "        tf.print(f'EPOCH: {ep}/{ep_max}')\n",
    "\n",
    "        # Train\n",
    "        \"\"\" Parallelism to speed up preprocessing.............. \"\"\"\n",
    "        train_ds = dataset.get_train_ds(cfg['DATA_SEL']['REDUCE_ITEMS_P'])\n",
    "        progbar = Progbar(len(train_ds))\n",
    "        enq = tf.keras.utils.OrderedEnqueuer(\n",
    "            train_ds, use_multiprocessing=True, shuffle=train_ds.shuffle)\n",
    "        enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "                  max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "        i = 0\n",
    "        while i < len(enq.sequence):\n",
    "            X = next(enq.get()) # X: Tuple(Xa, Xp)\n",
    "            avg_loss, sim_mtx = train_step(X, m_pre, m_specaug, m_fp,\n",
    "                                            loss_obj_train, helper)\n",
    "            progbar.add(1, values=[(\"tr loss\", avg_loss)])\n",
    "            i += 1\n",
    "        enq.stop()\n",
    "        \"\"\" End of Parallelism................................. \"\"\"\n",
    "\n",
    "        if cfg['TRAIN']['SAVE_IMG'] and (sim_mtx is not None):\n",
    "            helper.write_image_tensorboard('tr_sim_mtx', sim_mtx.numpy())\n",
    "\n",
    "        # Validate\n",
    "        \"\"\" Parallelism to speed up preprocessing.............. \"\"\"\n",
    "        val_ds = dataset.get_val_ds(max_song=250) # max 500\n",
    "        enq = tf.keras.utils.OrderedEnqueuer(\n",
    "            val_ds, use_multiprocessing=True, shuffle=False)\n",
    "        enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "                  max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "        i = 0\n",
    "        while i < len(enq.sequence):\n",
    "            X = next(enq.get()) # X: Tuple(Xa, Xp)\n",
    "            _, sim_mtx = val_step(X, m_pre, m_fp, loss_obj_val,\n",
    "                                  helper)\n",
    "            i += 1\n",
    "        enq.stop()\n",
    "        \"\"\" End of Parallelism................................. \"\"\"\n",
    "\n",
    "        if cfg['TRAIN']['SAVE_IMG'] and (sim_mtx is not None):\n",
    "            helper.write_image_tensorboard('val_sim_mtx', sim_mtx.numpy())\n",
    "\n",
    "        # On epoch end\n",
    "        tf.print('tr_loss:{:.4f}, val_loss:{:.4f}'.format(\n",
    "            helper._tr_loss.result(), helper._val_loss.result()))\n",
    "        helper.update_on_epoch_end(save_checkpoint_now=True)\n",
    "\n",
    "\n",
    "        # Mini-search-validation (optional)\n",
    "        if cfg['TRAIN']['MINI_TEST_IN_TRAIN']:\n",
    "            accs_by_scope, scopes, key_strs = mini_search_validation(\n",
    "                val_ds, m_pre, m_fp)\n",
    "            for k in key_strs:\n",
    "                helper.update_minitest_acc(accs_by_scope[k], scopes, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def update_config(cfg, key1: str, key2: str, val):\n",
    "    cfg[key1][key2] = val\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def print_config(cfg):\n",
    "    os.system(\"\")\n",
    "    print('\\033[36m' + yaml.dump(cfg, indent=4, width=120, sort_keys=False) +\n",
    "          '\\033[0m')\n",
    "    return\n",
    "\n",
    "\n",
    "def train(checkpoint_name, config, max_epoch):\n",
    "    \"\"\" Train a neural audio fingerprinter.\n",
    "\n",
    "    ex) python run.py train CHECKPOINT_NAME --max_epoch=100\n",
    "\n",
    "        # with custom config file\n",
    "        python run.py train CHECKPOINT_NAME --max_epoch=100 -c CONFIG_NAME\n",
    "\n",
    "    NOTE: If './LOG_ROOT_DIR/checkpoint/CHECKPOINT_NAME already exists, the training will resume from the latest checkpoint in the directory.\n",
    "\n",
    "    \"\"\"\n",
    "    from model.utils.config_gpu_memory_lim import allow_gpu_memory_growth\n",
    "    from model.trainer import trainer\n",
    "\n",
    "    cfg = load_config(config)\n",
    "    if max_epoch: update_config(cfg, 'TRAIN', 'MAX_EPOCH', max_epoch)\n",
    "    print_config(cfg)\n",
    "    # allow_gpu_memory_growth()\n",
    "    trainer(cfg, checkpoint_name)\n",
    "\n",
    "\"\"\" Generate fingerprint (after training) \"\"\"\n",
    "def generate(checkpoint_name, checkpoint_index, config, source, output, skip_dummy):\n",
    "    \"\"\" Generate fingerprints from a saved checkpoint.\n",
    "\n",
    "    ex) python run.py generate CHECKPOINT_NAME\n",
    "\n",
    "    With custom config: \\b\\n\n",
    "        python run.py generate CHECKPOINT_NAME -c CONFIG_NAME\n",
    "\n",
    "    • If CHECKPOINT_INDEX is not specified, the latest checkpoint in the OUTPUT_ROOT_DIR will be loaded.\n",
    "    • The default value for the fingerprinting source is [TEST_DUMMY_DB] and [TEST_QUERY_DB] specified in config file.\n",
    "\n",
    "    \"\"\"\n",
    "    from model.utils.config_gpu_memory_lim import allow_gpu_memory_growth\n",
    "    from model.generate import generate_fingerprint\n",
    "\n",
    "    cfg = load_config(config)\n",
    "    allow_gpu_memory_growth()\n",
    "    generate_fingerprint(cfg, checkpoint_name, checkpoint_index, source, output, skip_dummy)\n",
    "\n",
    "def evaluate(checkpoint_name, checkpoint_index, config, index_type,\n",
    "             test_seq_len, test_ids, nogpu):\n",
    "    \"\"\" Search and evalutation.\n",
    "\n",
    "    ex) python run.py evaluate CHECKPOINT_NAME CHECKPOINT_INDEX\n",
    "\n",
    "    With options: \\b\\n\n",
    "\n",
    "    ex) python run.py evaluate CHECKPOINT_NAME CHEKPOINT_INDEX -i ivfpq -t 3000 --nogpu\n",
    "\n",
    "\n",
    "    • Currently, the 'evaluate' command does not reference any information other\n",
    "    than the output log directory from the config file.\n",
    "    \"\"\"\n",
    "    from eval.eval_faiss import eval_faiss\n",
    "\n",
    "    cfg = load_config(config)\n",
    "    emb_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + checkpoint_name + '/' + \\\n",
    "        str(checkpoint_index) + '/'\n",
    "\n",
    "    if nogpu:\n",
    "        eval_faiss([emb_dir, \"--index_type\", index_type, \"--test_seq_len\",\n",
    "                    test_seq_len, \"--test_ids\", test_ids, \"--nogpu\"])\n",
    "    else:\n",
    "        eval_faiss([emb_dir, \"--index_type\", index_type, \"--test_seq_len\",\n",
    "                    test_seq_len, \"--test_ids\", test_ids])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name:str = \"CHECKPOINT\"   # string\n",
    "checkpoint_index:int = None  # int\n",
    "config:str = \"default\"       # string 'default'\n",
    "index_type:str = 'IVFPQ'  # {'L2', 'IVF', 'IVFPQ', \" + \"'IVFPQ-RR', 'IVFPQ-ONDISK', HNSW'}\"\n",
    "test_seq_len:str =  '11'   # string '1 3 5 9 11 19' segundos \n",
    "test_ids:str = \"icassp\"      # string 'icassp'\n",
    "nogpu:bool = False         # False or True\n",
    "max_epoch:int = 5     # int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(config)\n",
    "dataset = Dataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.get_train_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'genUnbalSequence' object has no attribute 'tr_source_fps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtr_source_fps\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'genUnbalSequence' object has no attribute 'tr_source_fps'"
     ]
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<model.dataset.Dataset at 0x7fb70e01d490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'get_single_element'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_element\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'get_single_element'"
     ]
    }
   ],
   "source": [
    "dataset.get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
