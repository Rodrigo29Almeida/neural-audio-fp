{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kapre\n",
      "  Downloading kapre-0.3.7.tar.gz (26 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from kapre) (1.24.3)\n",
      "Requirement already satisfied: librosa>=0.7.2 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from kapre) (0.9.2)\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from kapre) (2.13.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (5.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (0.4.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (0.57.1)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from librosa>=0.7.2->kapre) (23.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (1.57.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (4.24.0)\n",
      "Requirement already satisfied: setuptools in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorflow>=2.0.0->kapre) (0.33.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->kapre) (0.41.1)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from numba>=0.45.1->librosa>=0.7.2->kapre) (0.40.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa>=0.7.2->kapre) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa>=0.7.2->kapre) (1.15.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (2.3.6)\n",
      "Requirement already satisfied: pycparser in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.7.2->kapre) (2.21)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (3.16.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/dirceusilva/.pyenv/versions/3.9.17/envs/audio/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->kapre) (3.2.2)\n",
      "Building wheels for collected packages: kapre\n",
      "  Building wheel for kapre (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kapre: filename=kapre-0.3.7-py3-none-any.whl size=29602 sha256=aa736d8961e8cdd3ea324bb8b0094994c936c0045413fbb723932542d58702c8\n",
      "  Stored in directory: /home/dirceusilva/.cache/pip/wheels/b3/04/6b/a7c14b363e7942dad0706127cbf5b5817e51010175fda9026a\n",
      "Successfully built kapre\n",
      "Installing collected packages: kapre\n",
      "Successfully installed kapre-0.3.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install kapre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import click\n",
    "import yaml\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" trainer.py \"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from model.dataset import Dataset\n",
    "from model.fp.melspec.melspectrogram import get_melspec_layer\n",
    "from model.fp.specaug_chain.specaug_chain import get_specaug_chain_layer\n",
    "from model.fp.nnfp import get_fingerprinter\n",
    "from model.fp.NTxent_loss_single_gpu import NTxentLoss\n",
    "from model.fp.online_triplet_loss import OnlineTripletLoss\n",
    "from model.fp.lamb_optimizer import LAMB\n",
    "from model.utils.experiment_helper import ExperimentHelper\n",
    "from model.utils.mini_search_subroutines import mini_search_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_specaug: spec-augmentation layer.\n",
    "    m_specaug = get_specaug_chain_layer(cfg, trainable=False)\n",
    "    #assert(m_specaug.bypass==False) # Detachable by setting m_specaug.bypass.\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_specaug, m_fp\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(X, m_pre, m_specaug, m_fp, loss_obj, helper):\n",
    "    \"\"\" Train step \"\"\"\n",
    "    # X: (Xa, Xp)\n",
    "    # Xa: anchors or originals, s.t. [xa_0, xa_1,...]\n",
    "    # Xp: augmented replicas, s.t. [xp_0, xp_1] with xp_n = rand_aug(xa_n).\n",
    "    n_anchors = len(X[0])\n",
    "    X = tf.concat(X, axis=0)\n",
    "    feat = m_specaug(m_pre(X))  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = True\n",
    "    pdb.set_trace()\n",
    "    with tf.GradientTape() as t:\n",
    "        emb = m_fp(feat)  # (BSZ, Dim)\n",
    "        loss, sim_mtx, _ = loss_obj.compute_loss(\n",
    "            emb[:n_anchors, :], emb[n_anchors:, :]) # {emb_org, emb_rep}\n",
    "    g = t.gradient(loss, m_fp.trainable_variables)\n",
    "    helper.optimizer.apply_gradients(zip(g, m_fp.trainable_variables))\n",
    "    avg_loss = helper.update_tr_loss(loss) # To tensorboard.\n",
    "    return avg_loss, sim_mtx # avg_loss: average within the current epoch\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def val_step(X, m_pre, m_fp, loss_obj, helper):\n",
    "    \"\"\" Validation step \"\"\"\n",
    "    n_anchors = len(X[0])\n",
    "    X = tf.concat(X, axis=0)\n",
    "    feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = False\n",
    "    emb = m_fp(feat)  # (BSZ, Dim)\n",
    "    loss, sim_mtx, _ = loss_obj.compute_loss(\n",
    "        emb[:n_anchors, :], emb[n_anchors:, :]) # {emb_org, emb_rep}\n",
    "    avg_loss = helper.update_val_loss(loss) # To tensorboard.\n",
    "    return avg_loss, sim_mtx\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(X, m_pre, m_fp):\n",
    "    \"\"\" Test step used for mini-search-validation \"\"\"\n",
    "    X = tf.concat(X, axis=0)\n",
    "    feat = m_pre(X)  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = False\n",
    "    emb_f = m_fp.front_conv(feat)  # (BSZ, Dim)\n",
    "    emb_f_postL2 = tf.math.l2_normalize(emb_f, axis=1)\n",
    "    emb_gf = m_fp.div_enc(emb_f)\n",
    "    emb_gf = tf.math.l2_normalize(emb_gf, axis=1)\n",
    "    return emb_f, emb_f_postL2, emb_gf # f(.), L2(f(.)), L2(g(f(.))\n",
    "\n",
    "\n",
    "def mini_search_validation(ds, m_pre, m_fp, mode='argmin',\n",
    "                           scopes=[1, 3, 5, 9, 11, 19], max_n_samples=3000):\n",
    "    \"\"\" Mini-search-validation \"\"\"\n",
    "    # Construct mini-DB\n",
    "    key_strs = ['f', 'L2(f)', 'g(f)']\n",
    "    m_fp.trainable = False\n",
    "    (db, query, emb, dim) = (dict(), dict(), dict(), dict())\n",
    "    dim['f'] = dim['L2(f)'] = m_fp.front_hidden_ch[-1]\n",
    "    dim['g(f)'] = m_fp.emb_sz\n",
    "    bsz = ds.bsz\n",
    "    n_anchor = bsz // 2\n",
    "    n_iter = min(len(ds), max_n_samples // bsz)\n",
    "    for k in key_strs:\n",
    "        (db[k], query[k]) = (tf.zeros((0, dim[k])), tf.zeros((0, dim[k])))\n",
    "    for i in range(n_iter):\n",
    "        X = ds.__getitem__(i)\n",
    "        emb['f'], emb['L2(f)'], emb['g(f)'] = test_step(X, m_pre, m_fp)\n",
    "        for k in key_strs:\n",
    "            db[k] = tf.concat((db[k], emb[k][:n_anchor, :]), axis=0)\n",
    "            query[k] = tf.concat((query[k], emb[k][n_anchor:, :]), axis=0)\n",
    "\n",
    "    # Search test\n",
    "    accs_by_scope = dict()\n",
    "    for k in key_strs:\n",
    "        tf.print(f'======= mini-search-validation: \\033[31m{mode} \\033[33m{k} \\033[0m=======' + '\\033[0m')\n",
    "        query[k] = tf.expand_dims(query[k], axis=1) # (nQ, d) --> (nQ, 1, d)\n",
    "        accs_by_scope[k], _ = mini_search_eval(\n",
    "            query[k], db[k], scopes, mode, display=True)\n",
    "    return accs_by_scope, scopes, key_strs\n",
    "\n",
    "\n",
    "def trainer(cfg, checkpoint_name):\n",
    "    # Dataloader\n",
    "    dataset = Dataset(cfg)\n",
    "\n",
    "    # Build models.\n",
    "    m_pre, m_specaug, m_fp = build_fp(cfg)\n",
    "\n",
    "    # Learning schedule\n",
    "    total_nsteps = cfg['TRAIN']['MAX_EPOCH'] * len(dataset.get_train_ds())\n",
    "    if cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS':\n",
    "        lr_schedule = tf.keras.experimental.CosineDecay(\n",
    "            initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "            decay_steps=total_nsteps,\n",
    "            alpha=1e-06)\n",
    "    elif cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS-RESTART':\n",
    "        lr_schedule = tf.keras.experimental.CosineDecayRestarts(\n",
    "            initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "            first_decay_steps=int(total_nsteps * 0.1),\n",
    "            num_periods=0.5,\n",
    "            alpha=2e-06)\n",
    "    else:\n",
    "        lr_schedule = float(cfg['TRAIN']['LR'])\n",
    "\n",
    "    # Optimizer\n",
    "    if cfg['TRAIN']['OPTIMIZER'].upper() == 'LAMB':\n",
    "        opt = LAMB(learning_rate=lr_schedule)\n",
    "    elif cfg['TRAIN']['OPTIMIZER'].upper() == 'ADAM':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['TRAIN']['OPTIMIZER'])\n",
    "\n",
    "    # Experiment helper: see utils.experiment_helper.py for details.\n",
    "    helper = ExperimentHelper(\n",
    "        checkpoint_name=checkpoint_name,\n",
    "        optimizer=opt,\n",
    "        model_to_checkpoint=m_fp,\n",
    "        cfg=cfg)\n",
    "\n",
    "    # Loss objects\n",
    "    if cfg['LOSS']['LOSS_MODE'].upper() == 'NTXENT': # Default\n",
    "        loss_obj_train = NTxentLoss(\n",
    "            n_org=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            n_rep=cfg['BSZ']['TR_BATCH_SZ'] - cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            tau=cfg['LOSS']['TAU'])\n",
    "        loss_obj_val = NTxentLoss(\n",
    "            n_org=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            n_rep=cfg['BSZ']['VAL_BATCH_SZ'] - cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            tau=cfg['LOSS']['TAU'])\n",
    "    elif cfg['LOSS']['LOSS_MODE'].upper() == 'ONLINE-TRIPLET': # Now-playing\n",
    "        loss_obj_train = OnlineTripletLoss(\n",
    "            bsz=cfg['BSZ']['TR_BATCH_SZ'],\n",
    "            n_anchor=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            mode = 'semi-hard',\n",
    "            margin=cfg['LOSS']['MARGIN'])\n",
    "        loss_obj_val = OnlineTripletLoss(\n",
    "            bsz=cfg['BSZ']['VAL_BATCH_SZ'],\n",
    "            n_anchor=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            mode = 'all', # use 'all' mode for validation\n",
    "            margin=0.)\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['LOSS']['LOSS_MODE'])\n",
    "\n",
    "    # Training loop\n",
    "    ep_start = helper.epoch\n",
    "    ep_max = cfg['TRAIN']['MAX_EPOCH']\n",
    "    for ep in range(ep_start, ep_max + 1):\n",
    "        tf.print(f'EPOCH: {ep}/{ep_max}')\n",
    "\n",
    "        # Train\n",
    "        \"\"\" Parallelism to speed up preprocessing.............. \"\"\"\n",
    "        train_ds = dataset.get_train_ds(cfg['DATA_SEL']['REDUCE_ITEMS_P'])\n",
    "        progbar = Progbar(len(train_ds))\n",
    "        enq = tf.keras.utils.OrderedEnqueuer(\n",
    "            train_ds, use_multiprocessing=True, shuffle=train_ds.shuffle)\n",
    "        enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "                  max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "        i = 0\n",
    "        while i < len(enq.sequence):\n",
    "            X = next(enq.get()) # X: Tuple(Xa, Xp)\n",
    "            avg_loss, sim_mtx = train_step(X, m_pre, m_specaug, m_fp,\n",
    "                                            loss_obj_train, helper)\n",
    "            progbar.add(1, values=[(\"tr loss\", avg_loss)])\n",
    "            i += 1\n",
    "        enq.stop()\n",
    "        \"\"\" End of Parallelism................................. \"\"\"\n",
    "\n",
    "        if cfg['TRAIN']['SAVE_IMG'] and (sim_mtx is not None):\n",
    "            helper.write_image_tensorboard('tr_sim_mtx', sim_mtx.numpy())\n",
    "\n",
    "        # Validate\n",
    "        \"\"\" Parallelism to speed up preprocessing.............. \"\"\"\n",
    "        val_ds = dataset.get_val_ds(max_song=250) # max 500\n",
    "        enq = tf.keras.utils.OrderedEnqueuer(\n",
    "            val_ds, use_multiprocessing=True, shuffle=False)\n",
    "        enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "                  max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])\n",
    "        i = 0\n",
    "        while i < len(enq.sequence):\n",
    "            X = next(enq.get()) # X: Tuple(Xa, Xp)\n",
    "            _, sim_mtx = val_step(X, m_pre, m_fp, loss_obj_val,\n",
    "                                  helper)\n",
    "            i += 1\n",
    "        enq.stop()\n",
    "        \"\"\" End of Parallelism................................. \"\"\"\n",
    "\n",
    "        if cfg['TRAIN']['SAVE_IMG'] and (sim_mtx is not None):\n",
    "            helper.write_image_tensorboard('val_sim_mtx', sim_mtx.numpy())\n",
    "\n",
    "        # On epoch end\n",
    "        tf.print('tr_loss:{:.4f}, val_loss:{:.4f}'.format(\n",
    "            helper._tr_loss.result(), helper._val_loss.result()))\n",
    "        helper.update_on_epoch_end(save_checkpoint_now=True)\n",
    "\n",
    "\n",
    "        # Mini-search-validation (optional)\n",
    "        if cfg['TRAIN']['MINI_TEST_IN_TRAIN']:\n",
    "            accs_by_scope, scopes, key_strs = mini_search_validation(\n",
    "                val_ds, m_pre, m_fp)\n",
    "            for k in key_strs:\n",
    "                helper.update_minitest_acc(accs_by_scope[k], scopes, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def update_config(cfg, key1: str, key2: str, val):\n",
    "    cfg[key1][key2] = val\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def print_config(cfg):\n",
    "    os.system(\"\")\n",
    "    print('\\033[36m' + yaml.dump(cfg, indent=4, width=120, sort_keys=False) +\n",
    "          '\\033[0m')\n",
    "    return\n",
    "\n",
    "\n",
    "def train(checkpoint_name, config, max_epoch):\n",
    "    \"\"\" Train a neural audio fingerprinter.\n",
    "\n",
    "    ex) python run.py train CHECKPOINT_NAME --max_epoch=100\n",
    "\n",
    "        # with custom config file\n",
    "        python run.py train CHECKPOINT_NAME --max_epoch=100 -c CONFIG_NAME\n",
    "\n",
    "    NOTE: If './LOG_ROOT_DIR/checkpoint/CHECKPOINT_NAME already exists, the training will resume from the latest checkpoint in the directory.\n",
    "\n",
    "    \"\"\"\n",
    "    from model.utils.config_gpu_memory_lim import allow_gpu_memory_growth\n",
    "    from model.trainer import trainer\n",
    "\n",
    "    cfg = load_config(config)\n",
    "    if max_epoch: update_config(cfg, 'TRAIN', 'MAX_EPOCH', max_epoch)\n",
    "    print_config(cfg)\n",
    "    # allow_gpu_memory_growth()\n",
    "    trainer(cfg, checkpoint_name)\n",
    "\n",
    "\"\"\" Generate fingerprint (after training) \"\"\"\n",
    "def generate(checkpoint_name, checkpoint_index, config, source, output, skip_dummy):\n",
    "    \"\"\" Generate fingerprints from a saved checkpoint.\n",
    "\n",
    "    ex) python run.py generate CHECKPOINT_NAME\n",
    "\n",
    "    With custom config: \\b\\n\n",
    "        python run.py generate CHECKPOINT_NAME -c CONFIG_NAME\n",
    "\n",
    "    • If CHECKPOINT_INDEX is not specified, the latest checkpoint in the OUTPUT_ROOT_DIR will be loaded.\n",
    "    • The default value for the fingerprinting source is [TEST_DUMMY_DB] and [TEST_QUERY_DB] specified in config file.\n",
    "\n",
    "    \"\"\"\n",
    "    from model.utils.config_gpu_memory_lim import allow_gpu_memory_growth\n",
    "    from model.generate import generate_fingerprint\n",
    "\n",
    "    cfg = load_config(config)\n",
    "    allow_gpu_memory_growth()\n",
    "    generate_fingerprint(cfg, checkpoint_name, checkpoint_index, source, output, skip_dummy)\n",
    "\n",
    "def evaluate(checkpoint_name, checkpoint_index, config, index_type,\n",
    "             test_seq_len, test_ids, nogpu):\n",
    "    \"\"\" Search and evalutation.\n",
    "\n",
    "    ex) python run.py evaluate CHECKPOINT_NAME CHECKPOINT_INDEX\n",
    "\n",
    "    With options: \\b\\n\n",
    "\n",
    "    ex) python run.py evaluate CHECKPOINT_NAME CHEKPOINT_INDEX -i ivfpq -t 3000 --nogpu\n",
    "\n",
    "\n",
    "    • Currently, the 'evaluate' command does not reference any information other\n",
    "    than the output log directory from the config file.\n",
    "    \"\"\"\n",
    "    from eval.eval_faiss import eval_faiss\n",
    "\n",
    "    cfg = load_config(config)\n",
    "    emb_dir = cfg['DIR']['OUTPUT_ROOT_DIR'] + checkpoint_name + '/' + \\\n",
    "        str(checkpoint_index) + '/'\n",
    "\n",
    "    if nogpu:\n",
    "        eval_faiss([emb_dir, \"--index_type\", index_type, \"--test_seq_len\",\n",
    "                    test_seq_len, \"--test_ids\", test_ids, \"--nogpu\"])\n",
    "    else:\n",
    "        eval_faiss([emb_dir, \"--index_type\", index_type, \"--test_seq_len\",\n",
    "                    test_seq_len, \"--test_ids\", test_ids])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DEBUG**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inicializções**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name:str = \"CHECKPOINT\"   # string\n",
    "checkpoint_index:int = None  # int\n",
    "config:str = \"default\"       # string 'default'\n",
    "index_type:str = 'IVFPQ'  # {'L2', 'IVF', 'IVFPQ', \" + \"'IVFPQ-RR', 'IVFPQ-ONDISK', HNSW'}\"\n",
    "test_seq_len:str =  '11'   # string '1 3 5 9 11 19' segundos \n",
    "test_ids:str = \"icassp\"      # string 'icassp'\n",
    "nogpu:bool = False         # False or True\n",
    "max_epoch:int = 5     # int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(config)\n",
    "dataset = Dataset(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para perceber os dados no código**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.get_train_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36365"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.get_train_ds(cfg['DATA_SEL']['REDUCE_ITEMS_P'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criei csv para ver como os dados estão organizados, há músicas com 58 segmentos e outras com 59. Devido à diferença de bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds.fns_event_seg_list\n",
    "#dados=train_ds.index_event\n",
    "\n",
    "#dados=train_ds.fns_bg_seg_list\n",
    "#dados=train_ds.index_bg\n",
    "\n",
    "#dados=train_ds.fns_ir_seg_list\n",
    "#dados=train_ds.index_ir\n",
    "\n",
    "#train_ds.index_speech #NÃO ESTÁ INCLUIDO NOS RESULTADOS NO ARTIGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581850"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.get_train_ds().fns_event_seg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ```OrderedEnqueuer()``` é usado para processar os dados em batches de forma ordenado. Isto é, processar os dados na mesma ordem que foram fornecidos.\n",
    "O shuffle serve para baralhar os dados. À POSTERIOR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enq = tf.keras.utils.OrderedEnqueuer(train_ds, use_multiprocessing=True, shuffle=train_ds.shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[ 0.08642578,  0.046875  , -0.26290894, ...,  0.15084839,\n",
      "          0.1022644 , -0.04901123]],\n",
      "\n",
      "       [[ 0.0211792 , -0.02392578, -0.03652954, ...,  0.09417725,\n",
      "          0.10946655,  0.09588623]],\n",
      "\n",
      "       [[ 0.11630249,  0.20666504,  0.17889404, ...,  0.01394653,\n",
      "         -0.08651733, -0.00036621]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.28250122, -0.27682495, -0.140625  , ..., -0.27990723,\n",
      "         -0.06842041, -0.12115479]],\n",
      "\n",
      "       [[-0.08248901, -0.09136963,  0.01858521, ..., -0.01055908,\n",
      "         -0.00204468, -0.01480103]],\n",
      "\n",
      "       [[ 0.03213501,  0.03125   ,  0.02627563, ..., -0.09487915,\n",
      "         -0.11694336, -0.03839111]]], dtype=float32), array([[[-0.05917474,  0.11544432,  0.05569585, ..., -0.03807323,\n",
      "         -0.04518259,  0.129547  ]],\n",
      "\n",
      "       [[ 0.3758038 , -0.1149336 , -0.2801483 , ..., -0.22336556,\n",
      "          0.06892969,  0.50643253]],\n",
      "\n",
      "       [[-0.2296791 , -0.16798344, -0.11500147, ..., -0.33349124,\n",
      "         -0.28984046, -0.26033628]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.11976889, -0.22678374, -0.1153975 , ..., -0.10699975,\n",
      "         -0.21065304, -0.14034033]],\n",
      "\n",
      "       [[-0.01536427,  0.02863059,  0.00353282, ...,  0.09443795,\n",
      "          0.14031903,  0.01484234]],\n",
      "\n",
      "       [[ 0.11495943, -0.14178874, -0.14617783, ...,  0.20338206,\n",
      "          0.21104144,  0.29197052]]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.get_train_ds(cfg['DATA_SEL']['REDUCE_ITEMS_P'])\n",
    "progbar = Progbar(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"
     ]
    }
   ],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para chegar ao erro dos ***NaN***:\n",
    "<br>(Fazer o que ot rainer faz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pre, m_specaug, m_fp = build_fp(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss objects\n",
    "if cfg['LOSS']['LOSS_MODE'].upper() == 'NTXENT': # Default\n",
    "        loss_obj_train = NTxentLoss(\n",
    "            n_org=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            n_rep=cfg['BSZ']['TR_BATCH_SZ'] - cfg['BSZ']['TR_N_ANCHOR'],\n",
    "            tau=cfg['LOSS']['TAU'])\n",
    "        loss_obj_val = NTxentLoss(\n",
    "            n_org=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            n_rep=cfg['BSZ']['VAL_BATCH_SZ'] - cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "            tau=cfg['LOSS']['TAU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nsteps = cfg['TRAIN']['MAX_EPOCH'] * len(dataset.get_train_ds())\n",
    "if cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS':\n",
    "        lr_schedule = tf.keras.experimental.CosineDecay(\n",
    "            initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "            decay_steps=total_nsteps,\n",
    "            alpha=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg['TRAIN']['OPTIMIZER'].upper() == 'ADAM':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Restoring from ./logs/checkpoint/CHECKPOINT/ckpt-100---\n"
     ]
    }
   ],
   "source": [
    "helper = ExperimentHelper(\n",
    "        checkpoint_name=checkpoint_name,\n",
    "        optimizer=opt,\n",
    "        model_to_checkpoint=m_fp,\n",
    "        cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detected `pdb.set_trace()` in user code. The code generated by AutoGraph is not optimized for step-by-step debugging. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/debugging.md.\n",
      "WARNING: Detected `pdb.set_trace()` in user code. The code generated by AutoGraph is not optimized for step-by-step debugging. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/debugging.md.\n"
     ]
    }
   ],
   "source": [
    "X = next(enq.get()) # X: Tuple(Xa, Xp)\n",
    "avg_loss, sim_mtx = train_step(X, m_pre, m_specaug, m_fp, loss_obj_train, helper)\n",
    "progbar.add(1, values=[(\"tr loss\", avg_loss)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não correr a célula com o while. Não necessário. Depois está dividida em várias células."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < len(enq.sequence):\n",
    "    X = next(enq.get()) # X: Tuple(Xa, Xp)\n",
    "    avg_loss, sim_mtx = train_step(X, m_pre, m_specaug, m_fp, loss_obj_train, helper)\n",
    "    progbar.add(1, values=[(\"tr loss\", avg_loss)])\n",
    "    i += 1\n",
    "enq.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detected `pdb.set_trace()` in user code. The code generated by AutoGraph is not optimized for step-by-step debugging. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/debugging.md.\n",
      "WARNING: Detected `pdb.set_trace()` in user code. The code generated by AutoGraph is not optimized for step-by-step debugging. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/debugging.md.\n",
      "> \u001b[0;32m/tmp/tmpsa5pypkr.py\u001b[0m(16)\u001b[0;36mtf__train_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     14 \u001b[0;31m                \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m                \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 16 \u001b[0;31m                \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m                    \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m                    \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_anchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_anchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "<tf.Tensor 'spec_aug_chainer/PartitionedCall:0' shape=(32, 256, 32, 1) dtype=float32>\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "> \u001b[0;32m/tmp/tmpsa5pypkr.py\u001b[0m(16)\u001b[0;36mtf__train_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     14 \u001b[0;31m                \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m                \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 16 \u001b[0;31m                \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m                    \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m                    \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_anchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_anchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "<module 'pdb' from '/home/rodrigo/anaconda3/envs/fp/lib/python3.8/pdb.py'>\n",
      "<module 'pdb' from '/home/rodrigo/anaconda3/envs/fp/lib/python3.8/pdb.py'>\n",
      "<module 'pdb' from '/home/rodrigo/anaconda3/envs/fp/lib/python3.8/pdb.py'>\n"
     ]
    }
   ],
   "source": [
    "train_step(X, m_pre, m_specaug, m_fp, loss_obj_train, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj=loss_obj_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Células essenciais para encontrar o erro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(enq.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train step \"\"\"\n",
    "# X: (Xa, Xp)\n",
    "# Xa: anchors or originals, s.t. [xa_0, xa_1,...]\n",
    "# Xp: augmented replicas, s.t. [xp_0, xp_1] with xp_n = rand_aug(xa_n).\n",
    "n_anchors = len(X[0])\n",
    "X = tf.concat(X, axis=0)\n",
    "feat = m_specaug(m_pre(X))  # (nA+nP, F, T, 1)\n",
    "m_fp.trainable = True\n",
    "with tf.GradientTape() as t:\n",
    "    emb = m_fp(feat)  # (BSZ, Dim)\n",
    "    loss, sim_mtx, _ = loss_obj.compute_loss(\n",
    "        emb[:n_anchors, :], emb[n_anchors:, :]) # {emb_org, emb_rep}\n",
    "g = t.gradient(loss, m_fp.trainable_variables)\n",
    "helper.optimizer.apply_gradients(zip(g, m_fp.trainable_variables))\n",
    "avg_loss = helper.update_tr_loss(loss) # To tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_anchors = len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1, 8000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.concat(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1, 8000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1, 8000), dtype=float32, numpy=\n",
       "array([[[-1.4074707e-01, -2.2067261e-01, -2.9251099e-01, ...,\n",
       "         -5.4437256e-01, -5.9899902e-01, -6.2597656e-01]],\n",
       "\n",
       "       [[ 1.8615723e-02,  1.6906738e-02, -2.1057129e-03, ...,\n",
       "         -1.2207031e-04,  1.9836426e-03,  5.6762695e-03]],\n",
       "\n",
       "       [[ 3.6621094e-04, -3.2873535e-01, -5.8938599e-01, ...,\n",
       "         -2.9125977e-01, -8.3496094e-01, -3.0117798e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.4578062e-01, -1.8511537e-01, -1.9788538e-01, ...,\n",
       "         -3.0635187e-02, -8.5666180e-02, -8.4085211e-02]],\n",
       "\n",
       "       [[ 7.5484462e-02,  4.2671114e-03, -3.0220029e-01, ...,\n",
       "         -4.4676819e-01, -3.6109880e-01, -1.6327396e-01]],\n",
       "\n",
       "       [[ 7.5484030e-03, -2.8227130e-02, -8.0381058e-02, ...,\n",
       "          1.1758718e-01,  1.2955016e-01, -2.8872149e-02]]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 256, 32, 1), dtype=float32, numpy=\n",
       "array([[[[-1.769532  ],\n",
       "         [-1.101128  ],\n",
       "         [-1.0745572 ],\n",
       "         ...,\n",
       "         [-1.4830765 ],\n",
       "         [-1.5086174 ],\n",
       "         [-1.3256644 ]],\n",
       "\n",
       "        [[-1.9381204 ],\n",
       "         [-1.1754922 ],\n",
       "         [-1.145031  ],\n",
       "         ...,\n",
       "         [-1.7465193 ],\n",
       "         [-1.6469648 ],\n",
       "         [-1.4167099 ]],\n",
       "\n",
       "        [[-1.7804332 ],\n",
       "         [-1.1693628 ],\n",
       "         [-1.1604897 ],\n",
       "         ...,\n",
       "         [-1.6153746 ],\n",
       "         [-1.4958944 ],\n",
       "         [-1.4770952 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2276578 ],\n",
       "         [-2.2438145 ],\n",
       "         [-2.2582738 ],\n",
       "         ...,\n",
       "         [-2.2608    ],\n",
       "         [-2.175364  ],\n",
       "         [-2.0337825 ]],\n",
       "\n",
       "        [[-2.2249455 ],\n",
       "         [-2.2460814 ],\n",
       "         [-2.2652597 ],\n",
       "         ...,\n",
       "         [-2.2672591 ],\n",
       "         [-2.1799297 ],\n",
       "         [-2.038486  ]],\n",
       "\n",
       "        [[-2.2196138 ],\n",
       "         [-2.2429776 ],\n",
       "         [-2.2679245 ],\n",
       "         ...,\n",
       "         [-2.2681332 ],\n",
       "         [-2.1808481 ],\n",
       "         [-2.0401351 ]]],\n",
       "\n",
       "\n",
       "       [[[-2.1248288 ],\n",
       "         [-2.0755181 ],\n",
       "         [-2.019419  ],\n",
       "         ...,\n",
       "         [-2.1851144 ],\n",
       "         [-2.196869  ],\n",
       "         [-2.2279773 ]],\n",
       "\n",
       "        [[-2.0936537 ],\n",
       "         [-2.024613  ],\n",
       "         [-1.9678302 ],\n",
       "         ...,\n",
       "         [-2.1726718 ],\n",
       "         [-2.1891127 ],\n",
       "         [-2.2313564 ]],\n",
       "\n",
       "        [[-2.0314922 ],\n",
       "         [-1.9669535 ],\n",
       "         [-1.9381047 ],\n",
       "         ...,\n",
       "         [-2.162996  ],\n",
       "         [-2.1663513 ],\n",
       "         [-2.237864  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2648625 ],\n",
       "         [-2.2651687 ],\n",
       "         [-2.2655206 ],\n",
       "         ...,\n",
       "         [-2.2663002 ],\n",
       "         [-2.2662044 ],\n",
       "         [-2.2630763 ]],\n",
       "\n",
       "        [[-2.266119  ],\n",
       "         [-2.2671232 ],\n",
       "         [-2.267762  ],\n",
       "         ...,\n",
       "         [-2.2677183 ],\n",
       "         [-2.2666426 ],\n",
       "         [-2.263388  ]],\n",
       "\n",
       "        [[-2.2667131 ],\n",
       "         [-2.2674925 ],\n",
       "         [-2.268104  ],\n",
       "         ...,\n",
       "         [-2.2680886 ],\n",
       "         [-2.26683   ],\n",
       "         [-2.2636538 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.3620937 ],\n",
       "         [-1.2109177 ],\n",
       "         [-0.63002884],\n",
       "         ...,\n",
       "         [-1.2074082 ],\n",
       "         [-1.5593979 ],\n",
       "         [-1.1854851 ]],\n",
       "\n",
       "        [[-1.4689947 ],\n",
       "         [-1.0244993 ],\n",
       "         [-0.6927283 ],\n",
       "         ...,\n",
       "         [-1.2830715 ],\n",
       "         [-1.4688319 ],\n",
       "         [-1.1998867 ]],\n",
       "\n",
       "        [[-1.3134549 ],\n",
       "         [-0.9369434 ],\n",
       "         [-1.0258344 ],\n",
       "         ...,\n",
       "         [-1.3849612 ],\n",
       "         [-1.3329574 ],\n",
       "         [-1.1184934 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.180639  ],\n",
       "         [-2.212583  ],\n",
       "         [-2.2106085 ],\n",
       "         ...,\n",
       "         [-2.2357388 ],\n",
       "         [-2.1068645 ],\n",
       "         [-1.9162654 ]],\n",
       "\n",
       "        [[-2.1981773 ],\n",
       "         [-2.2313282 ],\n",
       "         [-2.247045  ],\n",
       "         ...,\n",
       "         [-2.2574015 ],\n",
       "         [-2.1296458 ],\n",
       "         [-1.9423926 ]],\n",
       "\n",
       "        [[-2.201929  ],\n",
       "         [-2.2338858 ],\n",
       "         [-2.261929  ],\n",
       "         ...,\n",
       "         [-2.2650216 ],\n",
       "         [-2.1394997 ],\n",
       "         [-1.9575765 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.4599556 ],\n",
       "         [-1.5786982 ],\n",
       "         [-1.5604681 ],\n",
       "         ...,\n",
       "         [-1.7703989 ],\n",
       "         [-1.880683  ],\n",
       "         [-1.7435105 ]],\n",
       "\n",
       "        [[-1.3434787 ],\n",
       "         [-1.3975241 ],\n",
       "         [-1.3161662 ],\n",
       "         ...,\n",
       "         [-1.4199592 ],\n",
       "         [-1.7065612 ],\n",
       "         [-1.6715574 ]],\n",
       "\n",
       "        [[-1.3285307 ],\n",
       "         [-1.1725333 ],\n",
       "         [-1.158856  ],\n",
       "         ...,\n",
       "         [-1.2270906 ],\n",
       "         [-1.5792941 ],\n",
       "         [-1.7177827 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2333708 ],\n",
       "         [-2.2505934 ],\n",
       "         [-2.267995  ],\n",
       "         ...,\n",
       "         [-2.2671537 ],\n",
       "         [-2.257154  ],\n",
       "         [-2.2351146 ]],\n",
       "\n",
       "        [[-2.2336845 ],\n",
       "         [-2.2508435 ],\n",
       "         [-2.2680824 ],\n",
       "         ...,\n",
       "         [-2.2680845 ],\n",
       "         [-2.2573247 ],\n",
       "         [-2.2353923 ]],\n",
       "\n",
       "        [[-2.2339575 ],\n",
       "         [-2.2510262 ],\n",
       "         [-2.2681024 ],\n",
       "         ...,\n",
       "         [-2.2683628 ],\n",
       "         [-2.257372  ],\n",
       "         [-2.2355132 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.1070715 ],\n",
       "         [-0.9364885 ],\n",
       "         [-0.97704244],\n",
       "         ...,\n",
       "         [-1.3758392 ],\n",
       "         [-1.05648   ],\n",
       "         [-1.0360322 ]],\n",
       "\n",
       "        [[-1.3006127 ],\n",
       "         [-1.2530736 ],\n",
       "         [-1.1971251 ],\n",
       "         ...,\n",
       "         [-1.1352005 ],\n",
       "         [-1.0706322 ],\n",
       "         [-1.1874459 ]],\n",
       "\n",
       "        [[-1.2737312 ],\n",
       "         [-1.2378595 ],\n",
       "         [-1.4583884 ],\n",
       "         ...,\n",
       "         [-1.0140156 ],\n",
       "         [-0.9992598 ],\n",
       "         [-1.1284623 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.244612  ],\n",
       "         [-2.254179  ],\n",
       "         [-2.260275  ],\n",
       "         ...,\n",
       "         [-2.258535  ],\n",
       "         [-2.254568  ],\n",
       "         [-2.2461233 ]],\n",
       "\n",
       "        [[-2.24326   ],\n",
       "         [-2.253264  ],\n",
       "         [-2.2603436 ],\n",
       "         ...,\n",
       "         [-2.2628565 ],\n",
       "         [-2.2591288 ],\n",
       "         [-2.2520947 ]],\n",
       "\n",
       "        [[-2.2459795 ],\n",
       "         [-2.2550392 ],\n",
       "         [-2.2598166 ],\n",
       "         ...,\n",
       "         [-2.2594573 ],\n",
       "         [-2.2574458 ],\n",
       "         [-2.2518666 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.0492369 ],\n",
       "         [-1.0653479 ],\n",
       "         [-1.2825534 ],\n",
       "         ...,\n",
       "         [-0.9118812 ],\n",
       "         [-1.0841506 ],\n",
       "         [-1.2602237 ]],\n",
       "\n",
       "        [[-0.9806851 ],\n",
       "         [-0.93132067],\n",
       "         [-1.2830324 ],\n",
       "         ...,\n",
       "         [-1.0189018 ],\n",
       "         [-0.8531946 ],\n",
       "         [-1.0118402 ]],\n",
       "\n",
       "        [[-1.0806273 ],\n",
       "         [-0.94963086],\n",
       "         [-1.0416993 ],\n",
       "         ...,\n",
       "         [-1.2489903 ],\n",
       "         [-0.87192225],\n",
       "         [-0.99709463]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2111843 ],\n",
       "         [-2.2384458 ],\n",
       "         [-2.2577925 ],\n",
       "         ...,\n",
       "         [-2.2674072 ],\n",
       "         [-2.2469397 ],\n",
       "         [-2.2051115 ]],\n",
       "\n",
       "        [[-2.2105942 ],\n",
       "         [-2.2384086 ],\n",
       "         [-2.256669  ],\n",
       "         ...,\n",
       "         [-2.2682922 ],\n",
       "         [-2.2471266 ],\n",
       "         [-2.2055879 ]],\n",
       "\n",
       "        [[-2.20449   ],\n",
       "         [-2.2340279 ],\n",
       "         [-2.2481022 ],\n",
       "         ...,\n",
       "         [-2.2683506 ],\n",
       "         [-2.2473135 ],\n",
       "         [-2.2060256 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pre(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 256, 32, 1), dtype=float32, numpy=\n",
       "array([[[[-1.769532  ],\n",
       "         [-1.101128  ],\n",
       "         [-1.0745572 ],\n",
       "         ...,\n",
       "         [-1.4830765 ],\n",
       "         [-1.5086174 ],\n",
       "         [-1.3256644 ]],\n",
       "\n",
       "        [[-1.9381204 ],\n",
       "         [-1.1754922 ],\n",
       "         [-1.145031  ],\n",
       "         ...,\n",
       "         [-1.7465193 ],\n",
       "         [-1.6469648 ],\n",
       "         [-1.4167099 ]],\n",
       "\n",
       "        [[-1.7804332 ],\n",
       "         [-1.1693628 ],\n",
       "         [-1.1604897 ],\n",
       "         ...,\n",
       "         [-1.6153746 ],\n",
       "         [-1.4958944 ],\n",
       "         [-1.4770952 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2276578 ],\n",
       "         [-2.2438145 ],\n",
       "         [-2.2582738 ],\n",
       "         ...,\n",
       "         [-2.2608    ],\n",
       "         [-2.175364  ],\n",
       "         [-2.0337825 ]],\n",
       "\n",
       "        [[-2.2249455 ],\n",
       "         [-2.2460814 ],\n",
       "         [-2.2652597 ],\n",
       "         ...,\n",
       "         [-2.2672591 ],\n",
       "         [-2.1799297 ],\n",
       "         [-2.038486  ]],\n",
       "\n",
       "        [[-2.2196138 ],\n",
       "         [-2.2429776 ],\n",
       "         [-2.2679245 ],\n",
       "         ...,\n",
       "         [-2.2681332 ],\n",
       "         [-2.1808481 ],\n",
       "         [-2.0401351 ]]],\n",
       "\n",
       "\n",
       "       [[[-2.1248288 ],\n",
       "         [-2.0755181 ],\n",
       "         [-2.019419  ],\n",
       "         ...,\n",
       "         [-2.1851144 ],\n",
       "         [-2.196869  ],\n",
       "         [-2.2279773 ]],\n",
       "\n",
       "        [[-2.0936537 ],\n",
       "         [-2.024613  ],\n",
       "         [-1.9678302 ],\n",
       "         ...,\n",
       "         [-2.1726718 ],\n",
       "         [-2.1891127 ],\n",
       "         [-2.2313564 ]],\n",
       "\n",
       "        [[-2.0314922 ],\n",
       "         [-1.9669535 ],\n",
       "         [-1.9381047 ],\n",
       "         ...,\n",
       "         [-2.162996  ],\n",
       "         [-2.1663513 ],\n",
       "         [-2.237864  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2648625 ],\n",
       "         [-2.2651687 ],\n",
       "         [-2.2655206 ],\n",
       "         ...,\n",
       "         [-2.2663002 ],\n",
       "         [-2.2662044 ],\n",
       "         [-2.2630763 ]],\n",
       "\n",
       "        [[-2.266119  ],\n",
       "         [-2.2671232 ],\n",
       "         [-2.267762  ],\n",
       "         ...,\n",
       "         [-2.2677183 ],\n",
       "         [-2.2666426 ],\n",
       "         [-2.263388  ]],\n",
       "\n",
       "        [[-2.2667131 ],\n",
       "         [-2.2674925 ],\n",
       "         [-2.268104  ],\n",
       "         ...,\n",
       "         [-2.2680886 ],\n",
       "         [-2.26683   ],\n",
       "         [-2.2636538 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.3620937 ],\n",
       "         [-1.2109177 ],\n",
       "         [-0.63002884],\n",
       "         ...,\n",
       "         [-1.2074082 ],\n",
       "         [-1.5593979 ],\n",
       "         [-1.1854851 ]],\n",
       "\n",
       "        [[-1.4689947 ],\n",
       "         [-1.0244993 ],\n",
       "         [-0.6927283 ],\n",
       "         ...,\n",
       "         [-1.2830715 ],\n",
       "         [-1.4688319 ],\n",
       "         [-1.1998867 ]],\n",
       "\n",
       "        [[-1.3134549 ],\n",
       "         [-0.9369434 ],\n",
       "         [-1.0258344 ],\n",
       "         ...,\n",
       "         [-1.3849612 ],\n",
       "         [-1.3329574 ],\n",
       "         [-1.1184934 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.180639  ],\n",
       "         [-2.212583  ],\n",
       "         [-2.2106085 ],\n",
       "         ...,\n",
       "         [-2.2357388 ],\n",
       "         [-2.1068645 ],\n",
       "         [-1.9162654 ]],\n",
       "\n",
       "        [[-2.1981773 ],\n",
       "         [-2.2313282 ],\n",
       "         [-2.247045  ],\n",
       "         ...,\n",
       "         [-2.2574015 ],\n",
       "         [-2.1296458 ],\n",
       "         [-1.9423926 ]],\n",
       "\n",
       "        [[-2.201929  ],\n",
       "         [-2.2338858 ],\n",
       "         [-2.261929  ],\n",
       "         ...,\n",
       "         [-2.2650216 ],\n",
       "         [-2.1394997 ],\n",
       "         [-1.9575765 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.4599556 ],\n",
       "         [-1.5786982 ],\n",
       "         [-1.5604681 ],\n",
       "         ...,\n",
       "         [-1.7703989 ],\n",
       "         [-1.880683  ],\n",
       "         [-1.7435105 ]],\n",
       "\n",
       "        [[-1.3434787 ],\n",
       "         [-1.3975241 ],\n",
       "         [-1.3161662 ],\n",
       "         ...,\n",
       "         [-1.4199592 ],\n",
       "         [-1.7065612 ],\n",
       "         [-1.6715574 ]],\n",
       "\n",
       "        [[-1.3285307 ],\n",
       "         [-1.1725333 ],\n",
       "         [-1.158856  ],\n",
       "         ...,\n",
       "         [-1.2270906 ],\n",
       "         [-1.5792941 ],\n",
       "         [-1.7177827 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2333708 ],\n",
       "         [-2.2505934 ],\n",
       "         [-2.267995  ],\n",
       "         ...,\n",
       "         [-2.2671537 ],\n",
       "         [-2.257154  ],\n",
       "         [-2.2351146 ]],\n",
       "\n",
       "        [[-2.2336845 ],\n",
       "         [-2.2508435 ],\n",
       "         [-2.2680824 ],\n",
       "         ...,\n",
       "         [-2.2680845 ],\n",
       "         [-2.2573247 ],\n",
       "         [-2.2353923 ]],\n",
       "\n",
       "        [[-2.2339575 ],\n",
       "         [-2.2510262 ],\n",
       "         [-2.2681024 ],\n",
       "         ...,\n",
       "         [-2.2683628 ],\n",
       "         [-2.257372  ],\n",
       "         [-2.2355132 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.1070715 ],\n",
       "         [-0.9364885 ],\n",
       "         [-0.97704244],\n",
       "         ...,\n",
       "         [-1.3758392 ],\n",
       "         [-1.05648   ],\n",
       "         [-1.0360322 ]],\n",
       "\n",
       "        [[-1.3006127 ],\n",
       "         [-1.2530736 ],\n",
       "         [-1.1971251 ],\n",
       "         ...,\n",
       "         [-1.1352005 ],\n",
       "         [-1.0706322 ],\n",
       "         [-1.1874459 ]],\n",
       "\n",
       "        [[-1.2737312 ],\n",
       "         [-1.2378595 ],\n",
       "         [-1.4583884 ],\n",
       "         ...,\n",
       "         [-1.0140156 ],\n",
       "         [-0.9992598 ],\n",
       "         [-1.1284623 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.244612  ],\n",
       "         [-2.254179  ],\n",
       "         [-2.260275  ],\n",
       "         ...,\n",
       "         [-2.258535  ],\n",
       "         [-2.254568  ],\n",
       "         [-2.2461233 ]],\n",
       "\n",
       "        [[-2.24326   ],\n",
       "         [-2.253264  ],\n",
       "         [-2.2603436 ],\n",
       "         ...,\n",
       "         [-2.2628565 ],\n",
       "         [-2.2591288 ],\n",
       "         [-2.2520947 ]],\n",
       "\n",
       "        [[-2.2459795 ],\n",
       "         [-2.2550392 ],\n",
       "         [-2.2598166 ],\n",
       "         ...,\n",
       "         [-2.2594573 ],\n",
       "         [-2.2574458 ],\n",
       "         [-2.2518666 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.0492369 ],\n",
       "         [-1.0653479 ],\n",
       "         [-1.2825534 ],\n",
       "         ...,\n",
       "         [-0.9118812 ],\n",
       "         [-1.0841506 ],\n",
       "         [-1.2602237 ]],\n",
       "\n",
       "        [[-0.9806851 ],\n",
       "         [-0.93132067],\n",
       "         [-1.2830324 ],\n",
       "         ...,\n",
       "         [-1.0189018 ],\n",
       "         [-0.8531946 ],\n",
       "         [-1.0118402 ]],\n",
       "\n",
       "        [[-1.0806273 ],\n",
       "         [-0.94963086],\n",
       "         [-1.0416993 ],\n",
       "         ...,\n",
       "         [-1.2489903 ],\n",
       "         [-0.87192225],\n",
       "         [-0.99709463]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2111843 ],\n",
       "         [-2.2384458 ],\n",
       "         [-2.2577925 ],\n",
       "         ...,\n",
       "         [-2.2674072 ],\n",
       "         [-2.2469397 ],\n",
       "         [-2.2051115 ]],\n",
       "\n",
       "        [[-2.2105942 ],\n",
       "         [-2.2384086 ],\n",
       "         [-2.256669  ],\n",
       "         ...,\n",
       "         [-2.2682922 ],\n",
       "         [-2.2471266 ],\n",
       "         [-2.2055879 ]],\n",
       "\n",
       "        [[-2.20449   ],\n",
       "         [-2.2340279 ],\n",
       "         [-2.2481022 ],\n",
       "         ...,\n",
       "         [-2.2683506 ],\n",
       "         [-2.2473135 ],\n",
       "         [-2.2060256 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_specaug(m_pre(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = m_specaug(m_pre(X))  # (nA+nP, F, T, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 256, 32, 1), dtype=float32, numpy=\n",
       "array([[[[-1.769532  ],\n",
       "         [-1.101128  ],\n",
       "         [-1.0745572 ],\n",
       "         ...,\n",
       "         [-1.4830765 ],\n",
       "         [-1.5086174 ],\n",
       "         [-1.3256644 ]],\n",
       "\n",
       "        [[-1.9381204 ],\n",
       "         [-1.1754922 ],\n",
       "         [-1.145031  ],\n",
       "         ...,\n",
       "         [-1.7465193 ],\n",
       "         [-1.6469648 ],\n",
       "         [-1.4167099 ]],\n",
       "\n",
       "        [[-1.7804332 ],\n",
       "         [-1.1693628 ],\n",
       "         [-1.1604897 ],\n",
       "         ...,\n",
       "         [-1.6153746 ],\n",
       "         [-1.4958944 ],\n",
       "         [-1.4770952 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2276578 ],\n",
       "         [-2.2438145 ],\n",
       "         [-2.2582738 ],\n",
       "         ...,\n",
       "         [-2.2608    ],\n",
       "         [-2.175364  ],\n",
       "         [-2.0337825 ]],\n",
       "\n",
       "        [[-2.2249455 ],\n",
       "         [-2.2460814 ],\n",
       "         [-2.2652597 ],\n",
       "         ...,\n",
       "         [-2.2672591 ],\n",
       "         [-2.1799297 ],\n",
       "         [-2.038486  ]],\n",
       "\n",
       "        [[-2.2196138 ],\n",
       "         [-2.2429776 ],\n",
       "         [-2.2679245 ],\n",
       "         ...,\n",
       "         [-2.2681332 ],\n",
       "         [-2.1808481 ],\n",
       "         [-2.0401351 ]]],\n",
       "\n",
       "\n",
       "       [[[-2.1248288 ],\n",
       "         [-2.0755181 ],\n",
       "         [-2.019419  ],\n",
       "         ...,\n",
       "         [-2.1851144 ],\n",
       "         [-2.196869  ],\n",
       "         [-2.2279773 ]],\n",
       "\n",
       "        [[-2.0936537 ],\n",
       "         [-2.024613  ],\n",
       "         [-1.9678302 ],\n",
       "         ...,\n",
       "         [-2.1726718 ],\n",
       "         [-2.1891127 ],\n",
       "         [-2.2313564 ]],\n",
       "\n",
       "        [[-2.0314922 ],\n",
       "         [-1.9669535 ],\n",
       "         [-1.9381047 ],\n",
       "         ...,\n",
       "         [-2.162996  ],\n",
       "         [-2.1663513 ],\n",
       "         [-2.237864  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2648625 ],\n",
       "         [-2.2651687 ],\n",
       "         [-2.2655206 ],\n",
       "         ...,\n",
       "         [-2.2663002 ],\n",
       "         [-2.2662044 ],\n",
       "         [-2.2630763 ]],\n",
       "\n",
       "        [[-2.266119  ],\n",
       "         [-2.2671232 ],\n",
       "         [-2.267762  ],\n",
       "         ...,\n",
       "         [-2.2677183 ],\n",
       "         [-2.2666426 ],\n",
       "         [-2.263388  ]],\n",
       "\n",
       "        [[-2.2667131 ],\n",
       "         [-2.2674925 ],\n",
       "         [-2.268104  ],\n",
       "         ...,\n",
       "         [-2.2680886 ],\n",
       "         [-2.26683   ],\n",
       "         [-2.2636538 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.3620937 ],\n",
       "         [-1.2109177 ],\n",
       "         [-0.63002884],\n",
       "         ...,\n",
       "         [-1.2074082 ],\n",
       "         [-1.5593979 ],\n",
       "         [-1.1854851 ]],\n",
       "\n",
       "        [[-1.4689947 ],\n",
       "         [-1.0244993 ],\n",
       "         [-0.6927283 ],\n",
       "         ...,\n",
       "         [-1.2830715 ],\n",
       "         [-1.4688319 ],\n",
       "         [-1.1998867 ]],\n",
       "\n",
       "        [[-1.3134549 ],\n",
       "         [-0.9369434 ],\n",
       "         [-1.0258344 ],\n",
       "         ...,\n",
       "         [-1.3849612 ],\n",
       "         [-1.3329574 ],\n",
       "         [-1.1184934 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.180639  ],\n",
       "         [-2.212583  ],\n",
       "         [-2.2106085 ],\n",
       "         ...,\n",
       "         [-2.2357388 ],\n",
       "         [-2.1068645 ],\n",
       "         [-1.9162654 ]],\n",
       "\n",
       "        [[-2.1981773 ],\n",
       "         [-2.2313282 ],\n",
       "         [-2.247045  ],\n",
       "         ...,\n",
       "         [-2.2574015 ],\n",
       "         [-2.1296458 ],\n",
       "         [-1.9423926 ]],\n",
       "\n",
       "        [[-2.201929  ],\n",
       "         [-2.2338858 ],\n",
       "         [-2.261929  ],\n",
       "         ...,\n",
       "         [-2.2650216 ],\n",
       "         [-2.1394997 ],\n",
       "         [-1.9575765 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.4599556 ],\n",
       "         [-1.5786982 ],\n",
       "         [-1.5604681 ],\n",
       "         ...,\n",
       "         [-1.7703989 ],\n",
       "         [-1.880683  ],\n",
       "         [-1.7435105 ]],\n",
       "\n",
       "        [[-1.3434787 ],\n",
       "         [-1.3975241 ],\n",
       "         [-1.3161662 ],\n",
       "         ...,\n",
       "         [-1.4199592 ],\n",
       "         [-1.7065612 ],\n",
       "         [-1.6715574 ]],\n",
       "\n",
       "        [[-1.3285307 ],\n",
       "         [-1.1725333 ],\n",
       "         [-1.158856  ],\n",
       "         ...,\n",
       "         [-1.2270906 ],\n",
       "         [-1.5792941 ],\n",
       "         [-1.7177827 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2333708 ],\n",
       "         [-2.2505934 ],\n",
       "         [-2.267995  ],\n",
       "         ...,\n",
       "         [-2.2671537 ],\n",
       "         [-2.257154  ],\n",
       "         [-2.2351146 ]],\n",
       "\n",
       "        [[-2.2336845 ],\n",
       "         [-2.2508435 ],\n",
       "         [-2.2680824 ],\n",
       "         ...,\n",
       "         [-2.2680845 ],\n",
       "         [-2.2573247 ],\n",
       "         [-2.2353923 ]],\n",
       "\n",
       "        [[-2.2339575 ],\n",
       "         [-2.2510262 ],\n",
       "         [-2.2681024 ],\n",
       "         ...,\n",
       "         [-2.2683628 ],\n",
       "         [-2.257372  ],\n",
       "         [-2.2355132 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.1070715 ],\n",
       "         [-0.9364885 ],\n",
       "         [-0.97704244],\n",
       "         ...,\n",
       "         [-1.3758392 ],\n",
       "         [-1.05648   ],\n",
       "         [-1.0360322 ]],\n",
       "\n",
       "        [[-1.3006127 ],\n",
       "         [-1.2530736 ],\n",
       "         [-1.1971251 ],\n",
       "         ...,\n",
       "         [-1.1352005 ],\n",
       "         [-1.0706322 ],\n",
       "         [-1.1874459 ]],\n",
       "\n",
       "        [[-1.2737312 ],\n",
       "         [-1.2378595 ],\n",
       "         [-1.4583884 ],\n",
       "         ...,\n",
       "         [-1.0140156 ],\n",
       "         [-0.9992598 ],\n",
       "         [-1.1284623 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.244612  ],\n",
       "         [-2.254179  ],\n",
       "         [-2.260275  ],\n",
       "         ...,\n",
       "         [-2.258535  ],\n",
       "         [-2.254568  ],\n",
       "         [-2.2461233 ]],\n",
       "\n",
       "        [[-2.24326   ],\n",
       "         [-2.253264  ],\n",
       "         [-2.2603436 ],\n",
       "         ...,\n",
       "         [-2.2628565 ],\n",
       "         [-2.2591288 ],\n",
       "         [-2.2520947 ]],\n",
       "\n",
       "        [[-2.2459795 ],\n",
       "         [-2.2550392 ],\n",
       "         [-2.2598166 ],\n",
       "         ...,\n",
       "         [-2.2594573 ],\n",
       "         [-2.2574458 ],\n",
       "         [-2.2518666 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.0492369 ],\n",
       "         [-1.0653479 ],\n",
       "         [-1.2825534 ],\n",
       "         ...,\n",
       "         [-0.9118812 ],\n",
       "         [-1.0841506 ],\n",
       "         [-1.2602237 ]],\n",
       "\n",
       "        [[-0.9806851 ],\n",
       "         [-0.93132067],\n",
       "         [-1.2830324 ],\n",
       "         ...,\n",
       "         [-1.0189018 ],\n",
       "         [-0.8531946 ],\n",
       "         [-1.0118402 ]],\n",
       "\n",
       "        [[-1.0806273 ],\n",
       "         [-0.94963086],\n",
       "         [-1.0416993 ],\n",
       "         ...,\n",
       "         [-1.2489903 ],\n",
       "         [-0.87192225],\n",
       "         [-0.99709463]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2111843 ],\n",
       "         [-2.2384458 ],\n",
       "         [-2.2577925 ],\n",
       "         ...,\n",
       "         [-2.2674072 ],\n",
       "         [-2.2469397 ],\n",
       "         [-2.2051115 ]],\n",
       "\n",
       "        [[-2.2105942 ],\n",
       "         [-2.2384086 ],\n",
       "         [-2.256669  ],\n",
       "         ...,\n",
       "         [-2.2682922 ],\n",
       "         [-2.2471266 ],\n",
       "         [-2.2055879 ]],\n",
       "\n",
       "        [[-2.20449   ],\n",
       "         [-2.2340279 ],\n",
       "         [-2.2481022 ],\n",
       "         ...,\n",
       "         [-2.2683506 ],\n",
       "         [-2.2473135 ],\n",
       "         [-2.2060256 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_fp.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as t:\n",
    "    emb = m_fp(feat)  # (BSZ, Dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 256, 32, 1), dtype=float32, numpy=\n",
       "array([[[[-1.769532  ],\n",
       "         [-1.101128  ],\n",
       "         [-1.0745572 ],\n",
       "         ...,\n",
       "         [-1.4830765 ],\n",
       "         [-1.5086174 ],\n",
       "         [-1.3256644 ]],\n",
       "\n",
       "        [[-1.9381204 ],\n",
       "         [-1.1754922 ],\n",
       "         [-1.145031  ],\n",
       "         ...,\n",
       "         [-1.7465193 ],\n",
       "         [-1.6469648 ],\n",
       "         [-1.4167099 ]],\n",
       "\n",
       "        [[-1.7804332 ],\n",
       "         [-1.1693628 ],\n",
       "         [-1.1604897 ],\n",
       "         ...,\n",
       "         [-1.6153746 ],\n",
       "         [-1.4958944 ],\n",
       "         [-1.4770952 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2276578 ],\n",
       "         [-2.2438145 ],\n",
       "         [-2.2582738 ],\n",
       "         ...,\n",
       "         [-2.2608    ],\n",
       "         [-2.175364  ],\n",
       "         [-2.0337825 ]],\n",
       "\n",
       "        [[-2.2249455 ],\n",
       "         [-2.2460814 ],\n",
       "         [-2.2652597 ],\n",
       "         ...,\n",
       "         [-2.2672591 ],\n",
       "         [-2.1799297 ],\n",
       "         [-2.038486  ]],\n",
       "\n",
       "        [[-2.2196138 ],\n",
       "         [-2.2429776 ],\n",
       "         [-2.2679245 ],\n",
       "         ...,\n",
       "         [-2.2681332 ],\n",
       "         [-2.1808481 ],\n",
       "         [-2.0401351 ]]],\n",
       "\n",
       "\n",
       "       [[[-2.1248288 ],\n",
       "         [-2.0755181 ],\n",
       "         [-2.019419  ],\n",
       "         ...,\n",
       "         [-2.1851144 ],\n",
       "         [-2.196869  ],\n",
       "         [-2.2279773 ]],\n",
       "\n",
       "        [[-2.0936537 ],\n",
       "         [-2.024613  ],\n",
       "         [-1.9678302 ],\n",
       "         ...,\n",
       "         [-2.1726718 ],\n",
       "         [-2.1891127 ],\n",
       "         [-2.2313564 ]],\n",
       "\n",
       "        [[-2.0314922 ],\n",
       "         [-1.9669535 ],\n",
       "         [-1.9381047 ],\n",
       "         ...,\n",
       "         [-2.162996  ],\n",
       "         [-2.1663513 ],\n",
       "         [-2.237864  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2648625 ],\n",
       "         [-2.2651687 ],\n",
       "         [-2.2655206 ],\n",
       "         ...,\n",
       "         [-2.2663002 ],\n",
       "         [-2.2662044 ],\n",
       "         [-2.2630763 ]],\n",
       "\n",
       "        [[-2.266119  ],\n",
       "         [-2.2671232 ],\n",
       "         [-2.267762  ],\n",
       "         ...,\n",
       "         [-2.2677183 ],\n",
       "         [-2.2666426 ],\n",
       "         [-2.263388  ]],\n",
       "\n",
       "        [[-2.2667131 ],\n",
       "         [-2.2674925 ],\n",
       "         [-2.268104  ],\n",
       "         ...,\n",
       "         [-2.2680886 ],\n",
       "         [-2.26683   ],\n",
       "         [-2.2636538 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.3620937 ],\n",
       "         [-1.2109177 ],\n",
       "         [-0.63002884],\n",
       "         ...,\n",
       "         [-1.2074082 ],\n",
       "         [-1.5593979 ],\n",
       "         [-1.1854851 ]],\n",
       "\n",
       "        [[-1.4689947 ],\n",
       "         [-1.0244993 ],\n",
       "         [-0.6927283 ],\n",
       "         ...,\n",
       "         [-1.2830715 ],\n",
       "         [-1.4688319 ],\n",
       "         [-1.1998867 ]],\n",
       "\n",
       "        [[-1.3134549 ],\n",
       "         [-0.9369434 ],\n",
       "         [-1.0258344 ],\n",
       "         ...,\n",
       "         [-1.3849612 ],\n",
       "         [-1.3329574 ],\n",
       "         [-1.1184934 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.180639  ],\n",
       "         [-2.212583  ],\n",
       "         [-2.2106085 ],\n",
       "         ...,\n",
       "         [-2.2357388 ],\n",
       "         [-2.1068645 ],\n",
       "         [-1.9162654 ]],\n",
       "\n",
       "        [[-2.1981773 ],\n",
       "         [-2.2313282 ],\n",
       "         [-2.247045  ],\n",
       "         ...,\n",
       "         [-2.2574015 ],\n",
       "         [-2.1296458 ],\n",
       "         [-1.9423926 ]],\n",
       "\n",
       "        [[-2.201929  ],\n",
       "         [-2.2338858 ],\n",
       "         [-2.261929  ],\n",
       "         ...,\n",
       "         [-2.2650216 ],\n",
       "         [-2.1394997 ],\n",
       "         [-1.9575765 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.4599556 ],\n",
       "         [-1.5786982 ],\n",
       "         [-1.5604681 ],\n",
       "         ...,\n",
       "         [-1.7703989 ],\n",
       "         [-1.880683  ],\n",
       "         [-1.7435105 ]],\n",
       "\n",
       "        [[-1.3434787 ],\n",
       "         [-1.3975241 ],\n",
       "         [-1.3161662 ],\n",
       "         ...,\n",
       "         [-1.4199592 ],\n",
       "         [-1.7065612 ],\n",
       "         [-1.6715574 ]],\n",
       "\n",
       "        [[-1.3285307 ],\n",
       "         [-1.1725333 ],\n",
       "         [-1.158856  ],\n",
       "         ...,\n",
       "         [-1.2270906 ],\n",
       "         [-1.5792941 ],\n",
       "         [-1.7177827 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2333708 ],\n",
       "         [-2.2505934 ],\n",
       "         [-2.267995  ],\n",
       "         ...,\n",
       "         [-2.2671537 ],\n",
       "         [-2.257154  ],\n",
       "         [-2.2351146 ]],\n",
       "\n",
       "        [[-2.2336845 ],\n",
       "         [-2.2508435 ],\n",
       "         [-2.2680824 ],\n",
       "         ...,\n",
       "         [-2.2680845 ],\n",
       "         [-2.2573247 ],\n",
       "         [-2.2353923 ]],\n",
       "\n",
       "        [[-2.2339575 ],\n",
       "         [-2.2510262 ],\n",
       "         [-2.2681024 ],\n",
       "         ...,\n",
       "         [-2.2683628 ],\n",
       "         [-2.257372  ],\n",
       "         [-2.2355132 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.1070715 ],\n",
       "         [-0.9364885 ],\n",
       "         [-0.97704244],\n",
       "         ...,\n",
       "         [-1.3758392 ],\n",
       "         [-1.05648   ],\n",
       "         [-1.0360322 ]],\n",
       "\n",
       "        [[-1.3006127 ],\n",
       "         [-1.2530736 ],\n",
       "         [-1.1971251 ],\n",
       "         ...,\n",
       "         [-1.1352005 ],\n",
       "         [-1.0706322 ],\n",
       "         [-1.1874459 ]],\n",
       "\n",
       "        [[-1.2737312 ],\n",
       "         [-1.2378595 ],\n",
       "         [-1.4583884 ],\n",
       "         ...,\n",
       "         [-1.0140156 ],\n",
       "         [-0.9992598 ],\n",
       "         [-1.1284623 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.244612  ],\n",
       "         [-2.254179  ],\n",
       "         [-2.260275  ],\n",
       "         ...,\n",
       "         [-2.258535  ],\n",
       "         [-2.254568  ],\n",
       "         [-2.2461233 ]],\n",
       "\n",
       "        [[-2.24326   ],\n",
       "         [-2.253264  ],\n",
       "         [-2.2603436 ],\n",
       "         ...,\n",
       "         [-2.2628565 ],\n",
       "         [-2.2591288 ],\n",
       "         [-2.2520947 ]],\n",
       "\n",
       "        [[-2.2459795 ],\n",
       "         [-2.2550392 ],\n",
       "         [-2.2598166 ],\n",
       "         ...,\n",
       "         [-2.2594573 ],\n",
       "         [-2.2574458 ],\n",
       "         [-2.2518666 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.0492369 ],\n",
       "         [-1.0653479 ],\n",
       "         [-1.2825534 ],\n",
       "         ...,\n",
       "         [-0.9118812 ],\n",
       "         [-1.0841506 ],\n",
       "         [-1.2602237 ]],\n",
       "\n",
       "        [[-0.9806851 ],\n",
       "         [-0.93132067],\n",
       "         [-1.2830324 ],\n",
       "         ...,\n",
       "         [-1.0189018 ],\n",
       "         [-0.8531946 ],\n",
       "         [-1.0118402 ]],\n",
       "\n",
       "        [[-1.0806273 ],\n",
       "         [-0.94963086],\n",
       "         [-1.0416993 ],\n",
       "         ...,\n",
       "         [-1.2489903 ],\n",
       "         [-0.87192225],\n",
       "         [-0.99709463]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2111843 ],\n",
       "         [-2.2384458 ],\n",
       "         [-2.2577925 ],\n",
       "         ...,\n",
       "         [-2.2674072 ],\n",
       "         [-2.2469397 ],\n",
       "         [-2.2051115 ]],\n",
       "\n",
       "        [[-2.2105942 ],\n",
       "         [-2.2384086 ],\n",
       "         [-2.256669  ],\n",
       "         ...,\n",
       "         [-2.2682922 ],\n",
       "         [-2.2471266 ],\n",
       "         [-2.2055879 ]],\n",
       "\n",
       "        [[-2.20449   ],\n",
       "         [-2.2340279 ],\n",
       "         [-2.2481022 ],\n",
       "         ...,\n",
       "         [-2.2683506 ],\n",
       "         [-2.2473135 ],\n",
       "         [-2.2060256 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ERRO:***\n",
    "<br> (nA+nP, F, T, 1) quando faz a fingerprint/embedding ```m_fp()``` do ```feat``` que é o spec aug.\n",
    "<br>\n",
    "<br> m_fp = get_fingerprinter(cfg, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 128), dtype=float32, numpy=\n",
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_fp(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as t:\n",
    "    emb = m_fp(feat)  # (BSZ, Dim)\n",
    "    loss, sim_mtx, _ = loss_obj.compute_loss(\n",
    "        emb[:n_anchors, :], emb[n_anchors:, :]) # {emb_org, emb_rep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = t.gradient(loss, m_fp.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.optimizer.apply_gradients(zip(g, m_fp.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss = helper.update_tr_loss(loss) # To tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Build fingerprinter \"\"\"\n",
    "# m_pre: log-power-Mel-spectrogram layer, S.\n",
    "m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "# m_specaug: spec-augmentation layer.\n",
    "m_specaug = get_specaug_chain_layer(cfg, trainable=False)\n",
    "#assert(m_specaug.bypass==False) # Detachable by setting m_specaug.bypass.\n",
    "\n",
    "# m_fp: fingerprinter g(f(.)).\n",
    "m_fp = get_fingerprinter(cfg, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<model.fp.nnfp.FingerPrinter at 0x7f5ca0092b20>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fingerprinter(cfg, trainable=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
