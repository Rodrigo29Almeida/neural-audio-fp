{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 16:18:44.148799: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from model.dataset import Dataset\n",
    "#from model.fp.melspec.melspectrogram import get_melspec_layer\n",
    "from model.fp.specaug_chain.specaug_chain import get_specaug_chain_layer\n",
    "from model.fp.nnfp import get_fingerprinter\n",
    "from model.fp.NTxent_loss_single_gpu import NTxentLoss\n",
    "from model.fp.online_triplet_loss import OnlineTripletLoss\n",
    "from model.fp.lamb_optimizer import LAMB\n",
    "from model.utils.experiment_helper import ExperimentHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Lambda, Permute\n",
    "from kapre.time_frequency import Magnitude #STFT, #, ApplyFilterbank\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from kapre import backend\n",
    "from kapre.backend import _CH_FIRST_STR, _CH_LAST_STR, _CH_DEFAULT_STR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import tensor_util\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops.signal import window_ops\n",
    "from tensorflow.python.ops.signal import shape_ops\n",
    "from tensorflow.python.ops.signal import fft_ops\n",
    "from tensorflow.python.util import dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _enclosing_power_of_two(value):\n",
    "  \"\"\"Return 2**N for integer N such that 2**N >= value.\"\"\"\n",
    "  value_static = tensor_util.constant_value(value)\n",
    "  if value_static is not None:\n",
    "    return constant_op.constant(\n",
    "        int(2**np.ceil(np.log(value_static) / np.log(2.0))), value.dtype)\n",
    "  return math_ops.cast(\n",
    "      math_ops.pow(\n",
    "          2.0,\n",
    "          math_ops.ceil(\n",
    "              math_ops.log(math_ops.cast(value, dtypes.float32)) /\n",
    "              math_ops.log(2.0))), value.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch.add_dispatch_support\n",
    "def stft(signals, frame_length, frame_step, fft_length=None,\n",
    "         window_fn=window_ops.hann_window,\n",
    "         pad_end=False, name=None):\n",
    "  with ops.name_scope(name, 'stft', [signals, frame_length,\n",
    "                                     frame_step]):\n",
    "    #tf.print(f\"window_fn{window_fn}\")\n",
    "    signals = ops.convert_to_tensor(signals, name='signals')\n",
    "    signals.shape.with_rank_at_least(1)\n",
    "    frame_length = ops.convert_to_tensor(frame_length, name='frame_length')\n",
    "    frame_length.shape.assert_has_rank(0)\n",
    "    frame_step = ops.convert_to_tensor(frame_step, name='frame_step')\n",
    "    frame_step.shape.assert_has_rank(0)\n",
    "\n",
    "    if fft_length is None:\n",
    "      fft_length = _enclosing_power_of_two(frame_length)\n",
    "    else:\n",
    "      fft_length = ops.convert_to_tensor(fft_length, name='fft_length')\n",
    "\n",
    "    framed_signals = shape_ops.frame(\n",
    "        signals, frame_length, frame_step, pad_end=pad_end)\n",
    "    \n",
    "    #tf.print(f\"framed_signals{framed_signals}\")\n",
    "\n",
    "    # Optionally window the framed signals.\n",
    "    if window_fn is not None:\n",
    "      window = window_fn(frame_length, dtype=framed_signals.dtype)\n",
    "      framed_signals *= window\n",
    "      #tf.print(f\"window{window}\")\n",
    "      #tf.print(f\"framed_signals{framed_signals}\")\n",
    "\n",
    "    #tf.print(f\"rfft{fft_ops.rfft(framed_signals, [fft_length])}\")\n",
    "    # fft_ops.rfft produces the (fft_length/2 + 1) unique components of the\n",
    "    # FFT of the real windowed signals in framed_signals.\n",
    "    return fft_ops.rfft(framed_signals, [fft_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STFT(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft=2048,\n",
    "        win_length=None,\n",
    "        hop_length=None,\n",
    "        window_name=None,\n",
    "        pad_begin=False,\n",
    "        pad_end=False,\n",
    "        input_data_format='default',\n",
    "        output_data_format='default',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(STFT, self).__init__(**kwargs)\n",
    "\n",
    "        backend.validate_data_format_str(input_data_format)\n",
    "        backend.validate_data_format_str(output_data_format)\n",
    "\n",
    "        if win_length is None:\n",
    "            win_length = n_fft\n",
    "        if hop_length is None:\n",
    "            hop_length = win_length // 4\n",
    "\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.window_name = window_name\n",
    "        self.window_fn = backend.get_window_fn(window_name)\n",
    "        self.pad_begin = pad_begin\n",
    "        self.pad_end = pad_end\n",
    "\n",
    "        idt, odt = input_data_format, output_data_format\n",
    "        self.output_data_format = K.image_data_format() if odt == _CH_DEFAULT_STR else odt\n",
    "        self.input_data_format = K.image_data_format() if idt == _CH_DEFAULT_STR else idt\n",
    "\n",
    "    def call(self, x):\n",
    "        #tf.print(f\"x{x.shape, type(x), x}\")\n",
    "        waveforms = x  # (batch, ch, time) if input_data_format == 'channels_first'.\n",
    "        # (batch, time, ch) if input_data_format == 'channels_last'.\n",
    "\n",
    "        # this is needed because tf.signal.stft lives in channels_first land.\n",
    "        if self.input_data_format == _CH_LAST_STR:\n",
    "            waveforms = tf.transpose(\n",
    "                waveforms, perm=(0, 2, 1)\n",
    "            )  # always (batch, ch, time) from here\n",
    "\n",
    "        if self.pad_begin:\n",
    "            waveforms = tf.pad(\n",
    "                waveforms, tf.constant([[0, 0], [0, 0], [int(self.n_fft - self.hop_length), 0]])\n",
    "            )\n",
    "        #tf.print(f\"self.pad_begin={self.pad_begin}, self.input_data_format={self.input_data_format}\")\n",
    "        #tf.print(f\"waveforms{waveforms.shape, type(waveforms), waveforms}\")\n",
    "        \n",
    "        #tf.print(f\"self.window_fn{self.window_fn}\")\n",
    "        stfts = stft(\n",
    "            signals=waveforms,\n",
    "            frame_length=self.win_length,\n",
    "            frame_step=self.hop_length,\n",
    "            fft_length=self.n_fft,\n",
    "            window_fn=self.window_fn,\n",
    "            pad_end=self.pad_end,\n",
    "            name='%s_tf.signal.stft' % self.name,\n",
    "        )  # (batch, ch, time, freq)\n",
    "        \n",
    "        #tf.print(f\"stfts{stfts}\")\n",
    "\n",
    "        if self.output_data_format == _CH_LAST_STR:\n",
    "            stfts = tf.transpose(stfts, perm=(0, 2, 3, 1))  # (batch, t, f, ch)\n",
    "\n",
    "        #tf.print(f\"self.output_data_format={self.output_data_format}\")\n",
    "        #tf.print(f\"stfts{stfts.shape, type(stfts), stfts}\")\n",
    "        return stfts\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(STFT, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                'n_fft': self.n_fft,\n",
    "                'win_length': self.win_length,\n",
    "                'hop_length': self.hop_length,\n",
    "                'window_name': self.window_name,\n",
    "                'pad_begin': self.pad_begin,\n",
    "                'pad_end': self.pad_end,\n",
    "                'input_data_format': self.input_data_format,\n",
    "                'output_data_format': self.output_data_format,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import librosa\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kapre.time_frequency import ApplyFilterbank\n",
    "\n",
    "class CustomApplyFilterbank(ApplyFilterbank):\n",
    "    def __init__(self, type, filterbank_kwargs, data_format='default', **kwargs):\n",
    "        super(CustomApplyFilterbank, self).__init__(type, filterbank_kwargs, data_format, **kwargs)\n",
    "\n",
    "        # tipo de Banco de filtros\n",
    "        if type == 'tri':\n",
    "            self.filterbank = self.filterbank_triangular_log(**filterbank_kwargs)\n",
    "\n",
    "        if data_format == _CH_DEFAULT_STR:\n",
    "            self.data_format = K.image_data_format()\n",
    "        else:\n",
    "            self.data_format = data_format\n",
    "\n",
    "        if self.data_format == _CH_FIRST_STR:\n",
    "            self.freq_axis = 3\n",
    "        else:\n",
    "            self.freq_axis = 2\n",
    "\n",
    "    def filterbank_triangular_log(self, sample_rate, n_fft):\n",
    "        # Com o objetivo de ter 256 filtros e 8000 Hz na frequência de amostragem, teve-se de optar por Nfft de 2048, o que resulta em 54.4024 filtros por oitava, e numa frequência mínima de 151.3483 Hz.\n",
    "\n",
    "        # Sendo assim, o Nfpo será 60, 5*12, e a frequência do último filtro, f256, será Si7 = 3951.066410048992 Hz. Resultando numa frequência máxima de 3996.975590329487 Hz.\n",
    "        # Com isto, obtem-se pelo menos um bin em cada filtro, visto que f0*(2^(2/Nfpo)-1) = 4.7979 > 8000/2048 = 3.9062. Para uma Nfft de 1024, não era certo que obtivesse pelo menos um bin por filtro.\n",
    "        #O primeiro filtro estava a zero.\n",
    "\n",
    "        n_fft=2048\n",
    "        sample_rate=8000\n",
    "        Nfpo=60 #=5*12\n",
    "        Nb =256\n",
    "\n",
    "        #Cálculo da fmin e fmax\n",
    "        f256 = 440*2.**(38/12) # Si7 = 3951.066410048992 Hz;\n",
    "        f0=f256/2**(256/Nfpo) # fmin, 205.2672581380976 Hz\n",
    "        fmax = f0*2**(257/Nfpo) # fmax, 3996.975590329487 Hz\n",
    "\n",
    "        #Depois disto, dá bins em todos os fitros. Ver a linha 24 do getOctaveFilterBanck2.m\n",
    "\n",
    "        i=np.arange(1,Nb+1, dtype=float)\n",
    "        k=np.arange(n_fft//2+1)\n",
    "        f=k*sample_rate/n_fft\n",
    "\n",
    "        fcf = f0 * 2.**(i/Nfpo) #3905.68454168\n",
    "\n",
    "        fi = np.concatenate(([f0], fcf, [fmax])) #fi =[f0, fcf, fmax] \n",
    "\n",
    "        # Construct the output matrix\n",
    "        H = np.zeros((Nb, n_fft // 2 + 1))\n",
    "\n",
    "        #for i in range(n_filters), com isto são 256\n",
    "        for j in range(Nb):\n",
    "            fLow = fi[j] \n",
    "            fmid = fi[j+1] \n",
    "            fUpp = fi[j+2]\n",
    "\n",
    "            H[j, :] = ((f - fLow) / (fmid - fLow)) * ((f > fLow) & (f <= fmid)) + \\\n",
    "                            ((f - fUpp) / (fmid - fUpp)) * ((f > fmid) & (f <= fUpp))\n",
    "            \n",
    "\n",
    "        H /= np.sum(H, axis=1, keepdims=True) # : A matriz é normalizada ao longo do eixo 1 (linhas), dividindo cada valor pela soma dos valores na respectiva linha. Isto garante que a soma de cada linha seja igual a 1.65\n",
    "        \n",
    "        #Ver os filtros\n",
    "        \"\"\"plt.figure(figsize=(10, 6))\n",
    "        for j in range(Nb):\n",
    "            plt.plot(f, H[j, :])\n",
    "        plt.title('Triangular Log Filterbank')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.grid(True)\n",
    "        plt.show()\"\"\"\n",
    "        return tf.convert_to_tensor(H.T, dtype=tf.float32)\n",
    "        #return tf.convert_to_tensor(H.T)\n",
    "    \n",
    "\n",
    "    def call(self, x):\n",
    "        #tf.print(f\"self.filterbank_shape={self.filterbank.shape}\")\n",
    "        output = tf.tensordot(x, self.filterbank, axes=(self.freq_axis, 0))\n",
    "                \n",
    "        if self.data_format == _CH_LAST_STR:\n",
    "            output = tf.transpose(output, (0, 1, 3, 2))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Melspec_layer(Model):\n",
    "    \"\"\"\n",
    "    A wrapper class, based on the implementation:\n",
    "        https://github.com/keunwoochoi/kapre\n",
    "        \n",
    "    Input:\n",
    "        (B,1,T)\n",
    "    Output:\n",
    "        (B,C,T,1) with C=Number of mel-bins\n",
    "    \n",
    "    USAGE:\n",
    "        \n",
    "        See get_melspec_layer() in the below.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_shape=(1, 8000),\n",
    "            segment_norm=False,\n",
    "            n_fft=2048,\n",
    "            stft_hop=192,\n",
    "            n_mels=256,\n",
    "            fs=8000,\n",
    "            dur=1.,\n",
    "            f_min=300,\n",
    "            f_max=4000.,\n",
    "            amin=1e-10, # minimum amp.\n",
    "            dynamic_range=80.,\n",
    "            use_pad_layer=False,\n",
    "            name='Mel-spectrogram',\n",
    "            trainable=False,\n",
    "            **kwargs\n",
    "            ):\n",
    "        super(Melspec_layer, self).__init__(name=name, trainable=False, **kwargs)\n",
    "        \n",
    "        self.mel_fb_kwargs = {\n",
    "            'sample_rate': fs,\n",
    "            'n_freq': n_fft // 2 + 1,\n",
    "            'n_mels': n_mels,\n",
    "            'f_min': f_min,\n",
    "            'f_max': f_max,\n",
    "            }\n",
    "        \n",
    "        self.tri_fb_kwargs = {\n",
    "            'sample_rate': fs,\n",
    "            'n_fft': n_fft,\n",
    "            }\n",
    "            \n",
    "        self.n_fft = n_fft\n",
    "        self.stft_hop = stft_hop\n",
    "        self.n_mels = n_mels\n",
    "        self.amin = amin\n",
    "        self.dynamic_range = dynamic_range\n",
    "        self.segment_norm = segment_norm\n",
    "\n",
    "         # 'SAME' Padding layer\n",
    "        self.use_pad_layer = use_pad_layer\n",
    "        self.pad_l = n_fft // 2\n",
    "        self.pad_r = n_fft // 2\n",
    "        self.padded_input_shape = (1, int(fs * dur) + self.pad_l + self.pad_r)\n",
    "        self.pad_layer = Lambda(\n",
    "            lambda z: tf.pad(z, tf.constant([[0, 0], [0, 0],\n",
    "                                             [self.pad_l, self.pad_r]]))\n",
    "            )\n",
    "        \n",
    "        # Construct log-power Mel-spec layer\n",
    "        self.m = self.construct_melspec_layer(input_shape, name)\n",
    "\n",
    "        # Permute layer\n",
    "        self.p = tf.keras.Sequential(name='Permute')\n",
    "        self.p.add(Permute((3, 2, 1), input_shape=self.m.output_shape[1:]))\n",
    "        \n",
    "        super(Melspec_layer, self).build((None, input_shape[0], input_shape[1]))\n",
    "        \n",
    "        \n",
    "    def construct_melspec_layer(self, input_shape, name):\n",
    "        m = tf.keras.Sequential(name=name)\n",
    "        m.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "        if self.use_pad_layer:\n",
    "            m.add(self.pad_layer)\n",
    "        m.add(\n",
    "            STFT(\n",
    "                n_fft=self.n_fft,\n",
    "                hop_length=self.stft_hop,\n",
    "                window_name='hamming_window',\n",
    "                pad_begin=False, # We do not use Kapre's padding, due to the @tf.function compatiability\n",
    "                pad_end=False, # We do not use Kapre's padding, due to the @tf.function compatiability\n",
    "                input_data_format='channels_first',\n",
    "                output_data_format='channels_first')\n",
    "            )\n",
    "        m.add(\n",
    "            Magnitude()\n",
    "            )\n",
    "        m.add(\n",
    "            CustomApplyFilterbank(type='tri',\n",
    "                            filterbank_kwargs=self.tri_fb_kwargs,\n",
    "                            data_format='channels_first'\n",
    "                            )\n",
    "            )\n",
    "        return m\n",
    "        \n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        x = self.m(x) + 0.06\n",
    "        #x = tf.sqrt(x)\n",
    "        \n",
    "        x = tf.math.log(tf.maximum(x, self.amin)) / math.log(10)\n",
    "        x = x - tf.reduce_max(x)\n",
    "        x = tf.maximum(x, -1 * self.dynamic_range)\n",
    "        if self.segment_norm:\n",
    "            x = (x - tf.reduce_min(x) / 2) / tf.abs(tf.reduce_min(x) / 2 + 1e-10)\n",
    "        return self.p(x) # Permute((3,2,1))\n",
    "    \n",
    "\n",
    "def get_melspec_layer(cfg, trainable=False):\n",
    "    #type - 'mel' filter bank\n",
    "    \"\"\"fs = cfg['MODEL']['FS']\n",
    "    dur = cfg['MODEL']['DUR']\n",
    "    n_fft = cfg['MODEL']['STFT_WIN']\n",
    "    stft_hop = cfg['MODEL']['STFT_HOP']\n",
    "    n_mels = cfg['MODEL']['N_MELS']\n",
    "    f_min = cfg['MODEL']['F_MIN']\n",
    "    f_max = cfg['MODEL']['F_MAX']\n",
    "    if cfg['MODEL']['FEAT'] == 'melspec':\n",
    "        segment_norm = False\n",
    "    elif cfg['MODEL']['FEAT'] == 'melspec_maxnorm':\n",
    "        segment_norm = True\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['MODEL']['FEAT'])\n",
    "    use_pad_layer = True\"\"\"\n",
    "\n",
    "    #type - 'tri' filter bank\n",
    "    fs = cfg['MODEL']['FS']\n",
    "    dur = cfg['MODEL']['DUR']\n",
    "    n_fft = cfg['MODEL']['STFT_WIN']\n",
    "    stft_hop = cfg['MODEL']['STFT_HOP']\n",
    "    n_mels = cfg['MODEL']['N_MELS']\n",
    "    f_min = cfg['MODEL']['F_MIN']\n",
    "    f_max = cfg['MODEL']['F_MAX']\n",
    "    if cfg['MODEL']['FEAT'] == 'melspec':\n",
    "        segment_norm = False\n",
    "    elif cfg['MODEL']['FEAT'] == 'melspec_maxnorm':\n",
    "        segment_norm = True\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['MODEL']['FEAT'])\n",
    "    use_pad_layer = False\n",
    "    \n",
    "    input_shape = (1, int(fs * dur))\n",
    "    l = Melspec_layer(input_shape=input_shape,\n",
    "                      segment_norm=segment_norm,\n",
    "                      n_fft=n_fft,\n",
    "                      stft_hop=stft_hop,\n",
    "                      n_mels=n_mels,\n",
    "                      fs=fs,\n",
    "                      dur=dur,\n",
    "                      f_min=f_min,\n",
    "                      f_max=f_max,\n",
    "                      use_pad_layer=use_pad_layer)\n",
    "    l.trainable = trainable\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_specaug: spec-augmentation layer.\n",
    "    m_specaug = get_specaug_chain_layer(cfg, trainable=False)\n",
    "    assert(m_specaug.bypass==False) # Detachable by setting m_specaug.bypass.\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_specaug, m_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import click\n",
    "import yaml\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default.yaml\n"
     ]
    }
   ],
   "source": [
    "config = \"default\"\n",
    "cfg = load_config(config)\n",
    "checkpoint_name = \"Checks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Restoring from ./logs/checkpoint/Checks/ckpt-100---\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "dataset = Dataset(cfg)\n",
    "\n",
    "# Build models.\n",
    "m_pre, m_specaug, m_fp = build_fp(cfg)\n",
    "\n",
    "# Learning schedule\n",
    "total_nsteps = cfg['TRAIN']['MAX_EPOCH'] * len(dataset.get_train_ds())\n",
    "if cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS':\n",
    "    lr_schedule = tf.keras.experimental.CosineDecay(\n",
    "        initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "        decay_steps=total_nsteps,\n",
    "        alpha=1e-06)\n",
    "elif cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS-RESTART':\n",
    "    lr_schedule = tf.keras.experimental.CosineDecayRestarts(\n",
    "        initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "        first_decay_steps=int(total_nsteps * 0.1),\n",
    "        num_periods=0.5,\n",
    "        alpha=2e-06)\n",
    "else:\n",
    "    lr_schedule = float(cfg['TRAIN']['LR'])\n",
    "\n",
    "# Optimizer\n",
    "if cfg['TRAIN']['OPTIMIZER'].upper() == 'LAMB':\n",
    "    opt = LAMB(learning_rate=lr_schedule)\n",
    "elif cfg['TRAIN']['OPTIMIZER'].upper() == 'ADAM':\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "else:\n",
    "    raise NotImplementedError(cfg['TRAIN']['OPTIMIZER'])\n",
    "\n",
    "# Experiment helper: see utils.experiment_helper.py for details.\n",
    "helper = ExperimentHelper(\n",
    "    checkpoint_name=checkpoint_name,\n",
    "    optimizer=opt,\n",
    "    model_to_checkpoint=m_fp,\n",
    "    cfg=cfg)\n",
    "\n",
    "# Loss objects\n",
    "if cfg['LOSS']['LOSS_MODE'].upper() == 'NTXENT': # Default\n",
    "    loss_obj_train = NTxentLoss(\n",
    "        n_org=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "        n_rep=cfg['BSZ']['TR_BATCH_SZ'] - cfg['BSZ']['TR_N_ANCHOR'],\n",
    "        tau=cfg['LOSS']['TAU'])\n",
    "    loss_obj_val = NTxentLoss(\n",
    "        n_org=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "        n_rep=cfg['BSZ']['VAL_BATCH_SZ'] - cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "        tau=cfg['LOSS']['TAU'])\n",
    "elif cfg['LOSS']['LOSS_MODE'].upper() == 'ONLINE-TRIPLET': # Now-playing\n",
    "    loss_obj_train = OnlineTripletLoss(\n",
    "        bsz=cfg['BSZ']['TR_BATCH_SZ'],\n",
    "        n_anchor=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "        mode = 'semi-hard',\n",
    "        margin=cfg['LOSS']['MARGIN'])\n",
    "    loss_obj_val = OnlineTripletLoss(\n",
    "        bsz=cfg['BSZ']['VAL_BATCH_SZ'],\n",
    "        n_anchor=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "        mode = 'all', # use 'all' mode for validation\n",
    "        margin=0.)\n",
    "else:\n",
    "    raise NotImplementedError(cfg['LOSS']['LOSS_MODE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.get_train_ds(0)\n",
    "enq = tf.keras.utils.OrderedEnqueuer(\n",
    "        train_ds, use_multiprocessing=True, shuffle=train_ds.shuffle)\n",
    "enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "        max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(enq.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_anchors = len(X[0])\n",
    "X = tf.concat(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teste - a ver se funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 256, 32, 1), dtype=float32, numpy=\n",
       "array([[[[-1.8856899 ],\n",
       "         [-1.8219882 ],\n",
       "         [-1.8321791 ],\n",
       "         ...,\n",
       "         [-2.9832838 ],\n",
       "         [-3.0193062 ],\n",
       "         [-3.05398   ]],\n",
       "\n",
       "        [[-1.897977  ],\n",
       "         [-1.8300189 ],\n",
       "         [-1.828851  ],\n",
       "         ...,\n",
       "         [-2.997298  ],\n",
       "         [-2.8920438 ],\n",
       "         [-2.892788  ]],\n",
       "\n",
       "        [[-1.9039111 ],\n",
       "         [-1.8317351 ],\n",
       "         [-1.8277899 ],\n",
       "         ...,\n",
       "         [-2.9129188 ],\n",
       "         [-2.8311872 ],\n",
       "         [-2.8318455 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.1046157 ],\n",
       "         [-3.1012685 ],\n",
       "         [-3.0658739 ],\n",
       "         ...,\n",
       "         [-3.022911  ],\n",
       "         [-3.0088663 ],\n",
       "         [-3.0049806 ]],\n",
       "\n",
       "        [[-3.319933  ],\n",
       "         [-3.353861  ],\n",
       "         [-3.3739104 ],\n",
       "         ...,\n",
       "         [-3.3477015 ],\n",
       "         [-3.3571806 ],\n",
       "         [-3.3283339 ]],\n",
       "\n",
       "        [[-3.3648086 ],\n",
       "         [-3.4009068 ],\n",
       "         [-3.4443629 ],\n",
       "         ...,\n",
       "         [-3.4245806 ],\n",
       "         [-3.4409137 ],\n",
       "         [-3.3783526 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.472487  ],\n",
       "         [-1.564373  ],\n",
       "         [-1.6581761 ],\n",
       "         ...,\n",
       "         [-1.3035567 ],\n",
       "         [-1.4638207 ],\n",
       "         [-1.7263875 ]],\n",
       "\n",
       "        [[-1.4717451 ],\n",
       "         [-1.5011501 ],\n",
       "         [-1.5131307 ],\n",
       "         ...,\n",
       "         [-1.8221035 ],\n",
       "         [-1.7642297 ],\n",
       "         [-1.852047  ]],\n",
       "\n",
       "        [[-1.4758337 ],\n",
       "         [-1.4949423 ],\n",
       "         [-1.5067492 ],\n",
       "         ...,\n",
       "         [-1.8202252 ],\n",
       "         [-1.7783542 ],\n",
       "         [-1.8648614 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.3905501 ],\n",
       "         [-3.3969169 ],\n",
       "         [-3.3996716 ],\n",
       "         ...,\n",
       "         [-3.0173535 ],\n",
       "         [-3.0607555 ],\n",
       "         [-3.085398  ]],\n",
       "\n",
       "        [[-3.4109359 ],\n",
       "         [-3.4263735 ],\n",
       "         [-3.4279337 ],\n",
       "         ...,\n",
       "         [-3.4180417 ],\n",
       "         [-3.4292707 ],\n",
       "         [-3.4148805 ]],\n",
       "\n",
       "        [[-3.4472013 ],\n",
       "         [-3.475998  ],\n",
       "         [-3.4607842 ],\n",
       "         ...,\n",
       "         [-3.4357417 ],\n",
       "         [-3.459897  ],\n",
       "         [-3.4412556 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.7783297 ],\n",
       "         [-1.7511195 ],\n",
       "         [-1.7824227 ],\n",
       "         ...,\n",
       "         [-2.3192017 ],\n",
       "         [-2.1985903 ],\n",
       "         [-2.1670125 ]],\n",
       "\n",
       "        [[-1.5011919 ],\n",
       "         [-1.5022322 ],\n",
       "         [-1.580694  ],\n",
       "         ...,\n",
       "         [-2.1337202 ],\n",
       "         [-2.16948   ],\n",
       "         [-2.305021  ]],\n",
       "\n",
       "        [[-1.4702808 ],\n",
       "         [-1.4525342 ],\n",
       "         [-1.5053933 ],\n",
       "         ...,\n",
       "         [-2.1535392 ],\n",
       "         [-2.1970167 ],\n",
       "         [-2.3091795 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.3761964 ],\n",
       "         [-3.3770928 ],\n",
       "         [-3.3682513 ],\n",
       "         ...,\n",
       "         [-3.1738484 ],\n",
       "         [-3.17051   ],\n",
       "         [-3.1817193 ]],\n",
       "\n",
       "        [[-3.4491162 ],\n",
       "         [-3.4443312 ],\n",
       "         [-3.4107752 ],\n",
       "         ...,\n",
       "         [-3.3704739 ],\n",
       "         [-3.3791504 ],\n",
       "         [-3.3888998 ]],\n",
       "\n",
       "        [[-3.4641013 ],\n",
       "         [-3.4552855 ],\n",
       "         [-3.4147859 ],\n",
       "         ...,\n",
       "         [-3.4295082 ],\n",
       "         [-3.444303  ],\n",
       "         [-3.4398177 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.6595764 ],\n",
       "         [-1.2795285 ],\n",
       "         [-0.93181086],\n",
       "         ...,\n",
       "         [-1.3533452 ],\n",
       "         [-1.1954156 ],\n",
       "         [-1.1348206 ]],\n",
       "\n",
       "        [[-1.2330207 ],\n",
       "         [-0.9804872 ],\n",
       "         [-0.797264  ],\n",
       "         ...,\n",
       "         [-1.1506525 ],\n",
       "         [-1.1386728 ],\n",
       "         [-1.1631038 ]],\n",
       "\n",
       "        [[-1.2712954 ],\n",
       "         [-1.0093129 ],\n",
       "         [-0.81441426],\n",
       "         ...,\n",
       "         [-1.1685838 ],\n",
       "         [-1.1525612 ],\n",
       "         [-1.175488  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.3526082 ],\n",
       "         [-3.3419409 ],\n",
       "         [-3.2848077 ],\n",
       "         ...,\n",
       "         [-3.3362875 ],\n",
       "         [-3.3589914 ],\n",
       "         [-3.3274727 ]],\n",
       "\n",
       "        [[-3.4504895 ],\n",
       "         [-3.431755  ],\n",
       "         [-3.3456209 ],\n",
       "         ...,\n",
       "         [-3.426333  ],\n",
       "         [-3.4554777 ],\n",
       "         [-3.3676338 ]],\n",
       "\n",
       "        [[-3.4629679 ],\n",
       "         [-3.442378  ],\n",
       "         [-3.348722  ],\n",
       "         ...,\n",
       "         [-3.4323606 ],\n",
       "         [-3.4698267 ],\n",
       "         [-3.3690188 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.5788932 ],\n",
       "         [-1.2783655 ],\n",
       "         [-1.0725306 ],\n",
       "         ...,\n",
       "         [-1.4532567 ],\n",
       "         [-1.5754232 ],\n",
       "         [-1.7064313 ]],\n",
       "\n",
       "        [[-1.2188982 ],\n",
       "         [-1.138978  ],\n",
       "         [-1.1149218 ],\n",
       "         ...,\n",
       "         [-1.61678   ],\n",
       "         [-1.7261304 ],\n",
       "         [-2.3314235 ]],\n",
       "\n",
       "        [[-1.2350794 ],\n",
       "         [-1.1571158 ],\n",
       "         [-1.1357856 ],\n",
       "         ...,\n",
       "         [-1.6030331 ],\n",
       "         [-1.6932127 ],\n",
       "         [-2.1059375 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.038904  ],\n",
       "         [-3.048314  ],\n",
       "         [-3.059131  ],\n",
       "         ...,\n",
       "         [-2.9886842 ],\n",
       "         [-3.0056942 ],\n",
       "         [-3.0426402 ]],\n",
       "\n",
       "        [[-3.2277222 ],\n",
       "         [-3.2997942 ],\n",
       "         [-3.3212228 ],\n",
       "         ...,\n",
       "         [-3.2225206 ],\n",
       "         [-3.240006  ],\n",
       "         [-3.3013391 ]],\n",
       "\n",
       "        [[-3.282355  ],\n",
       "         [-3.3655527 ],\n",
       "         [-3.4195619 ],\n",
       "         ...,\n",
       "         [-3.286004  ],\n",
       "         [-3.3065672 ],\n",
       "         [-3.3975306 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.6221485 ],\n",
       "         [-1.8579375 ],\n",
       "         [-1.8883578 ],\n",
       "         ...,\n",
       "         [-2.2971094 ],\n",
       "         [-1.68576   ],\n",
       "         [-1.6184237 ]],\n",
       "\n",
       "        [[-1.5040152 ],\n",
       "         [-1.6780052 ],\n",
       "         [-1.6274998 ],\n",
       "         ...,\n",
       "         [-1.235877  ],\n",
       "         [-1.3257276 ],\n",
       "         [-1.3109338 ]],\n",
       "\n",
       "        [[-1.483808  ],\n",
       "         [-1.6498263 ],\n",
       "         [-1.6245852 ],\n",
       "         ...,\n",
       "         [-1.1991096 ],\n",
       "         [-1.2974937 ],\n",
       "         [-1.2912085 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.2610474 ],\n",
       "         [-3.3621666 ],\n",
       "         [-3.3926468 ],\n",
       "         ...,\n",
       "         [-3.2945285 ],\n",
       "         [-3.3738782 ],\n",
       "         [-3.3646746 ]],\n",
       "\n",
       "        [[-3.2915635 ],\n",
       "         [-3.4211369 ],\n",
       "         [-3.448771  ],\n",
       "         ...,\n",
       "         [-3.3220196 ],\n",
       "         [-3.4440985 ],\n",
       "         [-3.4113789 ]],\n",
       "\n",
       "        [[-3.295608  ],\n",
       "         [-3.4331012 ],\n",
       "         [-3.4626184 ],\n",
       "         ...,\n",
       "         [-3.3250263 ],\n",
       "         [-3.4502163 ],\n",
       "         [-3.4131866 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pre(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo seguinte, alterar o data augmentation antes de treinar.\n",
    "feat = m_specaug(m_pre(X)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feito\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "folder_path = './DadosDebugMostrarProfessor'\n",
    "file_name = 'X_antes_concat_trainStep.csv'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "\n",
    "with open(file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for array in X:\n",
    "        writer.writerow(array)\n",
    "\n",
    "print('Feito')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
