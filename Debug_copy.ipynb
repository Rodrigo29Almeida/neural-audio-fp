{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: tensorflow-gpu\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponível: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "GPU disponível: PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verifica as GPUs disponíveis\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"GPU disponível:\", gpu)\n",
    "else:\n",
    "    print(\"Nenhuma GPU disponível.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 20:09:44.161950: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-03 20:09:44.161974: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-03 20:09:44.162707: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-03 20:09:44.168034: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 20:09:45.572223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-03 20:09:45.572401: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-03 20:09:45.608168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-03 20:09:45.608724: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-03 20:09:45.609168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-03 20:09:45.609589: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found:', tf.test.gpu_device_name())\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from model.dataset import Dataset\n",
    "#from model.fp.melspec.melspectrogram import get_melspec_layer\n",
    "from model.fp.specaug_chain.specaug_chain import get_specaug_chain_layer\n",
    "from model.fp.nnfp import get_fingerprinter\n",
    "from model.fp.NTxent_loss_single_gpu import NTxentLoss\n",
    "from model.fp.online_triplet_loss import OnlineTripletLoss\n",
    "from model.fp.lamb_optimizer import LAMB\n",
    "from model.utils.experiment_helper import ExperimentHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Lambda, Permute\n",
    "from kapre.time_frequency import Magnitude #STFT, #, ApplyFilterbank\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from kapre import backend\n",
    "from kapre.backend import _CH_FIRST_STR, _CH_LAST_STR, _CH_DEFAULT_STR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import tensor_util\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops.signal import window_ops\n",
    "from tensorflow.python.ops.signal import shape_ops\n",
    "from tensorflow.python.ops.signal import fft_ops\n",
    "from tensorflow.python.util import dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def _enclosing_power_of_two(value):\n",
    "  #\"\"\"Return 2**N for integer N such that 2**N >= value.\"\"\"\n",
    "\"\"\"\n",
    "  value_static = tensor_util.constant_value(value)\n",
    "  if value_static is not None:\n",
    "    return constant_op.constant(\n",
    "        int(2**np.ceil(np.log(value_static) / np.log(2.0))), value.dtype)\n",
    "  return math_ops.cast(\n",
    "      math_ops.pow(\n",
    "          2.0,\n",
    "          math_ops.ceil(\n",
    "              math_ops.log(math_ops.cast(value, dtypes.float32)) /\n",
    "              math_ops.log(2.0))), value.dtype)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@dispatch.add_dispatch_support\n",
    "def stft(signals, frame_length, frame_step, fft_length=None,\n",
    "         window_fn=window_ops.hann_window,\n",
    "         pad_end=False, name=None):\n",
    "  with ops.name_scope(name, 'stft', [signals, frame_length,\n",
    "                                     frame_step]):\n",
    "    #tf.print(f\"window_fn:{window_fn}\")\n",
    "    signals = ops.convert_to_tensor(signals, name='signals')\n",
    "    signals.shape.with_rank_at_least(1)\n",
    "    frame_length = ops.convert_to_tensor(frame_length, name='frame_length')\n",
    "    frame_length.shape.assert_has_rank(0)\n",
    "    frame_step = ops.convert_to_tensor(frame_step, name='frame_step')\n",
    "    frame_step.shape.assert_has_rank(0)\n",
    "\n",
    "    #tf.print(f\"frame_length:{frame_length}\")\n",
    "\n",
    "    if fft_length is None:\n",
    "      fft_length = _enclosing_power_of_two(frame_length)\n",
    "    else:\n",
    "      fft_length = ops.convert_to_tensor(fft_length, name='fft_length')\n",
    "\n",
    "    #tf.print(f\"fft_length:{fft_length}\")\n",
    "\n",
    "    framed_signals = shape_ops.frame(\n",
    "        signals, frame_length, frame_step, pad_end=pad_end)\n",
    "    \n",
    "    tf.print(f\"framed_signals{framed_signals}\")#ver uns tf.prints aqui\n",
    "\n",
    "    # Optionally window the framed signals.\n",
    "    if window_fn is not None:\n",
    "      window = window_fn(frame_length, dtype=framed_signals.dtype)\n",
    "      framed_signals *= window\n",
    "      #tf.print(f\"window{window}\")\n",
    "      #tf.print(f\"framed_signals{framed_signals}\")\n",
    "\n",
    "    #tf.print(f\"rfft{fft_ops.rfft(framed_signals, [fft_length])}\")\n",
    "    # fft_ops.rfft produces the (fft_length/2 + 1) unique components of the\n",
    "    # FFT of the real windowed signals in framed_signals.\n",
    "    return fft_ops.rfft(framed_signals, [fft_length])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STFT(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft=2048,\n",
    "        win_length=None,\n",
    "        hop_length=None,\n",
    "        window_name=None,\n",
    "        pad_begin=False,\n",
    "        pad_end=False,\n",
    "        input_data_format='default',\n",
    "        output_data_format='default',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(STFT, self).__init__(**kwargs)\n",
    "\n",
    "        backend.validate_data_format_str(input_data_format)\n",
    "        backend.validate_data_format_str(output_data_format)\n",
    "\n",
    "        if win_length is None:\n",
    "            win_length = n_fft\n",
    "        if hop_length is None:\n",
    "            hop_length = win_length // 4\n",
    "\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.window_name = window_name\n",
    "        self.window_fn = backend.get_window_fn(window_name)\n",
    "        self.pad_begin = pad_begin\n",
    "        self.pad_end = pad_end\n",
    "\n",
    "        idt, odt = input_data_format, output_data_format\n",
    "        self.output_data_format = K.image_data_format() if odt == _CH_DEFAULT_STR else odt\n",
    "        self.input_data_format = K.image_data_format() if idt == _CH_DEFAULT_STR else idt\n",
    "\n",
    "    def call(self, x):\n",
    "        #tf.print(f\"x antes waveform:{x.shape, type(x), x}\")\n",
    "        waveforms = x  # (batch, ch, time) if input_data_format == 'channels_first'.\n",
    "        # (batch, time, ch) if input_data_format == 'channels_last'.\n",
    "\n",
    "        # this is needed because tf.signal.stft lives in channels_first land.\n",
    "        if self.input_data_format == _CH_LAST_STR:\n",
    "            waveforms = tf.transpose(\n",
    "                waveforms, perm=(0, 2, 1)\n",
    "            )  # always (batch, ch, time) from here\n",
    "\n",
    "        if self.pad_begin:\n",
    "            waveforms = tf.pad(\n",
    "                waveforms, tf.constant([[0, 0], [0, 0], [int(self.n_fft - self.hop_length), 0]])\n",
    "            )\n",
    "        #tf.print(f\"self.pad_begin={self.pad_begin}, self.input_data_format={self.input_data_format}\")\n",
    "        #tf.print(f\"waveforms{waveforms.shape, type(waveforms), waveforms}\")\n",
    "        \n",
    "        #tf.print(f\"waveforms:{waveforms}\")\n",
    "        #tf.print(f\"self.win_length:{self.win_length}\")\n",
    "        #tf.print(f\"self.hop_length:{self.hop_length}\")\n",
    "        #tf.print(f\"self.n_fft:{self.n_fft}\")\n",
    "        #tf.print(f\"self.pad_end:{self.pad_end}\")\n",
    "        #tf.print(f\"self.name:{self.name}\")\n",
    "            \n",
    "        stfts = tf.signal.stft(\n",
    "            signals=waveforms,\n",
    "            frame_length=self.win_length,\n",
    "            frame_step=self.hop_length,\n",
    "            fft_length=self.n_fft,\n",
    "            window_fn=self.window_fn,\n",
    "            pad_end=self.pad_end,\n",
    "            name='%s_tf.signal.stft' % self.name,\n",
    "        )  # (batch, ch, time, freq)\n",
    "        \n",
    "        #tf.print(f\"stfts:{stfts}\")\n",
    "\n",
    "        if self.output_data_format == _CH_LAST_STR:\n",
    "            stfts = tf.transpose(stfts, perm=(0, 2, 3, 1))  # (batch, t, f, ch)\n",
    "\n",
    "        #tf.print(f\"self.output_data_format={self.output_data_format}\")\n",
    "        #tf.print(f\"stfts{stfts.shape, type(stfts), stfts}\")\n",
    "        return stfts\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(STFT, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                'n_fft': self.n_fft,\n",
    "                'win_length': self.win_length,\n",
    "                'hop_length': self.hop_length,\n",
    "                'window_name': self.window_name,\n",
    "                'pad_begin': self.pad_begin,\n",
    "                'pad_end': self.pad_end,\n",
    "                'input_data_format': self.input_data_format,\n",
    "                'output_data_format': self.output_data_format,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import librosa\n",
    "#%matplotlib widget\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kapre.time_frequency import ApplyFilterbank\n",
    "\n",
    "class CustomApplyFilterbank(ApplyFilterbank):\n",
    "    def __init__(self, type, filterbank_kwargs, data_format='default', **kwargs):\n",
    "        super(CustomApplyFilterbank, self).__init__(type, filterbank_kwargs, data_format, **kwargs)\n",
    "\n",
    "        # tipo de Banco de filtros\n",
    "        if type == 'tri':\n",
    "            self.filterbank = self.filterbank_triangular_log(**filterbank_kwargs)\n",
    "\n",
    "        if data_format == _CH_DEFAULT_STR:\n",
    "            self.data_format = K.image_data_format()\n",
    "        else:\n",
    "            self.data_format = data_format\n",
    "\n",
    "        if self.data_format == _CH_FIRST_STR:\n",
    "            self.freq_axis = 3\n",
    "        else:\n",
    "            self.freq_axis = 2\n",
    "\n",
    "    def filterbank_triangular_log(self, sample_rate, n_fft):\n",
    "        # Com o objetivo de ter 256 filtros e 8000 Hz na frequência de amostragem, teve-se de optar por Nfft de 2048, o que resulta em 54.4024 filtros por oitava, e numa frequência mínima de 151.3483 Hz.\n",
    "\n",
    "        # Sendo assim, o Nfpo será 60, 5*12, e a frequência do último filtro, f256, será Si7 = 3951.066410048992 Hz. Resultando numa frequência máxima de 3996.975590329487 Hz.\n",
    "        # Com isto, obtem-se pelo menos um bin em cada filtro, visto que f0*(2^(2/Nfpo)-1) = 4.7979 > 8000/2048 = 3.9062. Para uma Nfft de 1024, não era certo que obtivesse pelo menos um bin por filtro.\n",
    "        #O primeiro filtro estava a zero.\n",
    "\n",
    "        n_fft=2048\n",
    "        sample_rate=8000\n",
    "        Nfpo=60 #=5*12\n",
    "        Nb =256\n",
    "\n",
    "        #Cálculo da fmin e fmax\n",
    "        f256 = 440*2.**(38/12) # Si7 = 3951.066410048992 Hz;\n",
    "        f0=f256/2**(256/Nfpo) # fmin, 205.2672581380976 Hz\n",
    "        fmax = f0*2**(257/Nfpo) # fmax, 3996.975590329487 Hz\n",
    "\n",
    "        #Depois disto, dá bins em todos os fitros. Ver a linha 24 do getOctaveFilterBanck2.m\n",
    "\n",
    "        i=np.arange(0,Nb+2, dtype=np.int32)\n",
    "        k=np.arange(0, n_fft//2+1, dtype=int)\n",
    "        f=k*sample_rate/n_fft\n",
    "\n",
    "        fcf = f0 * 2.**(i/Nfpo) #3905.68454168\n",
    "\n",
    "        #fi = np.concatenate(([f0], fcf, [fmax])) #fi =[f0, fcf, fmax] \n",
    "        #fcf está a incluir f0, fcf e fmax\n",
    "        #tf.print(f\"fcf:{fcf}\")\n",
    "\n",
    "        # Construct the output matrix\n",
    "        H = np.zeros((Nb, n_fft // 2 + 1))\n",
    "\n",
    "        #for i in range(n_filters), com isto são 256\n",
    "        for j in range(Nb):\n",
    "            fLow = fcf[j] \n",
    "            fmid = fcf[j+1] \n",
    "            fUpp = fcf[j+2]\n",
    "\n",
    "            H[j, :] = ((f - fLow) / (fmid - fLow)) * ((f > fLow) & (f <= fmid)) + \\\n",
    "                            ((f - fUpp) / (fmid - fUpp)) * ((f > fmid) & (f <= fUpp))\n",
    "            \n",
    "\n",
    "        #H /= np.sum(H, axis=1, keepdims=True) # : A matriz é normalizada ao longo do eixo 1 (linhas), dividindo cada valor pela soma dos valores na respectiva linha. Isto garante que a soma de cada linha seja igual a 1.65\n",
    "        \n",
    "        #Ver os filtros\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for j in range(Nb):\n",
    "            plt.plot(f, H[j, :])\n",
    "        plt.title('Triangular Log Filterbank')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        return tf.convert_to_tensor(H.T, dtype=tf.float32)\n",
    "        #return tf.convert_to_tensor(H.T)\n",
    "    \n",
    "\n",
    "    def call(self, x):\n",
    "        #tf.print(f\"self.filterbank_shape={self.filterbank.shape}\")\n",
    "        output = tf.tensordot(x, self.filterbank, axes=(self.freq_axis, 0))\n",
    "        #tf.print(f\"x={x}\")\n",
    "                \n",
    "        if self.data_format == _CH_LAST_STR:\n",
    "            output = tf.transpose(output, (0, 1, 3, 2))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MagnitudeSquared(Layer):\n",
    "    def call(self, x):\n",
    "        return tf.abs(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Melspec_layer(Model):\n",
    "    \"\"\"\n",
    "    A wrapper class, based on the implementation:\n",
    "        https://github.com/keunwoochoi/kapre\n",
    "        \n",
    "    Input:\n",
    "        (B,1,T)\n",
    "    Output:\n",
    "        (B,C,T,1) with C=Number of mel-bins\n",
    "    \n",
    "    USAGE:\n",
    "        \n",
    "        See get_melspec_layer() in the below.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_shape=(1, 8000),\n",
    "            segment_norm=False,\n",
    "            n_fft=2048,\n",
    "            stft_hop=258,\n",
    "            n_win=1549, # = 6*M+1, Window Length\n",
    "            n_mels=256,\n",
    "            fs=8000,\n",
    "            dur=1.,\n",
    "            f_min=300,\n",
    "            f_max=4000.,\n",
    "            amin=10**(-20/10), # minimum amp.\n",
    "            dynamic_range=80.,\n",
    "            use_pad_layer=False,\n",
    "            name='Mel-spectrogram',\n",
    "            trainable=False,\n",
    "            **kwargs\n",
    "            ):\n",
    "        super(Melspec_layer, self).__init__(name=name, trainable=False, **kwargs)\n",
    "        \n",
    "        self.mel_fb_kwargs = {\n",
    "            'sample_rate': fs,\n",
    "            'n_freq': n_fft // 2 + 1,\n",
    "            'n_mels': n_mels,\n",
    "            'f_min': f_min,\n",
    "            'f_max': f_max,\n",
    "            }\n",
    "        \n",
    "        self.tri_fb_kwargs = {\n",
    "            'sample_rate': fs,\n",
    "            'n_fft': n_fft,\n",
    "            }\n",
    "            \n",
    "        self.n_fft = n_fft\n",
    "        self.stft_hop = stft_hop\n",
    "        self.n_mels = n_mels\n",
    "        self.amin = amin\n",
    "        self.dynamic_range = dynamic_range\n",
    "        self.segment_norm = segment_norm\n",
    "\n",
    "        self.n_win = n_win #RA\n",
    "\n",
    "        #Padding para type ='mel'\n",
    "         # 'SAME' Padding layer\n",
    "        self.use_pad_layer = use_pad_layer\n",
    "        self.pad_l = n_fft // 2\n",
    "        self.pad_r = n_fft // 2\n",
    "        self.padded_input_shape = (1, int(fs * dur) + self.pad_l + self.pad_r)\n",
    "        self.pad_layer = Lambda(\n",
    "            lambda z: tf.pad(z, tf.constant([[0, 0], [0, 0],\n",
    "                                             [self.pad_l, self.pad_r]]))\n",
    "            )\n",
    "\n",
    "        #Padding para type ='tri'\n",
    "        self.Npad_l = 3*self.stft_hop\n",
    "        self.Npad_r = 3*self.stft_hop-1\n",
    "        self.padded_input_shape_RA = (1, int(fs * dur) + self.Npad_l + self.Npad_r) #self.padded_input_shape:(1, 9547)\n",
    "        self.pad_layer_RA = Lambda(\n",
    "            lambda z: tf.pad(z, tf.constant([[0, 0], [0, 0],\n",
    "                                             [self.Npad_l, self.Npad_r]]))\n",
    "            )  #onde fs=31*M+2\n",
    "        \n",
    "        #tf.print(f\"self.padded_input_shape:{self.padded_input_shape_RA}\")\n",
    "        #tf.print(f\"self.pad_layer_RA:{self.pad_layer_RA}\")\n",
    "\n",
    "\n",
    "        # Construct log-power Mel-spec layer\n",
    "        self.m = self.construct_melspec_layer(input_shape, name)\n",
    "\n",
    "\n",
    "        # Permute layer\n",
    "        self.p = tf.keras.Sequential(name='Permute')\n",
    "        self.p.add(Permute((3, 2, 1), input_shape=self.m.output_shape[1:]))\n",
    "        \n",
    "        super(Melspec_layer, self).build((None, input_shape[0], input_shape[1]))\n",
    "        \n",
    "        \n",
    "    def construct_melspec_layer(self, input_shape, name):\n",
    "        m = tf.keras.Sequential(name=name)\n",
    "        m.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "        \"\"\"if self.use_pad_layer: #mel e log\n",
    "            m.add(self.pad_layer)\n",
    "        else: #tri\n",
    "            m.add(self.pad_layer_RA)\"\"\"\n",
    "        m.add(self.pad_layer_RA)\n",
    "        #tf.print(f\"m:{m}\")\n",
    "        m.add(\n",
    "            STFT(\n",
    "                n_fft=self.n_fft,\n",
    "                win_length=self.n_win,\n",
    "                hop_length=self.stft_hop,\n",
    "                window_name='hamming_window',#'hamming_window',\n",
    "                pad_begin=False, # We do not use Kapre's padding, due to the @tf.function compatiability\n",
    "                pad_end=False, # We do not use Kapre's padding, due to the @tf.function compatiability\n",
    "                input_data_format='channels_first',\n",
    "                output_data_format='channels_first')\n",
    "            )\n",
    "        m.add(\n",
    "            MagnitudeSquared()\n",
    "            )\n",
    "        m.add(\n",
    "            CustomApplyFilterbank(type='tri', #pode ser 'tri', 'log', ou 'mel'\n",
    "                            filterbank_kwargs=self.tri_fb_kwargs,\n",
    "                            data_format='channels_first'\n",
    "                            )\n",
    "            )\n",
    "        return m\n",
    "        \n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        #tf.print(f\"x={x, type(x), x.shape}\")\n",
    "        x = self.m(x) + 0.06\n",
    "        #x = tf.sqrt(x)\n",
    "        \n",
    "        #tf.print(f\"x={x, type(x), x.shape}\")\n",
    "        #tf.print(f\"maximo={tf.maximum(x, self.amin)}\")\n",
    "        #tf.print(f\"x_contas={tf.math.log(tf.maximum(x, self.amin)) / math.log(10)}\")\n",
    "        \n",
    "        x = tf.math.log(tf.maximum(x, self.amin)) / math.log(10) # ver se usa o 20 aqui, com 20 ficava em db, sem 20 não\n",
    "        \n",
    "        #tf.print(f\"x do log={x}\")\n",
    "        \n",
    "        x = x - tf.reduce_max(x)\n",
    "        x = tf.maximum(x, -1 * self.dynamic_range) #ver os dados do x aqui\n",
    "        if self.segment_norm:\n",
    "            x = (x - tf.reduce_min(x) / 2) / tf.abs(tf.reduce_min(x) / 2 + 1e-10)\n",
    "        return self.p(x) # Permute((3,2,1))\n",
    "    \n",
    "\n",
    "def get_melspec_layer(cfg, trainable=False):\n",
    "    #type - 'mel' filter bank\n",
    "    \"\"\"fs = cfg['MODEL']['FS']\n",
    "    dur = cfg['MODEL']['DUR']\n",
    "    n_fft = cfg['MODEL']['STFT_WIN']\n",
    "    stft_hop = cfg['MODEL']['STFT_HOP']\n",
    "    n_mels = cfg['MODEL']['N_MELS']\n",
    "    f_min = cfg['MODEL']['F_MIN']\n",
    "    f_max = cfg['MODEL']['F_MAX']\n",
    "    if cfg['MODEL']['FEAT'] == 'melspec':\n",
    "        segment_norm = False\n",
    "    elif cfg['MODEL']['FEAT'] == 'melspec_maxnorm':\n",
    "        segment_norm = True\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['MODEL']['FEAT'])\n",
    "    use_pad_layer = True\"\"\"\n",
    "\n",
    "    #type - 'tri' filter bank\n",
    "    fs = cfg['MODEL']['FS']\n",
    "    dur = cfg['MODEL']['DUR']\n",
    "    n_fft = cfg['MODEL']['STFT_WIN']\n",
    "    stft_hop = cfg['MODEL']['STFT_HOP']\n",
    "    n_win = cfg['MODEL']['N_WIN'] #RA\n",
    "    n_mels = cfg['MODEL']['N_MELS']\n",
    "    f_min = cfg['MODEL']['F_MIN']\n",
    "    f_max = cfg['MODEL']['F_MAX']\n",
    "    if cfg['MODEL']['FEAT'] == 'melspec':\n",
    "        segment_norm = False\n",
    "    elif cfg['MODEL']['FEAT'] == 'melspec_maxnorm':\n",
    "        segment_norm = True\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['MODEL']['FEAT'])\n",
    "    use_pad_layer = False\n",
    "    \n",
    "    input_shape = (1, int(fs * dur))\n",
    "    l = Melspec_layer(input_shape=input_shape,\n",
    "                      segment_norm=segment_norm,\n",
    "                      n_fft=n_fft,\n",
    "                      stft_hop=stft_hop,\n",
    "                      n_win=n_win, #RA\n",
    "                      n_mels=n_mels,\n",
    "                      fs=fs,\n",
    "                      dur=dur,\n",
    "                      f_min=f_min,\n",
    "                      f_max=f_max,\n",
    "                      use_pad_layer=use_pad_layer)#RA\n",
    "    l.trainable = trainable\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_specaug: spec-augmentation layer.\n",
    "    m_specaug = get_specaug_chain_layer(cfg, trainable=False)\n",
    "    assert(m_specaug.bypass==False) # Detachable by setting m_specaug.bypass.\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_specaug, m_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import click\n",
    "import yaml\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"default_RA\"\n",
    "cfg = load_config(config)\n",
    "checkpoint_name = \"Checks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "dataset = Dataset(cfg)\n",
    "\n",
    "# Build models.\n",
    "m_pre, m_specaug, m_fp = build_fp(cfg)\n",
    "\n",
    "# Learning schedule\n",
    "total_nsteps = cfg['TRAIN']['MAX_EPOCH'] * len(dataset.get_train_ds())\n",
    "if cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS':\n",
    "    lr_schedule = tf.keras.experimental.CosineDecay(\n",
    "        initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "        decay_steps=total_nsteps,\n",
    "        alpha=1e-06)\n",
    "elif cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS-RESTART':\n",
    "    lr_schedule = tf.keras.experimental.CosineDecayRestarts(\n",
    "        initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "        first_decay_steps=int(total_nsteps * 0.1),\n",
    "        num_periods=0.5,\n",
    "        alpha=2e-06)\n",
    "else:\n",
    "    lr_schedule = float(cfg['TRAIN']['LR'])\n",
    "\n",
    "# Optimizer\n",
    "if cfg['TRAIN']['OPTIMIZER'].upper() == 'LAMB':\n",
    "    opt = LAMB(learning_rate=lr_schedule)\n",
    "elif cfg['TRAIN']['OPTIMIZER'].upper() == 'ADAM':\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "else:\n",
    "    raise NotImplementedError(cfg['TRAIN']['OPTIMIZER'])\n",
    "\n",
    "# Experiment helper: see utils.experiment_helper.py for details.\n",
    "helper = ExperimentHelper(\n",
    "    checkpoint_name=checkpoint_name,\n",
    "    optimizer=opt,\n",
    "    model_to_checkpoint=m_fp,\n",
    "    cfg=cfg)\n",
    "\n",
    "# Loss objects\n",
    "if cfg['LOSS']['LOSS_MODE'].upper() == 'NTXENT': # Default\n",
    "    loss_obj_train = NTxentLoss(\n",
    "        n_org=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "        n_rep=cfg['BSZ']['TR_BATCH_SZ'] - cfg['BSZ']['TR_N_ANCHOR'],\n",
    "        tau=cfg['LOSS']['TAU'])\n",
    "    loss_obj_val = NTxentLoss(\n",
    "        n_org=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "        n_rep=cfg['BSZ']['VAL_BATCH_SZ'] - cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "        tau=cfg['LOSS']['TAU'])\n",
    "elif cfg['LOSS']['LOSS_MODE'].upper() == 'ONLINE-TRIPLET': # Now-playing\n",
    "    loss_obj_train = OnlineTripletLoss(\n",
    "        bsz=cfg['BSZ']['TR_BATCH_SZ'],\n",
    "        n_anchor=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "        mode = 'semi-hard',\n",
    "        margin=cfg['LOSS']['MARGIN'])\n",
    "    loss_obj_val = OnlineTripletLoss(\n",
    "        bsz=cfg['BSZ']['VAL_BATCH_SZ'],\n",
    "        n_anchor=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "        mode = 'all', # use 'all' mode for validation\n",
    "        margin=0.)\n",
    "else:\n",
    "    raise NotImplementedError(cfg['LOSS']['LOSS_MODE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinal de teste para implementação de N e Nfft diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_win = cfg['MODEL']['N_WIN']\n",
    "fs = cfg['MODEL']['FS']\n",
    "\n",
    "n1 = np.arange(0, (n_win-1)/2)  # 3*M amostras\n",
    "n2 = np.arange(0, n_win-1)      # 6*M amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.sin(2 * np.pi * 3520 / fs * n1)  # 3*M Deixa um \"rasto\" de mais 3 tramas (6 tramas).\n",
    "x2 = np.zeros(n_win-1)                       # 6*M A 7ª trama só tem zeros\n",
    "x3 = np.sin(2 * np.pi * 880 / fs * n2)   # 6*M A 13ª trama só tem tom a 880 Hz\n",
    "x4 = np.sin(2 * np.pi * 440 / fs * n2)   # 6*M A 19ª trama só tem tom a 440 Hz\n",
    "x5 = 2 * np.random.rand(n_win-1) - 1         # Ruído uniforme entre -1 e 1; 6*M\n",
    "x6 = np.sin(2 * np.pi * 2200 / fs * np.arange(0, 1028))  # 3*M ruído com distribuição uniforme entre -1 e 1; 6*M. A 25ª trama só tem ruido\n",
    "x7=1\n",
    "\n",
    "x = np.concatenate([x1, [0], x2, [0], x3, [0], x4, [0], x5, [0], x6, [0]]) #adicionei este 0 para dar 8000 amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x) #tamanho do sinal 7999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x)\n",
    "plt.xlabel('Amostras')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Sinal x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_hop = 258\n",
    "Npad_l = 3*stft_hop\n",
    "Npad_r = 3*stft_hop-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbuf = np.concatenate([np.zeros(Npad_l), x, np.zeros(Npad_r)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(xbuf)\n",
    "plt.xlabel('Amostras')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Sinal com padding')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer(arr, n, p=0, opt='none'):\n",
    "    \"\"\"\n",
    "    Segmenta o vetor `arr` em colunas de comprimento `n` com sobreposição de `p` elementos.\n",
    "    \n",
    "    Parâmetros:\n",
    "    arr: vetor de entrada (1D numpy array)\n",
    "    n: tamanho de cada janela (int)\n",
    "    p: sobreposição entre janelas consecutivas (int, opcional, padrão 0)\n",
    "    opt: 'nodelay' para não atrasar a janela, 'none' para comportamento padrão (string, opcional)\n",
    "    \n",
    "    Retorna:\n",
    "    2D numpy array com as janelas segmentadas como colunas.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    step = n - p\n",
    "    if step <= 0:\n",
    "        raise ValueError(\"A sobreposição p deve ser menor que o tamanho da janela n.\")\n",
    "    \n",
    "    if opt == 'nodelay':\n",
    "        num_windows = int(np.ceil(len(arr) / float(step)))\n",
    "    else:\n",
    "        num_windows = int(np.floor((len(arr) - p) / float(step))) + 1\n",
    "    \n",
    "    shape = (num_windows, n)\n",
    "    buffer_matrix = np.zeros(shape)\n",
    "\n",
    "    for i in range(num_windows):\n",
    "        start = i * step\n",
    "        end = start + n\n",
    "        buffer_matrix[i, :len(arr[start:end])] = arr[start:end]\n",
    "\n",
    "    return buffer_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def buffer(sig, frame_len, overlap):\n",
    "    step = frame_len - overlap\n",
    "    shape = (sig.size - overlap, frame_len)\n",
    "    strides = (sig.strides[0], sig.strides[0])\n",
    "    return np.lib.stride_tricks.as_strided(sig, shape=shape, strides=strides)[::step]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer\n",
    "xf = buffer(xbuf, n_win, n_win-stft_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(xf[6, :])\n",
    "plt.xlabel('Amostras')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Sinal da 7ª Trama')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf.shape, xf.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pre, _, _ = build_fp(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = tf.convert_to_tensor(x, dtype=tf.float32) # <tf.Tensor: shape=(9546,), dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = tf.reshape(x_tensor, (1, 1, -1)) # <tf.Tensor: shape=(1, 1, 9546), dtype=float32, numpy=array([[[0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=m_pre(x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_reshaped = tf.squeeze(Y, axis=(0, 3))  # Remove-se os eixos do Batch e Canal. (B,F,T,C) -> (F,T)\n",
    "plt.figure()\n",
    "plt.imshow(Y_reshaped, aspect='auto', origin='lower')\n",
    "plt.colorbar()\n",
    "#plt.title('CQT Spectrogram')\n",
    "plt.xlabel('Tramas de 1 a 32')\n",
    "plt.ylabel('Canais: de 1 a 256')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinal de teste antes de 28 de maio, para implementação antiga de CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros\n",
    "fs = 8000\n",
    "Nx = fs  # 1 segundo de sinal\n",
    "N = 2048  # comprimento da janela\n",
    "M = 192  # hop-size\n",
    "\n",
    "# Sinal x\n",
    "x = np.zeros(Nx)\n",
    "x[0:2048] = np.sin(2 * np.pi * 3520 / fs * np.arange(2048))\n",
    "x[2049:2049 + 11 * 192] = 0\n",
    "x[22 * M:8000] = np.sin(2 * np.pi * 880 / fs * np.arange(3776))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pre, _, _ = build_fp(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = tf.convert_to_tensor(x, dtype=tf.float32) #<tf.Tensor: shape=(120, 1, 8000), dtype=float32, numpy=...>\n",
    "                        #<tf.Tensor: shape=(B, 1, 8000), dtype=float32, numpy=...>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = tf.reshape(x_tensor, (1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=m_pre(x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<tf.Tensor: shape=(1, 256, 32, 1), dtype=float32, numpy=...>\n",
    "Y_reshaped = tf.squeeze(Y, axis=(0, 3))  # Remove-se os eixos do Batch e Canal. (B,F,T,C) -> (F,T)\n",
    "plt.figure(1)\n",
    "plt.imshow(Y_reshaped, aspect='auto', origin='lower')\n",
    "plt.colorbar()\n",
    "#plt.title('CQT Spectrogram')\n",
    "plt.xlabel('Tramas de 1 a 32')\n",
    "plt.ylabel('Canais: de 1 a 256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nfpo=60\n",
    "\n",
    "f256 = 440*2.**(38/12) # Si7 = 3951.066410048992 Hz;\n",
    "f0=f256/2**(256/Nfpo) # fmin, 205.2672581380976 Hz\n",
    "fmax = f0*2**(257/Nfpo) # fmax, 3996.975590329487 Hz\n",
    "\n",
    "i=np.arange(1,256+1, dtype=np.int32)\n",
    "#k=np.arange(n_fft//2+1)\n",
    "#f=k*sample_rate/n_fft\n",
    "\n",
    "fcf = f0 * 2.**(i/Nfpo) #3905.68454168\n",
    "\n",
    "#fi = np.concatenate(([f0], fcf, [fmax])) #fi =[f0, fcf, fmax] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcf[257] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados\n",
    "tramas = np.arange(0, 32)\n",
    "diff_fc = np.diff(np.concatenate((fcf, [4000])))\n",
    "#f_centrais = fcf - np.diff(np.concatenate(([fi[0]], fi, [4000]))) // 2\n",
    "fc2 = fcf - diff_fc / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(2)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "X, Y = np.meshgrid(tramas, fc2)\n",
    "surf = ax.plot_surface(X, Y, Y_reshaped, cmap='jet', edgecolor='none')\n",
    "fig.colorbar(surf, label='dB')\n",
    "\n",
    "# Configurações de visualização\n",
    "ax.view_init(90, -90)\n",
    "ax.set_xlabel('Tramas de 0 a 31')\n",
    "ax.set_ylabel('fCentrais em Hertz')\n",
    "ax.set_zlabel('dB')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.plot(np.arange(Nx), x)\n",
    "plt.title('Signal')\n",
    "plt.xlabel('Amostras')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.get_train_ds(0)\n",
    "enq = tf.keras.utils.OrderedEnqueuer(\n",
    "        train_ds, use_multiprocessing=True, shuffle=train_ds.shuffle)\n",
    "enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "        max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(enq.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_anchors = len(X[0])\n",
    "X = tf.concat(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teste - a ver se funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pre(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo seguinte, alterar o data augmentation antes de treinar.\n",
    "feat = m_specaug(m_pre(X)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "folder_path = './DadosDebugMostrarProfessor'\n",
    "file_name = 'X_antes_concat_trainStep.csv'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "\n",
    "with open(file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for array in X:\n",
    "        writer.writerow(array)\n",
    "\n",
    "print('Feito')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/rodrigo/Documents/neural-audio-fp/model_RA/fp/specaug_chain/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_RA.fp.specaug_chain.specaug_chain_RA import get_specaug_chain_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_specaug_chain_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.fp.specaug_chain.specaug_chain import get_specaug_chain_layer\n",
    "from model.fp.specaug_chain.specaug_chain import display_spec\n",
    "from model.fp.specaug_chain.specaug_chain import plot_to_image\n",
    "from model.fp.specaug_chain.specaug_chain import test_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_specaug_chain_layer(cfg, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
