{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 13:52:35.848960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from model.dataset import Dataset\n",
    "#from model.fp.melspec.melspectrogram import get_melspec_layer\n",
    "from model.fp.specaug_chain.specaug_chain import get_specaug_chain_layer\n",
    "from model.fp.nnfp import get_fingerprinter\n",
    "from model.fp.NTxent_loss_single_gpu import NTxentLoss\n",
    "from model.fp.online_triplet_loss import OnlineTripletLoss\n",
    "from model.fp.lamb_optimizer import LAMB\n",
    "from model.utils.experiment_helper import ExperimentHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Lambda, Permute\n",
    "from kapre.time_frequency import Magnitude #STFT, #, ApplyFilterbank\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from kapre import backend\n",
    "from kapre.backend import _CH_FIRST_STR, _CH_LAST_STR, _CH_DEFAULT_STR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import tensor_util\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops.signal import window_ops\n",
    "from tensorflow.python.ops.signal import shape_ops\n",
    "from tensorflow.python.ops.signal import fft_ops\n",
    "from tensorflow.python.util import dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _enclosing_power_of_two(value):\n",
    "  \"\"\"Return 2**N for integer N such that 2**N >= value.\"\"\"\n",
    "  value_static = tensor_util.constant_value(value)\n",
    "  if value_static is not None:\n",
    "    return constant_op.constant(\n",
    "        int(2**np.ceil(np.log(value_static) / np.log(2.0))), value.dtype)\n",
    "  return math_ops.cast(\n",
    "      math_ops.pow(\n",
    "          2.0,\n",
    "          math_ops.ceil(\n",
    "              math_ops.log(math_ops.cast(value, dtypes.float32)) /\n",
    "              math_ops.log(2.0))), value.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch.add_dispatch_support\n",
    "def stft(signals, frame_length, frame_step, fft_length=None,\n",
    "         window_fn=window_ops.hann_window,\n",
    "         pad_end=False, name=None):\n",
    "  with ops.name_scope(name, 'stft', [signals, frame_length,\n",
    "                                     frame_step]):\n",
    "    signals = ops.convert_to_tensor(signals, name='signals')\n",
    "    signals.shape.with_rank_at_least(1)\n",
    "    frame_length = ops.convert_to_tensor(frame_length, name='frame_length')\n",
    "    frame_length.shape.assert_has_rank(0)\n",
    "    frame_step = ops.convert_to_tensor(frame_step, name='frame_step')\n",
    "    frame_step.shape.assert_has_rank(0)\n",
    "\n",
    "    if fft_length is None:\n",
    "      fft_length = _enclosing_power_of_two(frame_length)\n",
    "    else:\n",
    "      fft_length = ops.convert_to_tensor(fft_length, name='fft_length')\n",
    "\n",
    "    framed_signals = shape_ops.frame(\n",
    "        signals, frame_length, frame_step, pad_end=pad_end)\n",
    "\n",
    "    # Optionally window the framed signals.\n",
    "    if window_fn is not None:\n",
    "      window = window_fn(frame_length, dtype=framed_signals.dtype)\n",
    "      framed_signals *= window\n",
    "\n",
    "    # fft_ops.rfft produces the (fft_length/2 + 1) unique components of the\n",
    "    # FFT of the real windowed signals in framed_signals.\n",
    "    return fft_ops.rfft(framed_signals, [fft_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STFT(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft=2048,\n",
    "        win_length=None,\n",
    "        hop_length=None,\n",
    "        window_name=None,\n",
    "        pad_begin=False,\n",
    "        pad_end=False,\n",
    "        input_data_format='default',\n",
    "        output_data_format='default',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(STFT, self).__init__(**kwargs)\n",
    "\n",
    "        backend.validate_data_format_str(input_data_format)\n",
    "        backend.validate_data_format_str(output_data_format)\n",
    "\n",
    "        if win_length is None:\n",
    "            win_length = n_fft\n",
    "        if hop_length is None:\n",
    "            hop_length = win_length // 4\n",
    "\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.window_name = window_name\n",
    "        self.window_fn = backend.get_window_fn(window_name)\n",
    "        self.pad_begin = pad_begin\n",
    "        self.pad_end = pad_end\n",
    "\n",
    "        idt, odt = input_data_format, output_data_format\n",
    "        self.output_data_format = K.image_data_format() if odt == _CH_DEFAULT_STR else odt\n",
    "        self.input_data_format = K.image_data_format() if idt == _CH_DEFAULT_STR else idt\n",
    "\n",
    "    def call(self, x):\n",
    "        #tf.print(f\"x{x.shape, type(x), x}\")\n",
    "        waveforms = x  # (batch, ch, time) if input_data_format == 'channels_first'.\n",
    "        # (batch, time, ch) if input_data_format == 'channels_last'.\n",
    "\n",
    "        # this is needed because tf.signal.stft lives in channels_first land.\n",
    "        if self.input_data_format == _CH_LAST_STR:\n",
    "            waveforms = tf.transpose(\n",
    "                waveforms, perm=(0, 2, 1)\n",
    "            )  # always (batch, ch, time) from here\n",
    "\n",
    "        if self.pad_begin:\n",
    "            waveforms = tf.pad(\n",
    "                waveforms, tf.constant([[0, 0], [0, 0], [int(self.n_fft - self.hop_length), 0]])\n",
    "            )\n",
    "        #tf.print(f\"self.pad_begin={self.pad_begin}, self.input_data_format={self.input_data_format}\")\n",
    "        #tf.print(f\"waveforms{waveforms.shape, type(waveforms), waveforms}\")\n",
    "\n",
    "        stfts = stft(\n",
    "            signals=waveforms,\n",
    "            frame_length=self.win_length,\n",
    "            frame_step=self.hop_length,\n",
    "            fft_length=self.n_fft,\n",
    "            window_fn=self.window_fn,\n",
    "            pad_end=self.pad_end,\n",
    "            name='%s_tf.signal.stft' % self.name,\n",
    "        )  # (batch, ch, time, freq)\n",
    "        \n",
    "        #tf.print(f\"stfts{stfts}\")\n",
    "\n",
    "        if self.output_data_format == _CH_LAST_STR:\n",
    "            stfts = tf.transpose(stfts, perm=(0, 2, 3, 1))  # (batch, t, f, ch)\n",
    "\n",
    "        #tf.print(f\"self.output_data_format={self.output_data_format}\")\n",
    "        #tf.print(f\"stfts{stfts.shape, type(stfts), stfts}\")\n",
    "        return stfts\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(STFT, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                'n_fft': self.n_fft,\n",
    "                'win_length': self.win_length,\n",
    "                'hop_length': self.hop_length,\n",
    "                'window_name': self.window_name,\n",
    "                'pad_begin': self.pad_begin,\n",
    "                'pad_end': self.pad_end,\n",
    "                'input_data_format': self.input_data_format,\n",
    "                'output_data_format': self.output_data_format,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyFilterbank(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        type,\n",
    "        filterbank_kwargs,\n",
    "        data_format='default',\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        backend.validate_data_format_str(data_format)\n",
    "\n",
    "        self.type = type\n",
    "        self.filterbank_kwargs = filterbank_kwargs\n",
    "\n",
    "        if type == 'log':\n",
    "            self.filterbank = _log_filterbank = backend.filterbank_log(**filterbank_kwargs)\n",
    "        elif type == 'mel':\n",
    "            self.filterbank = _mel_filterbank = backend.filterbank_mel(**filterbank_kwargs)\n",
    "\n",
    "        if data_format == _CH_DEFAULT_STR:\n",
    "            self.data_format = K.image_data_format()\n",
    "        else:\n",
    "            self.data_format = data_format\n",
    "\n",
    "        if self.data_format == _CH_FIRST_STR:\n",
    "            self.freq_axis = 3\n",
    "        else:\n",
    "            self.freq_axis = 2\n",
    "        super(ApplyFilterbank, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Apply filterbank to `x`.\n",
    "\n",
    "        Args:\n",
    "            x (`Tensor`): float tensor in 2D batch shape.\n",
    "        \"\"\"\n",
    "\n",
    "        # x: 2d batch input. (b, t, fr, ch) or (b, ch, t, fr)\n",
    "        #tf.print(f\"x eh {x.shape, type(x)}\")\n",
    "        #tf.print(f\"\\n\\nfiltervank:{self.filterbank}\\naxes {(self.freq_axis, 0)}\")\n",
    "        #tf.print(f\"\\n\\nfilterbank:{self.filterbank.shape}\")\n",
    "        output = tf.tensordot(x, self.filterbank, axes=(self.freq_axis, 0))\n",
    "        #tf.print(f\"output{output.shape, type(output), output}\")\n",
    "        # ch_last -> (b, t, ch, new_fr). ch_first -> (b, ch, t, new_fr)\n",
    "        if self.data_format == _CH_LAST_STR:\n",
    "            output = tf.transpose(output, (0, 1, 3, 2))\n",
    "\n",
    "        #tf.print(f\"output{output.shape, type(output), output}\")\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ApplyFilterbank, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                'type': self.type,\n",
    "                'filterbank_kwargs': self.filterbank_kwargs,\n",
    "                'data_format': self.data_format,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Melspec_layer(Model):\n",
    "    \"\"\"\n",
    "    A wrapper class, based on the implementation:\n",
    "        https://github.com/keunwoochoi/kapre\n",
    "        \n",
    "    Input:\n",
    "        (B,1,T)\n",
    "    Output:\n",
    "        (B,C,T,1) with C=Number of mel-bins\n",
    "    \n",
    "    USAGE:\n",
    "        \n",
    "        See get_melspec_layer() in the below.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_shape=(1, 8000),\n",
    "            segment_norm=False,\n",
    "            n_fft=1024,\n",
    "            stft_hop=256,\n",
    "            n_mels=256,\n",
    "            fs=8000,\n",
    "            dur=1.,\n",
    "            f_min=300.,\n",
    "            f_max=4000.,\n",
    "            amin=1e-10, # minimum amp.\n",
    "            dynamic_range=80.,\n",
    "            name='Mel-spectrogram',\n",
    "            trainable=False,\n",
    "            **kwargs\n",
    "            ):\n",
    "        super(Melspec_layer, self).__init__(name=name, trainable=False, **kwargs)\n",
    "        \n",
    "        self.mel_fb_kwargs = {\n",
    "            'sample_rate': fs,\n",
    "            'n_freq': n_fft // 2 + 1,\n",
    "            'n_mels': n_mels,\n",
    "            'f_min': f_min,\n",
    "            'f_max': f_max,\n",
    "            }\n",
    "        self.n_fft = n_fft\n",
    "        self.stft_hop = stft_hop\n",
    "        self.n_mels = n_mels\n",
    "        self.amin = amin\n",
    "        self.dynamic_range = dynamic_range\n",
    "        self.segment_norm = segment_norm\n",
    "        \n",
    "        # 'SAME' Padding layer\n",
    "        self.pad_l = n_fft // 2\n",
    "        self.pad_r = n_fft // 2\n",
    "        self.padded_input_shape = (1, int(fs * dur) + self.pad_l + self.pad_r)\n",
    "        self.pad_layer = Lambda(\n",
    "            lambda z: tf.pad(z, tf.constant([[0, 0], [0, 0],\n",
    "                                             [self.pad_l, self.pad_r]]))\n",
    "            )\n",
    "        \n",
    "        # Construct log-power Mel-spec layer\n",
    "        self.m = self.construct_melspec_layer(input_shape, name)\n",
    "\n",
    "        # Permute layer\n",
    "        self.p = tf.keras.Sequential(name='Permute')\n",
    "        self.p.add(Permute((3, 2, 1), input_shape=self.m.output_shape[1:]))\n",
    "        \n",
    "        super(Melspec_layer, self).build((None, input_shape[0], input_shape[1]))\n",
    "        \n",
    "        \n",
    "    def construct_melspec_layer(self, input_shape, name):\n",
    "        m = tf.keras.Sequential(name=name)\n",
    "        m.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "        m.add(self.pad_layer)\n",
    "        m.add(\n",
    "            STFT(\n",
    "                n_fft=self.n_fft,\n",
    "                hop_length=self.stft_hop,\n",
    "                pad_begin=False, # We do not use Kapre's padding, due to the @tf.function compatiability\n",
    "                pad_end=False, # We do not use Kapre's padding, due to the @tf.function compatiability\n",
    "                input_data_format='channels_first',\n",
    "                output_data_format='channels_first')\n",
    "            )\n",
    "        m.add(\n",
    "            Magnitude()\n",
    "            )\n",
    "        m.add(\n",
    "            ApplyFilterbank(type='mel',\n",
    "                            filterbank_kwargs=self.mel_fb_kwargs,\n",
    "                            data_format='channels_first'\n",
    "                            )\n",
    "            )\n",
    "        return m\n",
    "        \n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        x = self.m(x) + 0.06\n",
    "        #x = tf.sqrt(x)\n",
    "        \n",
    "        x = tf.math.log(tf.maximum(x, self.amin)) / math.log(10)\n",
    "        x = x - tf.reduce_max(x)\n",
    "        x = tf.maximum(x, -1 * self.dynamic_range)\n",
    "        if self.segment_norm:\n",
    "            x = (x - tf.reduce_min(x) / 2) / tf.abs(tf.reduce_min(x) / 2 + 1e-10)\n",
    "        return self.p(x) # Permute((3,2,1))\n",
    "    \n",
    "\n",
    "def get_melspec_layer(cfg, trainable=False):\n",
    "    fs = cfg['MODEL']['FS']\n",
    "    dur = cfg['MODEL']['DUR']\n",
    "    n_fft = cfg['MODEL']['STFT_WIN']\n",
    "    stft_hop = cfg['MODEL']['STFT_HOP']\n",
    "    n_mels = cfg['MODEL']['N_MELS']\n",
    "    f_min = cfg['MODEL']['F_MIN']\n",
    "    f_max = cfg['MODEL']['F_MAX']\n",
    "    if cfg['MODEL']['FEAT'] == 'melspec':\n",
    "        segment_norm = False\n",
    "    elif cfg['MODEL']['FEAT'] == 'melspec_maxnorm':\n",
    "        segment_norm = True\n",
    "    else:\n",
    "        raise NotImplementedError(cfg['MODEL']['FEAT'])\n",
    "    \n",
    "    input_shape = (1, int(fs * dur))\n",
    "    l = Melspec_layer(input_shape=input_shape,\n",
    "                      segment_norm=segment_norm,\n",
    "                      n_fft=n_fft,\n",
    "                      stft_hop=stft_hop,\n",
    "                      n_mels=n_mels,\n",
    "                      fs=fs,\n",
    "                      dur=dur,\n",
    "                      f_min=f_min,\n",
    "                      f_max=f_max)\n",
    "    l.trainable = trainable\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_specaug: spec-augmentation layer.\n",
    "    m_specaug = get_specaug_chain_layer(cfg, trainable=False)\n",
    "    assert(m_specaug.bypass==False) # Detachable by setting m_specaug.bypass.\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    return m_pre, m_specaug, m_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import click\n",
    "import yaml\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(X, m_pre, m_specaug, m_fp, loss_obj, helper):\n",
    "    \"\"\" Train step \"\"\"\n",
    "    # X: (Xa, Xp)\n",
    "    # Xa: anchors or originals, s.t. [xa_0, xa_1,...]\n",
    "    # Xp: augmented replicas, s.t. [xp_0, xp_1] with xp_n = rand_aug(xa_n).\n",
    "    n_anchors = len(X[0])\n",
    "    X = tf.concat(X, axis=0)\n",
    "    feat = m_specaug(m_pre(X))  # (nA+nP, F, T, 1)\n",
    "    m_fp.trainable = True\n",
    "    with tf.GradientTape() as t:\n",
    "        emb = m_fp(feat)  # (BSZ, Dim)\n",
    "        loss, sim_mtx, _ = loss_obj.compute_loss(\n",
    "            emb[:n_anchors, :], emb[n_anchors:, :]) # {emb_org, emb_rep}\n",
    "    g = t.gradient(loss, m_fp.trainable_variables)\n",
    "    helper.optimizer.apply_gradients(zip(g, m_fp.trainable_variables))\n",
    "    avg_loss = helper.update_tr_loss(loss) # To tensorboard.\n",
    "    return avg_loss, sim_mtx # avg_loss: average within the current epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default.yaml\n"
     ]
    }
   ],
   "source": [
    "config = \"default\"\n",
    "cfg = load_config(config)\n",
    "checkpoint_name = \"Checks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Restoring from ./logs/checkpoint/Checks/ckpt-100---\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "dataset = Dataset(cfg)\n",
    "\n",
    "# Build models.\n",
    "m_pre, m_specaug, m_fp = build_fp(cfg)\n",
    "\n",
    "# Learning schedule\n",
    "total_nsteps = cfg['TRAIN']['MAX_EPOCH'] * len(dataset.get_train_ds())\n",
    "if cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS':\n",
    "    lr_schedule = tf.keras.experimental.CosineDecay(\n",
    "        initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "        decay_steps=total_nsteps,\n",
    "        alpha=1e-06)\n",
    "elif cfg['TRAIN']['LR_SCHEDULE'].upper() == 'COS-RESTART':\n",
    "    lr_schedule = tf.keras.experimental.CosineDecayRestarts(\n",
    "        initial_learning_rate=float(cfg['TRAIN']['LR']),\n",
    "        first_decay_steps=int(total_nsteps * 0.1),\n",
    "        num_periods=0.5,\n",
    "        alpha=2e-06)\n",
    "else:\n",
    "    lr_schedule = float(cfg['TRAIN']['LR'])\n",
    "\n",
    "# Optimizer\n",
    "if cfg['TRAIN']['OPTIMIZER'].upper() == 'LAMB':\n",
    "    opt = LAMB(learning_rate=lr_schedule)\n",
    "elif cfg['TRAIN']['OPTIMIZER'].upper() == 'ADAM':\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "else:\n",
    "    raise NotImplementedError(cfg['TRAIN']['OPTIMIZER'])\n",
    "\n",
    "# Experiment helper: see utils.experiment_helper.py for details.\n",
    "helper = ExperimentHelper(\n",
    "    checkpoint_name=checkpoint_name,\n",
    "    optimizer=opt,\n",
    "    model_to_checkpoint=m_fp,\n",
    "    cfg=cfg)\n",
    "\n",
    "# Loss objects\n",
    "if cfg['LOSS']['LOSS_MODE'].upper() == 'NTXENT': # Default\n",
    "    loss_obj_train = NTxentLoss(\n",
    "        n_org=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "        n_rep=cfg['BSZ']['TR_BATCH_SZ'] - cfg['BSZ']['TR_N_ANCHOR'],\n",
    "        tau=cfg['LOSS']['TAU'])\n",
    "    loss_obj_val = NTxentLoss(\n",
    "        n_org=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "        n_rep=cfg['BSZ']['VAL_BATCH_SZ'] - cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "        tau=cfg['LOSS']['TAU'])\n",
    "elif cfg['LOSS']['LOSS_MODE'].upper() == 'ONLINE-TRIPLET': # Now-playing\n",
    "    loss_obj_train = OnlineTripletLoss(\n",
    "        bsz=cfg['BSZ']['TR_BATCH_SZ'],\n",
    "        n_anchor=cfg['BSZ']['TR_N_ANCHOR'],\n",
    "        mode = 'semi-hard',\n",
    "        margin=cfg['LOSS']['MARGIN'])\n",
    "    loss_obj_val = OnlineTripletLoss(\n",
    "        bsz=cfg['BSZ']['VAL_BATCH_SZ'],\n",
    "        n_anchor=cfg['BSZ']['VAL_N_ANCHOR'],\n",
    "        mode = 'all', # use 'all' mode for validation\n",
    "        margin=0.)\n",
    "else:\n",
    "    raise NotImplementedError(cfg['LOSS']['LOSS_MODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.get_train_ds(0)\n",
    "enq = tf.keras.utils.OrderedEnqueuer(\n",
    "        train_ds, use_multiprocessing=True, shuffle=train_ds.shuffle)\n",
    "enq.start(workers=cfg['DEVICE']['CPU_N_WORKERS'],\n",
    "        max_queue_size=cfg['DEVICE']['CPU_MAX_QUEUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(enq.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_anchors = len(X[0])\n",
    "X = tf.concat(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]]] 1024 256 1024 <function hann_window at 0x763d5cfe1bc0> False stft_tf.signal.stft\n",
      "stftsTensor(\"Mel-spectrogram/stft/stft_tf.signal.stft/rfft:0\", shape=(None, 1, 32, 513), dtype=complex64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 256, 32, 1), dtype=float32, numpy=\n",
       "array([[[[-2.2151241 ],\n",
       "         [-2.2898803 ],\n",
       "         [-2.3167448 ],\n",
       "         ...,\n",
       "         [-2.1805067 ],\n",
       "         [-2.0726318 ],\n",
       "         [-1.8118098 ]],\n",
       "\n",
       "        [[-2.114199  ],\n",
       "         [-2.102054  ],\n",
       "         [-2.1039279 ],\n",
       "         ...,\n",
       "         [-2.299484  ],\n",
       "         [-2.0498333 ],\n",
       "         [-1.8043013 ]],\n",
       "\n",
       "        [[-2.0431278 ],\n",
       "         [-1.9357278 ],\n",
       "         [-1.9275297 ],\n",
       "         ...,\n",
       "         [-2.2669683 ],\n",
       "         [-2.0041091 ],\n",
       "         [-1.7864234 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.365312  ],\n",
       "         [-2.366416  ],\n",
       "         [-2.3673136 ],\n",
       "         ...,\n",
       "         [-2.3674002 ],\n",
       "         [-2.346119  ],\n",
       "         [-2.3041387 ]],\n",
       "\n",
       "        [[-2.3652709 ],\n",
       "         [-2.3664103 ],\n",
       "         [-2.3672857 ],\n",
       "         ...,\n",
       "         [-2.367259  ],\n",
       "         [-2.3460605 ],\n",
       "         [-2.304075  ]],\n",
       "\n",
       "        [[-2.3653584 ],\n",
       "         [-2.3664715 ],\n",
       "         [-2.3672767 ],\n",
       "         ...,\n",
       "         [-2.3672767 ],\n",
       "         [-2.3461435 ],\n",
       "         [-2.3041964 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.6850444 ],\n",
       "         [-1.6319014 ],\n",
       "         [-1.7171981 ],\n",
       "         ...,\n",
       "         [-1.8197832 ],\n",
       "         [-1.979578  ],\n",
       "         [-1.7184446 ]],\n",
       "\n",
       "        [[-1.7947056 ],\n",
       "         [-1.9331639 ],\n",
       "         [-1.8967147 ],\n",
       "         ...,\n",
       "         [-1.7970622 ],\n",
       "         [-1.8647716 ],\n",
       "         [-1.692237  ]],\n",
       "\n",
       "        [[-1.7978086 ],\n",
       "         [-1.8251045 ],\n",
       "         [-1.9805737 ],\n",
       "         ...,\n",
       "         [-1.7036905 ],\n",
       "         [-1.6425647 ],\n",
       "         [-1.5794163 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.3611226 ],\n",
       "         [-2.3634033 ],\n",
       "         [-2.3649547 ],\n",
       "         ...,\n",
       "         [-2.3637204 ],\n",
       "         [-2.3629928 ],\n",
       "         [-2.3627691 ]],\n",
       "\n",
       "        [[-2.3638809 ],\n",
       "         [-2.3657413 ],\n",
       "         [-2.366869  ],\n",
       "         ...,\n",
       "         [-2.366342  ],\n",
       "         [-2.3654451 ],\n",
       "         [-2.3629565 ]],\n",
       "\n",
       "        [[-2.3641825 ],\n",
       "         [-2.3658853 ],\n",
       "         [-2.367227  ],\n",
       "         ...,\n",
       "         [-2.367342  ],\n",
       "         [-2.3662763 ],\n",
       "         [-2.3632638 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.9859664 ],\n",
       "         [-1.5189908 ],\n",
       "         [-1.601179  ],\n",
       "         ...,\n",
       "         [-1.7669568 ],\n",
       "         [-1.7027311 ],\n",
       "         [-1.9303324 ]],\n",
       "\n",
       "        [[-2.0540938 ],\n",
       "         [-1.5179949 ],\n",
       "         [-1.3322183 ],\n",
       "         ...,\n",
       "         [-1.7328298 ],\n",
       "         [-1.7069077 ],\n",
       "         [-1.864913  ]],\n",
       "\n",
       "        [[-2.0857642 ],\n",
       "         [-1.553616  ],\n",
       "         [-1.3800256 ],\n",
       "         ...,\n",
       "         [-1.8322885 ],\n",
       "         [-1.7858987 ],\n",
       "         [-1.9505752 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.3506799 ],\n",
       "         [-2.3547952 ],\n",
       "         [-2.32553   ],\n",
       "         ...,\n",
       "         [-2.3668137 ],\n",
       "         [-2.3509316 ],\n",
       "         [-2.3187194 ]],\n",
       "\n",
       "        [[-2.3505657 ],\n",
       "         [-2.3586535 ],\n",
       "         [-2.3574665 ],\n",
       "         ...,\n",
       "         [-2.367364  ],\n",
       "         [-2.3511114 ],\n",
       "         [-2.3184133 ]],\n",
       "\n",
       "        [[-2.3505678 ],\n",
       "         [-2.3589895 ],\n",
       "         [-2.365913  ],\n",
       "         ...,\n",
       "         [-2.3674035 ],\n",
       "         [-2.3512187 ],\n",
       "         [-2.3185806 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.5408552 ],\n",
       "         [-1.219523  ],\n",
       "         [-1.4012659 ],\n",
       "         ...,\n",
       "         [-1.3107288 ],\n",
       "         [-1.4479324 ],\n",
       "         [-1.1685693 ]],\n",
       "\n",
       "        [[-1.5759379 ],\n",
       "         [-1.2601238 ],\n",
       "         [-1.3055613 ],\n",
       "         ...,\n",
       "         [-1.0425768 ],\n",
       "         [-1.1089047 ],\n",
       "         [-1.0002339 ]],\n",
       "\n",
       "        [[-1.490534  ],\n",
       "         [-1.3803825 ],\n",
       "         [-1.4211879 ],\n",
       "         ...,\n",
       "         [-0.7415179 ],\n",
       "         [-0.7607901 ],\n",
       "         [-0.8555161 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2938445 ],\n",
       "         [-2.3290496 ],\n",
       "         [-2.3643537 ],\n",
       "         ...,\n",
       "         [-2.364439  ],\n",
       "         [-2.3434658 ],\n",
       "         [-2.296567  ]],\n",
       "\n",
       "        [[-2.294045  ],\n",
       "         [-2.3290915 ],\n",
       "         [-2.3637633 ],\n",
       "         ...,\n",
       "         [-2.3651004 ],\n",
       "         [-2.3440619 ],\n",
       "         [-2.2975197 ]],\n",
       "\n",
       "        [[-2.2939553 ],\n",
       "         [-2.328885  ],\n",
       "         [-2.3636365 ],\n",
       "         ...,\n",
       "         [-2.3663318 ],\n",
       "         [-2.3432648 ],\n",
       "         [-2.2966793 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.4882702 ],\n",
       "         [-1.758266  ],\n",
       "         [-1.7470163 ],\n",
       "         ...,\n",
       "         [-1.8381739 ],\n",
       "         [-1.875283  ],\n",
       "         [-1.6530769 ]],\n",
       "\n",
       "        [[-1.321233  ],\n",
       "         [-1.3945578 ],\n",
       "         [-1.7456565 ],\n",
       "         ...,\n",
       "         [-1.4508903 ],\n",
       "         [-1.4199418 ],\n",
       "         [-1.3940824 ]],\n",
       "\n",
       "        [[-1.2342483 ],\n",
       "         [-1.1329818 ],\n",
       "         [-1.2021403 ],\n",
       "         ...,\n",
       "         [-0.9448413 ],\n",
       "         [-0.93262905],\n",
       "         [-1.0688396 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2759023 ],\n",
       "         [-2.3007758 ],\n",
       "         [-2.3052394 ],\n",
       "         ...,\n",
       "         [-2.3611171 ],\n",
       "         [-2.361325  ],\n",
       "         [-2.3481753 ]],\n",
       "\n",
       "        [[-2.2934742 ],\n",
       "         [-2.322045  ],\n",
       "         [-2.3495092 ],\n",
       "         ...,\n",
       "         [-2.3667722 ],\n",
       "         [-2.3613906 ],\n",
       "         [-2.3481345 ]],\n",
       "\n",
       "        [[-2.3049088 ],\n",
       "         [-2.3358397 ],\n",
       "         [-2.3662915 ],\n",
       "         ...,\n",
       "         [-2.3672552 ],\n",
       "         [-2.3615255 ],\n",
       "         [-2.348415  ]]],\n",
       "\n",
       "\n",
       "       [[[-1.2964548 ],\n",
       "         [-1.3974278 ],\n",
       "         [-1.3099803 ],\n",
       "         ...,\n",
       "         [-1.2370286 ],\n",
       "         [-1.6008297 ],\n",
       "         [-1.8958652 ]],\n",
       "\n",
       "        [[-1.1542522 ],\n",
       "         [-1.1887965 ],\n",
       "         [-1.1965332 ],\n",
       "         ...,\n",
       "         [-1.3524673 ],\n",
       "         [-1.450557  ],\n",
       "         [-1.4341221 ]],\n",
       "\n",
       "        [[-1.0691444 ],\n",
       "         [-1.1706069 ],\n",
       "         [-1.2104615 ],\n",
       "         ...,\n",
       "         [-1.1296893 ],\n",
       "         [-1.1627586 ],\n",
       "         [-1.1885409 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.1739697 ],\n",
       "         [-2.1055849 ],\n",
       "         [-2.1551332 ],\n",
       "         ...,\n",
       "         [-2.1224003 ],\n",
       "         [-1.9155385 ],\n",
       "         [-1.9082326 ]],\n",
       "\n",
       "        [[-2.209931  ],\n",
       "         [-2.251778  ],\n",
       "         [-2.2470798 ],\n",
       "         ...,\n",
       "         [-2.1467671 ],\n",
       "         [-1.9973049 ],\n",
       "         [-1.9652956 ]],\n",
       "\n",
       "        [[-2.228907  ],\n",
       "         [-2.171941  ],\n",
       "         [-2.2148623 ],\n",
       "         ...,\n",
       "         [-2.0936844 ],\n",
       "         [-2.045315  ],\n",
       "         [-2.0955014 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pre(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados salvos em: ./DadosDebugMostrarProfessor/X_antes_concat_trainStep.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Caminho da pasta onde o arquivo CSV será salvo\n",
    "folder_path = './DadosDebugMostrarProfessor'\n",
    "# Nome do arquivo CSV\n",
    "file_name = 'X_antes_concat_trainStep.csv'\n",
    "\n",
    "# Criar a pasta se ela não existir\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Caminho completo do arquivo CSV\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Escrever os dados no arquivo CSV\n",
    "with open(file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Iterar sobre o tuple e escrever cada array em uma linha separada\n",
    "    for array in X:\n",
    "        writer.writerow(array)\n",
    "\n",
    "print(f'Dados salvos em: {file_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
