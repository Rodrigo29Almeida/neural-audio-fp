{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import glob\n",
    "import wave\n",
    "\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "from model.fp.melspec.melspectrogram import get_melspec_layer\n",
    "from model.fp.specaug_chain.specaug_chain import get_specaug_chain_layer\n",
    "from model.fp.nnfp import get_fingerprinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fp(cfg):\n",
    "    \"\"\" Build fingerprinter \"\"\"\n",
    "    # m_pre: log-power-Mel-spectrogram layer, S.\n",
    "    m_pre = get_melspec_layer(cfg, trainable=False)\n",
    "\n",
    "    # m_specaug: spec-augmentation layer.\n",
    "    #m_specaug = get_specaug_chain_layer(cfg, trainable=False)\n",
    "    #assert(m_specaug.bypass==False) # Detachable by setting m_specaug.bypass.\n",
    "\n",
    "    # m_fp: fingerprinter g(f(.)).\n",
    "    m_fp = get_fingerprinter(cfg, trainable=False)\n",
    "    m_fp.trainable = False\n",
    "    \n",
    "    return m_pre, m_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_fname):\n",
    "    config_filepath = './config/' + config_fname + '.yaml'\n",
    "    if os.path.exists(config_filepath):\n",
    "        print(f'cli: Configuration from {config_filepath}')\n",
    "    else:\n",
    "        sys.exit(f'cli: ERROR! Configuration file {config_filepath} is missing!!')\n",
    "\n",
    "    with open(config_filepath, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return cfg\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def predict(X, m_fp):\n",
    "    \"\"\" \n",
    "    Test step used for mini-search-validation \n",
    "    X -> (B,1,8000)\n",
    "    \"\"\"\n",
    "    emb_gf = m_fp(X)\n",
    "\n",
    "    return emb_gf\n",
    "\n",
    "\n",
    "def load_model():\n",
    "\n",
    "    checkpoint_name_dir:str = \"./logs/CHECKPOINT_BSZ_120\"  #\"CHECKPOINT\"   # string\n",
    "    config:str = \"default\"   \n",
    "\n",
    "    cfg = load_config(config)\n",
    "\n",
    "    m_pre, m_fp = build_fp(cfg)\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(m_fp)\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_name_dir))\n",
    "        \n",
    "    return m_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def predict(X, m_fp):\n",
    "    \"\"\" \n",
    "    Test step used for mini-search-validation \n",
    "    X -> (B,1,8000)\n",
    "    \"\"\"\n",
    "    emb_gf = m_fp(X)\n",
    "\n",
    "    return emb_gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:/mnt/dataset/public/Fingerprinting/teste/uniqueFile/002000.wav\n",
      "seg_idx:3\n",
      "offset_min:-4000\n",
      "offset_max:4000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audioDir = '/mnt/dataset/public/Fingerprinting/teste/uniqueFile/002000.wav'\n",
    "\n",
    "fns_list = sorted(glob.glob(audioDir, recursive=True))\n",
    "\n",
    "fns_seg_list = []\n",
    "seg_list_test = []\n",
    "\n",
    "fs:int = 8000\n",
    "duration:int = 1\n",
    "hop:int = 0.5\n",
    "\n",
    "for offset_idx, filename in enumerate(fns_list):\n",
    "    # Get audio info\n",
    "    n_frames_in_seg = fs * duration\n",
    "    n_frames_in_hop = fs * hop  # 2019 09.05\n",
    "    file_ext = filename[-3:]\n",
    "\n",
    "    if file_ext == 'wav':\n",
    "        pt_wav = wave.open(filename, 'r')\n",
    "        _fs = pt_wav.getframerate()\n",
    "\n",
    "        if fs != _fs:\n",
    "            raise ValueError('Sample rate should be {} but got {}'.format(\n",
    "                str(fs), str(_fs)))\n",
    "\n",
    "        n_frames = pt_wav.getnframes()\n",
    "        #n_segs = n_frames // n_frames_in_seg\n",
    "        if n_frames > n_frames_in_seg:\n",
    "            n_segs = (n_frames - n_frames_in_seg +\n",
    "                        n_frames_in_hop) // n_frames_in_hop\n",
    "        else:\n",
    "            n_segs = 1\n",
    "\n",
    "        n_segs = int(n_segs)\n",
    "        assert (n_segs > 0)\n",
    "        residual_frames = np.max([\n",
    "            0,\n",
    "            n_frames - ((n_segs - 1) * n_frames_in_hop + n_frames_in_seg)\n",
    "        ])\n",
    "        \n",
    "        #print(f\"filename:{filename}\\nn_frames_in_seg:{n_frames_in_seg}\\nn_frames_in_hop:{n_frames_in_hop}\\nfile_ext:{file_ext}\\n\")\n",
    "        #print(f\"_fs:{_fs}\\nn_frames:{n_frames}\\nn_segs:{n_segs}\\nresidual_frames:{residual_frames}\\n\")\n",
    "        \n",
    "        pt_wav.close()\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(file_ext)\n",
    "    \n",
    "\n",
    "    for seg_idx in range(n_segs):\n",
    "        offset_min, offset_max = int(-1 * n_frames_in_hop), n_frames_in_hop\n",
    "        \n",
    "        #print(f\"seg_idx:{seg_idx}\\noffset_min:{offset_min}\\noffset_max:{offset_max}\\nfns_seg_list:{fns_seg_list}\\n\")\n",
    "\n",
    "        if seg_idx == 0:  # first seg\n",
    "            offset_min = 0\n",
    "        if seg_idx == (n_segs - 1):  # last seg\n",
    "            offset_max = residual_frames\n",
    "        if seg_idx == 3:\n",
    "            seg_list_test.append( [filename, seg_idx, offset_min, offset_max])\n",
    "            print(f\"filename:{filename}\\nseg_idx:{seg_idx}\\noffset_min:{offset_min}\\noffset_max:{offset_max}\\n\")\n",
    "\n",
    "        fns_seg_list.append(\n",
    "            [filename, seg_idx, offset_min, offset_max])\n",
    "        \n",
    "        #print(f\"seg_idx:{seg_idx}\\noffset_min:{offset_min}\\noffset_max:{offset_max}\\nfns_seg_list:{fns_seg_list}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(filename=str(),\n",
    "               seg_start_sec=float(),\n",
    "               offset_sec=0.0,\n",
    "               seg_length_sec=float(),\n",
    "               seg_pad_offset_sec=0.0,\n",
    "               fs=22050,\n",
    "               amp_mode='normal'):\n",
    "    \"\"\"\n",
    "        Open file to get file info --> Calulate index range\n",
    "        --> Load sample by index --> Padding --> Max-Normalize --> Out\n",
    "        \n",
    "    \"\"\"\n",
    "    start_frame_idx = np.floor((seg_start_sec + offset_sec) * fs).astype(int)\n",
    "    seg_length_frame = np.floor(seg_length_sec * fs).astype(int)\n",
    "    end_frame_idx = start_frame_idx + seg_length_frame\n",
    "\n",
    "    # Get file-info\n",
    "    file_ext = filename[-3:]\n",
    "    print(start_frame_idx, end_frame_idx)\n",
    "\n",
    "    if file_ext == 'wav':\n",
    "        pt_wav = wave.open(filename, 'r')\n",
    "        pt_wav.setpos(start_frame_idx)\n",
    "        x = pt_wav.readframes(end_frame_idx - start_frame_idx)\n",
    "        x = np.frombuffer(x, dtype=np.int16)\n",
    "        x = x / 2**15  # dtype=float\n",
    "    else:\n",
    "        raise NotImplementedError(file_ext)\n",
    "\n",
    "    # Max Normalize, random amplitude\n",
    "    if amp_mode == 'normal':\n",
    "        pass\n",
    "    elif amp_mode == 'max_normalize':\n",
    "        _x_max = np.max(np.abs(x))\n",
    "        if _x_max != 0:\n",
    "            x = x / _x_max\n",
    "    else:\n",
    "        raise ValueError('amp_mode={}'.format(amp_mode))\n",
    "\n",
    "    # padding process. it works only when win_size> audio_size and padding='random'\n",
    "    audio_arr = np.zeros(int(seg_length_sec * fs))\n",
    "    seg_pad_offset_idx = int(seg_pad_offset_sec * fs)\n",
    "    audio_arr[seg_pad_offset_idx:seg_pad_offset_idx + len(x)] = x\n",
    "    return audio_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000 20000\n"
     ]
    }
   ],
   "source": [
    "x = load_audio(filename=filename,\n",
    "               seg_start_sec=1.5,\n",
    "               seg_length_sec=1,\n",
    "               fs=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(8000,)\n",
      "[0.0213623  0.01916504 0.021698   ... 0.02557373 0.0295105  0.02172852]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(type(x))\n",
    "print(np.shape(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 8000)\n",
      "[[0.0213623  0.01916504 0.021698   ... 0.02557373 0.0295105  0.02172852]]\n"
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "print(np.shape(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(x, m_fp):\n",
    "    '''\n",
    "    filepath: (str, ndarray)\n",
    "    '''\n",
    "\n",
    "    # tenho as tramas e de 8000 amostras tenho de chamar a get_melspec, tenho de trazer o get_melspec e o get_fringerprint, tenho trazer uma matriz do input_shape para que consigo ver os pesos\n",
    "    # tem de ser m_spec, _, m_fp = build_fp(cfg). matching. tirar o librosa pegar no sinal, passar no fingerprint. 3 tensores, um para mel spec, um para data_aug e outro para a rede.\n",
    "    # (256,32,1) de entrada no X, tenho de alterar em vez de 8000\n",
    "    \n",
    "    emb = predict(x, m_fp)\n",
    "\n",
    "    tf.config.run_functions_eagerly(True)\n",
    "\n",
    "    return emb.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default.yaml\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_3084456/2396453651.py\", line 7, in predict  *\n        emb_gf = m_fp(X)\n    File \"/home/rodrigo/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file7mrpzq9p.py\", line 10, in tf__call\n        x = ag__.converted_call(ag__.ld(self).front_conv, (ag__.ld(inputs),), None, fscope)\n    File \"/tmp/__autograph_generated_fileu8kwn9i4.py\", line 15, in tf__call\n        raise\n\n    ValueError: Exception encountered when calling layer 'finger_printer_5' (type FingerPrinter).\n    \n    in user code:\n    \n        File \"/home/rodrigo/Documents/neural-audio-fp/model/fp/nnfp.py\", line 229, in call  *\n            x = self.front_conv(inputs) # (B,D) with D = (T/2^4) x last_hidden_ch\n        File \"/home/rodrigo/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/tmp/__autograph_generated_fileu8kwn9i4.py\", line 15, in tf__call\n            raise\n    \n        ValueError: Exception encountered when calling layer 'conv_layer_40' (type ConvLayer).\n        \n        in user code:\n        \n            File \"/home/rodrigo/Documents/neural-audio-fp/model/fp/nnfp.py\", line 83, in call  *\n                return self.forward(x)\n            File \"/home/rodrigo/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"/home/rodrigo/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n                raise ValueError(\n        \n            ValueError: Exception encountered when calling layer 'sequential_683' (type Sequential).\n            \n            Input 0 of layer \"conv2d_80\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (1, 8000)\n            \n            Call arguments received by layer 'sequential_683' (type Sequential):\n              • inputs=tf.Tensor(shape=(1, 8000), dtype=float32)\n              • training=None\n              • mask=None\n        \n        \n        Call arguments received by layer 'conv_layer_40' (type ConvLayer):\n          • x=tf.Tensor(shape=(1, 8000), dtype=float32)\n    \n    \n    Call arguments received by layer 'finger_printer_5' (type FingerPrinter):\n      • inputs=tf.Tensor(shape=(1, 8000), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m m_fp \u001b[38;5;241m=\u001b[39m load_model()\n\u001b[0;32m----> 2\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_fp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[114], line 10\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(x, m_fp)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mfilepath: (str, ndarray)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# tenho as tramas e de 8000 amostras tenho de chamar a get_melspec, tenho de trazer o get_melspec e o get_fringerprint, tenho trazer uma matriz do input_shape para que consigo ver os pesos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# tem de ser m_spec, _, m_fp = build_fp(cfg). matching. tirar o libros,a pegar no sinla, passar no fingerprint. 3 tensores, um para mel spec, um para data_aug e outro para a rede.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# (256,32,1) de entrada no X, tenho de alterar em vez de 8000\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_fp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m emb\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filekdc7cggg.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict\u001b[0;34m(X, m_fp)\u001b[0m\n\u001b[1;32m     12\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     13\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 14\u001b[0m emb_gf \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm_fp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file7mrpzq9p.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfront_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdiv_enc, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m():\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileu8kwn9i4.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mforward, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_3084456/2396453651.py\", line 7, in predict  *\n        emb_gf = m_fp(X)\n    File \"/home/rodrigo/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file7mrpzq9p.py\", line 10, in tf__call\n        x = ag__.converted_call(ag__.ld(self).front_conv, (ag__.ld(inputs),), None, fscope)\n    File \"/tmp/__autograph_generated_fileu8kwn9i4.py\", line 15, in tf__call\n        raise\n\n    ValueError: Exception encountered when calling layer 'finger_printer_5' (type FingerPrinter).\n    \n    in user code:\n    \n        File \"/home/rodrigo/Documents/neural-audio-fp/model/fp/nnfp.py\", line 229, in call  *\n            x = self.front_conv(inputs) # (B,D) with D = (T/2^4) x last_hidden_ch\n        File \"/home/rodrigo/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/tmp/__autograph_generated_fileu8kwn9i4.py\", line 15, in tf__call\n            raise\n    \n        ValueError: Exception encountered when calling layer 'conv_layer_40' (type ConvLayer).\n        \n        in user code:\n        \n            File \"/home/rodrigo/Documents/neural-audio-fp/model/fp/nnfp.py\", line 83, in call  *\n                return self.forward(x)\n            File \"/home/rodrigo/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"/home/rodrigo/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n                raise ValueError(\n        \n            ValueError: Exception encountered when calling layer 'sequential_683' (type Sequential).\n            \n            Input 0 of layer \"conv2d_80\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (1, 8000)\n            \n            Call arguments received by layer 'sequential_683' (type Sequential):\n              • inputs=tf.Tensor(shape=(1, 8000), dtype=float32)\n              • training=None\n              • mask=None\n        \n        \n        Call arguments received by layer 'conv_layer_40' (type ConvLayer):\n          • x=tf.Tensor(shape=(1, 8000), dtype=float32)\n    \n    \n    Call arguments received by layer 'finger_printer_5' (type FingerPrinter):\n      • inputs=tf.Tensor(shape=(1, 8000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "m_fp = load_model()\n",
    "emb = run(x, m_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seg_list_test[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nseg_list_test[0][0]\\nseg_list_test[0][2]\\nduration = 1\\nfs = 8000\\namp_mode = 'normal'\\n\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "seg_list_test[0][0]\n",
    "seg_list_test[0][2]\n",
    "duration = 1\n",
    "fs = 8000\n",
    "amp_mode = 'normal'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xs = load_audio_multi_start(fns_event_seg_list[idx][0], start_sec_list, duration, fs, amp_mode)  # xs: ((1+n_pos)),T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RASCUNHOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = predict(X, m_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default.yaml\n"
     ]
    }
   ],
   "source": [
    "modelo = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.fp.nnfp.FingerPrinter"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<model.fp.nnfp.DivEncLayer at 0x7aab17659750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.div_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"default\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli: Configuration from ./config/default.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/dataset/public/Fingerprinting/neural-audio-fp-dataset/music/'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['DIR']['SOURCE_ROOT_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([5, 1, 2, 4])\n",
    "y=tf.reduce_max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5 1 2 4], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 4], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda, Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=Permute((3, 2, 1), input_shape=x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.reshaping.permute.Permute object at 0x7aab1769bd90>\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front_strides=[\n",
    "                [(1,2), (2,1)], \n",
    "                [(1,2), (2,1)],\n",
    "                [(1,2), (2,1)],\n",
    "                [(1,2), (2,1)],\n",
    "                [(1,1), (2,1)],\n",
    "                [(1,2), (2,1)],\n",
    "                [(1,1), (2,1)],\n",
    "                [(1,2), (2,1)]\n",
    "                ]\n",
    "len(front_strides[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(front_strides)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
